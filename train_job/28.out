/home/exouser/YuZheng/experiments/autoencoder_kl_gan/world_size1-hmdb_autoencoder
load yaml from config
Launching processes...
2025-02-06 17:56:04,644 train INFO: Building config ...
2025-02-06 17:56:04,644 train INFO: Building dataloaders ...
Total frames in dataset: 186436
2025-02-06 17:57:05,555 train INFO: Train dataloaders build complete
Total frames in dataset: 186436
2025-02-06 17:58:04,662 train INFO: Valid dataloaders build complete
2025-02-06 17:58:04,662 train INFO: Building models ...
/home/exouser/YuZheng/models/model.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.gscaler = amp.GradScaler(enabled=self.enabled_amp)
2025-02-06 17:58:05,376 train INFO: finetune checkpoint path not exist
2025-02-06 17:58:05,573 train INFO: params autoencoder_kl: 55912619
2025-02-06 17:58:05,574 train INFO: params lpipsWithDisc: 2765634
2025-02-06 17:58:05,574 train INFO: begin training ...
2025-02-06 17:58:09,623 train INFO: [20/46609/10000]  lr: 2.881e-06  eta: 0:33:40  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0192, 0.0193)  train/logits_fake: 0.0165 (0.0165, 0.0165)  train/total_loss: 77273.1406 (77418.9609, 61893.9219)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 1029.6658 (990.1771, 1439.9606)  train/nll_loss: 77273.1406 (77418.9609, 61893.9219)  train/rec_loss: 0.3354 (0.3360, 0.2686)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0165 (-0.0165, -0.0165)
2025-02-06 17:58:12,145 train INFO: [40/46609/10000]  lr: 4.8610000000000006e-06  eta: 0:27:16  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0201)  train/logits_fake: 0.0167 (0.0170, 0.0194)  train/total_loss: 59704.8203 (66340.6523, 50116.2227)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 1348.7134 (1293.7349, 1998.4031)  train/nll_loss: 59704.8203 (66340.6521, 50116.2188)  train/rec_loss: 0.2591 (0.2879, 0.2175)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0167 (-0.0170, -0.0194)
2025-02-06 17:58:14,682 train INFO: [60/46609/10000]  lr: 6.841e-06  eta: 0:25:08  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0192, 0.0200)  train/logits_fake: 0.0175 (0.0178, 0.0194)  train/total_loss: 54942.9336 (57757.4968, 34559.5586)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 1571.4991 (1759.9947, 4038.1345)  train/nll_loss: 54942.9336 (57757.4954, 34559.5547)  train/rec_loss: 0.2385 (0.2507, 0.1500)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0176 (-0.0178, -0.0194)
2025-02-06 17:58:17,217 train INFO: [80/46609/10000]  lr: 8.821000000000002e-06  eta: 0:24:03  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0193, 0.0181)  train/logits_fake: 0.0187 (0.0185, 0.0212)  train/total_loss: 47993.7734 (51723.3650, 33145.5859)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 2068.8708 (2361.2787, 4492.6250)  train/nll_loss: 47993.7695 (51723.3629, 33145.5820)  train/rec_loss: 0.2083 (0.2245, 0.1439)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0189 (-0.0185, -0.0212)
2025-02-06 17:58:19,756 train INFO: [100/46609/10000]  lr: 1.0801000000000002e-05  eta: 0:23:23  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0192, 0.0170)  train/logits_fake: 0.0192 (0.0187, 0.0184)  train/total_loss: 39378.2266 (47518.8250, 33705.0664)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 2580.6206 (2827.8201, 4798.4736)  train/nll_loss: 39378.2227 (47518.8224, 33705.0625)  train/rec_loss: 0.1709 (0.2062, 0.1463)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0187, -0.0184)
2025-02-06 17:58:22,288 train INFO: [120/46609/10000]  lr: 1.2781000000000002e-05  eta: 0:22:55  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0192, 0.0188)  train/logits_fake: 0.0196 (0.0189, 0.0187)  train/total_loss: 34507.7930 (44230.8537, 27400.4277)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 4071.1167 (3380.6935, 7130.7935)  train/nll_loss: 34507.7891 (44230.8506, 27400.4199)  train/rec_loss: 0.1498 (0.1920, 0.1189)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0196 (-0.0189, -0.0187)
2025-02-06 17:58:24,822 train INFO: [140/46609/10000]  lr: 1.4761000000000003e-05  eta: 0:22:35  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0192, 0.0182)  train/logits_fake: 0.0199 (0.0190, 0.0205)  train/total_loss: 31110.7266 (41752.7082, 25671.5996)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 4816.4697 (3952.1354, 6961.2744)  train/nll_loss: 31110.7227 (41752.7044, 25671.5918)  train/rec_loss: 0.1350 (0.1812, 0.1114)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0199 (-0.0190, -0.0205)
2025-02-06 17:58:27,358 train INFO: [160/46609/10000]  lr: 1.6741e-05  eta: 0:22:19  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0192, 0.0191)  train/logits_fake: 0.0199 (0.0191, 0.0199)  train/total_loss: 28035.0039 (39799.2447, 22368.9453)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 6139.5879 (4444.9182, 8234.3574)  train/nll_loss: 28035.0000 (39799.2404, 22368.9375)  train/rec_loss: 0.1217 (0.1727, 0.0971)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0200 (-0.0191, -0.0199)
2025-02-06 17:58:29,894 train INFO: [180/46609/10000]  lr: 1.8721000000000003e-05  eta: 0:22:06  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0192, 0.0194)  train/logits_fake: 0.0199 (0.0192, 0.0204)  train/total_loss: 26680.5371 (37977.5643, 19045.9062)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 7317.1816 (4920.0080, 8829.0547)  train/nll_loss: 26680.5293 (37977.5595, 19045.8965)  train/rec_loss: 0.1158 (0.1648, 0.0827)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0199 (-0.0192, -0.0204)
2025-02-06 17:58:32,426 train INFO: [200/46609/10000]  lr: 2.0701000000000004e-05  eta: 0:21:55  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0192, 0.0206)  train/logits_fake: 0.0198 (0.0192, 0.0202)  train/total_loss: 25109.9727 (36523.5078, 25623.5059)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 7855.3398 (5335.4682, 9579.9141)  train/nll_loss: 25109.9648 (36523.5026, 25623.4961)  train/rec_loss: 0.1090 (0.1585, 0.1112)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0199 (-0.0192, -0.0202)
2025-02-06 17:58:34,960 train INFO: [220/46609/10000]  lr: 2.2681000000000002e-05  eta: 0:21:46  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0170)  train/logits_fake: 0.0197 (0.0192, 0.0203)  train/total_loss: 24349.1582 (35467.2970, 32424.2012)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 8553.9277 (5744.4663, 10928.3262)  train/nll_loss: 24349.1504 (35467.2914, 32424.1895)  train/rec_loss: 0.1057 (0.1539, 0.1407)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0197 (-0.0192, -0.0203)
2025-02-06 17:58:37,491 train INFO: [240/46609/10000]  lr: 2.4661000000000003e-05  eta: 0:21:37  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0193)  train/logits_fake: 0.0196 (0.0192, 0.0201)  train/total_loss: 24021.4023 (34571.6727, 22300.3438)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 9161.7031 (6220.4358, 11414.7236)  train/nll_loss: 24021.3945 (34571.6666, 22300.3320)  train/rec_loss: 0.1043 (0.1501, 0.0968)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0196 (-0.0192, -0.0201)
2025-02-06 17:58:40,017 train INFO: [260/46609/10000]  lr: 2.6641000000000005e-05  eta: 0:21:30  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0203)  train/logits_fake: 0.0195 (0.0192, 0.0204)  train/total_loss: 23497.4883 (33670.0207, 26944.0332)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 9719.3662 (6678.2177, 12424.4297)  train/nll_loss: 23497.4766 (33670.0141, 26944.0215)  train/rec_loss: 0.1020 (0.1461, 0.1169)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0204)
2025-02-06 17:58:42,542 train INFO: [280/46609/10000]  lr: 2.8621000000000003e-05  eta: 0:21:23  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0180)  train/logits_fake: 0.0195 (0.0193, 0.0208)  train/total_loss: 23116.1816 (32817.0582, 21467.9395)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 11389.3555 (7130.7636, 12712.7334)  train/nll_loss: 23116.1738 (32817.0511, 21467.9258)  train/rec_loss: 0.1003 (0.1424, 0.0932)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0208)
2025-02-06 17:58:45,074 train INFO: [300/46609/10000]  lr: 3.0601e-05  eta: 0:21:17  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0193)  train/logits_fake: 0.0194 (0.0193, 0.0204)  train/total_loss: 22669.1699 (32113.7205, 22669.1699)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 12206.6328 (7519.3381, 13362.3398)  train/nll_loss: 22669.1562 (32113.7131, 22669.1562)  train/rec_loss: 0.0984 (0.1394, 0.0984)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0204)
2025-02-06 17:58:47,601 train INFO: [320/46609/10000]  lr: 3.2581e-05  eta: 0:21:11  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0189)  train/logits_fake: 0.0196 (0.0193, 0.0194)  train/total_loss: 22004.4551 (31379.8536, 21541.3867)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 12662.3701 (7952.4872, 14709.9326)  train/nll_loss: 22004.4414 (31379.8457, 21541.3711)  train/rec_loss: 0.0955 (0.1362, 0.0935)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0196 (-0.0193, -0.0194)
2025-02-06 17:58:50,130 train INFO: [340/46609/10000]  lr: 3.4561e-05  eta: 0:21:05  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0186)  train/logits_fake: 0.0196 (0.0193, 0.0185)  train/total_loss: 21552.1133 (30754.4903, 25682.2969)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 13174.1025 (8416.3105, 15138.9023)  train/nll_loss: 21552.1016 (30754.4819, 25682.2812)  train/rec_loss: 0.0935 (0.1335, 0.1115)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0197 (-0.0193, -0.0185)
2025-02-06 17:58:52,660 train INFO: [360/46609/10000]  lr: 3.6541e-05  eta: 0:21:00  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0194 (0.0192, 0.0176)  train/logits_fake: 0.0198 (0.0194, 0.0196)  train/total_loss: 21209.2305 (30268.7044, 26749.2812)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 14031.0908 (8759.3601, 14919.3594)  train/nll_loss: 21209.2129 (30268.6956, 26749.2656)  train/rec_loss: 0.0921 (0.1314, 0.1161)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0198 (-0.0194, -0.0196)
2025-02-06 17:58:55,190 train INFO: [380/46609/10000]  lr: 3.8521e-05  eta: 0:20:56  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0200)  train/logits_fake: 0.0198 (0.0193, 0.0213)  train/total_loss: 21552.1133 (29861.9654, 20117.6426)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 14791.6357 (9200.9965, 18734.4922)  train/nll_loss: 21552.1016 (29861.9562, 20117.6230)  train/rec_loss: 0.0935 (0.1296, 0.0873)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0198 (-0.0193, -0.0213)
2025-02-06 17:58:57,718 train INFO: [400/46609/10000]  lr: 4.0501000000000004e-05  eta: 0:20:51  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0167)  train/logits_fake: 0.0196 (0.0193, 0.0189)  train/total_loss: 20566.7480 (29375.2130, 21273.2266)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 15572.1367 (9660.8773, 20480.9609)  train/nll_loss: 20566.7324 (29375.2034, 21273.2070)  train/rec_loss: 0.0893 (0.1275, 0.0923)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0197 (-0.0193, -0.0189)
2025-02-06 17:59:00,243 train INFO: [420/46609/10000]  lr: 4.2481e-05  eta: 0:20:46  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0190)  train/logits_fake: 0.0197 (0.0193, 0.0187)  train/total_loss: 20359.4336 (28873.6881, 12956.6709)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 17215.5273 (10084.7648, 20392.9238)  train/nll_loss: 20359.4180 (28873.6780, 12956.6504)  train/rec_loss: 0.0884 (0.1253, 0.0562)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0197 (-0.0193, -0.0187)
2025-02-06 17:59:02,771 train INFO: [440/46609/10000]  lr: 4.4461e-05  eta: 0:20:42  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0203)  train/logits_fake: 0.0195 (0.0193, 0.0199)  train/total_loss: 20117.6426 (28420.4289, 12922.4443)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 17888.9375 (10501.4068, 19550.6406)  train/nll_loss: 20117.6230 (28420.4184, 12922.4248)  train/rec_loss: 0.0873 (0.1234, 0.0561)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0196 (-0.0193, -0.0199)
2025-02-06 17:59:05,300 train INFO: [460/46609/10000]  lr: 4.6441000000000005e-05  eta: 0:20:38  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0207)  train/logits_fake: 0.0195 (0.0194, 0.0194)  train/total_loss: 19797.8379 (28045.3003, 20229.4590)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 18683.3262 (10937.1360, 21015.8965)  train/nll_loss: 19797.8203 (28045.2894, 20229.4375)  train/rec_loss: 0.0859 (0.1217, 0.0878)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0194, -0.0194)
2025-02-06 17:59:07,828 train INFO: [480/46609/10000]  lr: 4.8421e-05  eta: 0:20:34  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0210)  train/logits_fake: 0.0195 (0.0194, 0.0197)  train/total_loss: 18767.3789 (27661.7147, 19107.9258)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 19306.7402 (11337.2910, 21100.7402)  train/nll_loss: 18767.3594 (27661.7034, 19107.9043)  train/rec_loss: 0.0815 (0.1201, 0.0829)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0194, -0.0197)
2025-02-06 17:59:10,356 train INFO: [500/46609/10000]  lr: 5.0401e-05  eta: 0:20:30  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0192)  train/logits_fake: 0.0195 (0.0194, 0.0191)  train/total_loss: 18193.1699 (27241.8612, 13313.2822)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 19699.9961 (11735.0940, 20199.9531)  train/nll_loss: 18193.1484 (27241.8495, 13313.2617)  train/rec_loss: 0.0790 (0.1182, 0.0578)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0196 (-0.0194, -0.0191)
2025-02-06 17:59:12,897 train INFO: [520/46609/10000]  lr: 5.2381000000000006e-05  eta: 0:20:27  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0193)  train/logits_fake: 0.0193 (0.0193, 0.0188)  train/total_loss: 18584.9668 (26933.3180, 20355.0059)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 20568.0645 (12100.1318, 21201.0039)  train/nll_loss: 18584.9473 (26933.3059, 20354.9844)  train/rec_loss: 0.0807 (0.1169, 0.0883)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0188)
2025-02-06 17:59:15,435 train INFO: [540/46609/10000]  lr: 5.4361000000000004e-05  eta: 0:20:23  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0187)  train/logits_fake: 0.0193 (0.0193, 0.0187)  train/total_loss: 18361.8867 (26607.0699, 16183.1172)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 21008.1582 (12430.4164, 23123.3047)  train/nll_loss: 18361.8672 (26607.0575, 16183.0938)  train/rec_loss: 0.0797 (0.1155, 0.0702)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0187)
2025-02-06 17:59:17,969 train INFO: [560/46609/10000]  lr: 5.6341e-05  eta: 0:20:20  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0180)  train/logits_fake: 0.0193 (0.0194, 0.0204)  train/total_loss: 18039.1230 (26321.1515, 17671.4785)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 21329.8047 (12784.5254, 22519.0840)  train/nll_loss: 18039.1016 (26321.1388, 17671.4551)  train/rec_loss: 0.0783 (0.1142, 0.0767)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0194, -0.0204)
2025-02-06 17:59:20,496 train INFO: [580/46609/10000]  lr: 5.8321000000000006e-05  eta: 0:20:16  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0195)  train/logits_fake: 0.0193 (0.0194, 0.0210)  train/total_loss: 18240.1309 (26078.2761, 21281.9297)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 21683.1855 (13099.4486, 19486.6426)  train/nll_loss: 18240.1094 (26078.2630, 21281.9102)  train/rec_loss: 0.0792 (0.1132, 0.0924)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0194, -0.0210)
2025-02-06 17:59:23,032 train INFO: [600/46609/10000]  lr: 6.0301000000000004e-05  eta: 0:20:13  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0184)  train/logits_fake: 0.0194 (0.0194, 0.0198)  train/total_loss: 18774.4648 (25868.4611, 22240.0723)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 21954.2852 (13441.3389, 27378.3340)  train/nll_loss: 18774.4414 (25868.4476, 22240.0449)  train/rec_loss: 0.0815 (0.1123, 0.0965)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0194, -0.0198)
2025-02-06 17:59:25,562 train INFO: [620/46609/10000]  lr: 6.228100000000001e-05  eta: 0:20:10  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0189)  train/logits_fake: 0.0196 (0.0194, 0.0195)  train/total_loss: 18240.1309 (25601.9641, 17193.3887)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 22529.8164 (13815.1199, 24622.6016)  train/nll_loss: 18240.1094 (25601.9503, 17193.3633)  train/rec_loss: 0.0792 (0.1111, 0.0746)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0196 (-0.0194, -0.0195)
2025-02-06 17:59:28,097 train INFO: [640/46609/10000]  lr: 6.4261e-05  eta: 0:20:06  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0175)  train/logits_fake: 0.0196 (0.0194, 0.0194)  train/total_loss: 18769.9766 (25438.3600, 17668.0098)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 23667.5391 (14228.3368, 31310.9609)  train/nll_loss: 18769.9531 (25438.3457, 17667.9785)  train/rec_loss: 0.0815 (0.1104, 0.0767)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0196 (-0.0194, -0.0194)
2025-02-06 17:59:30,627 train INFO: [660/46609/10000]  lr: 6.6241e-05  eta: 0:20:03  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0195)  train/logits_fake: 0.0195 (0.0194, 0.0196)  train/total_loss: 18643.9082 (25223.8394, 20326.0820)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 24449.5996 (14596.5965, 28118.8008)  train/nll_loss: 18643.8828 (25223.8248, 20326.0547)  train/rec_loss: 0.0809 (0.1095, 0.0882)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0194, -0.0196)
2025-02-06 17:59:33,165 train INFO: [680/46609/10000]  lr: 6.822100000000001e-05  eta: 0:20:00  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0187)  train/logits_fake: 0.0196 (0.0194, 0.0196)  train/total_loss: 18108.8203 (25000.9296, 23282.2051)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 25649.2930 (14951.1507, 27781.8281)  train/nll_loss: 18108.7891 (25000.9146, 23282.1777)  train/rec_loss: 0.0786 (0.1085, 0.1011)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0196 (-0.0194, -0.0196)
2025-02-06 17:59:35,703 train INFO: [700/46609/10000]  lr: 7.0201e-05  eta: 0:19:57  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0190)  train/logits_fake: 0.0195 (0.0194, 0.0189)  train/total_loss: 17668.0098 (24765.5469, 16686.1074)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 26177.4844 (15279.6021, 25254.8047)  train/nll_loss: 17667.9785 (24765.5316, 16686.0820)  train/rec_loss: 0.0767 (0.1075, 0.0724)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0194, -0.0189)
2025-02-06 17:59:38,234 train INFO: [720/46609/10000]  lr: 7.2181e-05  eta: 0:19:54  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0213)  train/logits_fake: 0.0195 (0.0194, 0.0202)  train/total_loss: 17655.6660 (24530.1465, 17295.7617)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 26418.2773 (15619.7318, 27435.4199)  train/nll_loss: 17655.6387 (24530.1309, 17295.7344)  train/rec_loss: 0.0766 (0.1065, 0.0751)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0194, -0.0202)
2025-02-06 17:59:40,766 train INFO: [740/46609/10000]  lr: 7.416100000000001e-05  eta: 0:19:51  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0155)  train/logits_fake: 0.0195 (0.0194, 0.0190)  train/total_loss: 17602.4727 (24384.9610, 19007.0176)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 26794.5703 (15959.1552, 31340.1211)  train/nll_loss: 17602.4473 (24384.9450, 19006.9863)  train/rec_loss: 0.0764 (0.1058, 0.0825)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0194, -0.0190)
2025-02-06 17:59:43,300 train INFO: [760/46609/10000]  lr: 7.6141e-05  eta: 0:19:48  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0185)  train/logits_fake: 0.0195 (0.0194, 0.0188)  train/total_loss: 17555.5547 (24219.1603, 24248.2422)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 27435.4199 (16355.0411, 31549.9492)  train/nll_loss: 17555.5293 (24219.1440, 24248.2109)  train/rec_loss: 0.0762 (0.1051, 0.1052)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0194, -0.0188)
2025-02-06 17:59:45,831 train INFO: [780/46609/10000]  lr: 7.8121e-05  eta: 0:19:45  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0188)  train/logits_fake: 0.0194 (0.0194, 0.0188)  train/total_loss: 17655.6660 (24063.1702, 20626.3281)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 28795.8477 (16753.3669, 24607.3281)  train/nll_loss: 17655.6387 (24063.1535, 20626.3027)  train/rec_loss: 0.0766 (0.1044, 0.0895)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0194, -0.0188)
2025-02-06 17:59:48,360 train INFO: [800/46609/10000]  lr: 8.010100000000001e-05  eta: 0:19:42  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0160)  train/logits_fake: 0.0193 (0.0194, 0.0193)  train/total_loss: 18043.7793 (23927.8629, 19276.6406)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 29931.4141 (17143.8776, 31383.6211)  train/nll_loss: 18043.7500 (23927.8458, 19276.6094)  train/rec_loss: 0.0783 (0.1039, 0.0837)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0194, -0.0193)
2025-02-06 17:59:50,891 train INFO: [820/46609/10000]  lr: 8.2081e-05  eta: 0:19:39  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0200)  train/logits_fake: 0.0193 (0.0194, 0.0200)  train/total_loss: 18021.5996 (23760.1738, 15890.8105)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 30756.9258 (17491.0453, 31001.6074)  train/nll_loss: 18021.5645 (23760.1563, 15890.7793)  train/rec_loss: 0.0782 (0.1031, 0.0690)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0194, -0.0200)
2025-02-06 17:59:53,420 train INFO: [840/46609/10000]  lr: 8.406100000000001e-05  eta: 0:19:36  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0194)  train/logits_fake: 0.0193 (0.0194, 0.0186)  train/total_loss: 17562.9336 (23594.2982, 22847.5098)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 32213.6250 (17986.1206, 34389.1562)  train/nll_loss: 17562.9043 (23594.2802, 22847.4746)  train/rec_loss: 0.0762 (0.1024, 0.0992)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0194, -0.0186)
2025-02-06 17:59:55,953 train INFO: [860/46609/10000]  lr: 8.604100000000001e-05  eta: 0:19:33  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0199)  train/logits_fake: 0.0193 (0.0194, 0.0208)  train/total_loss: 17148.4824 (23423.6165, 17450.9473)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 32918.1055 (18375.1599, 32760.9766)  train/nll_loss: 17148.4531 (23423.5981, 17450.9141)  train/rec_loss: 0.0744 (0.1017, 0.0757)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0194, -0.0208)
2025-02-06 17:59:58,485 train INFO: [880/46609/10000]  lr: 8.8021e-05  eta: 0:19:30  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0201)  train/logits_fake: 0.0192 (0.0194, 0.0188)  train/total_loss: 16716.5352 (23279.2479, 11643.7285)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 33746.0508 (18742.8491, 29372.0332)  train/nll_loss: 16716.5000 (23279.2292, 11643.6992)  train/rec_loss: 0.0726 (0.1010, 0.0505)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0194, -0.0188)
2025-02-06 18:00:01,023 train INFO: [900/46609/10000]  lr: 9.000100000000001e-05  eta: 0:19:27  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0186)  train/logits_fake: 0.0194 (0.0194, 0.0194)  train/total_loss: 16445.4473 (23133.6136, 14435.0029)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 33916.5195 (19078.6407, 26049.1309)  train/nll_loss: 16445.4121 (23133.5945, 14434.9766)  train/rec_loss: 0.0714 (0.1004, 0.0627)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0194, -0.0194)
2025-02-06 18:00:03,558 train INFO: [920/46609/10000]  lr: 9.198100000000001e-05  eta: 0:19:24  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0194)  train/logits_fake: 0.0193 (0.0194, 0.0190)  train/total_loss: 16569.2246 (23007.8049, 13228.4746)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 34017.0742 (19332.7122, 31526.1465)  train/nll_loss: 16569.1875 (23007.7856, 13228.4434)  train/rec_loss: 0.0719 (0.0999, 0.0574)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0194, -0.0190)
2025-02-06 18:00:06,094 train INFO: [940/46609/10000]  lr: 9.3961e-05  eta: 0:19:21  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0177)  train/logits_fake: 0.0194 (0.0194, 0.0185)  train/total_loss: 16745.1875 (22895.9408, 15381.5635)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 33766.9844 (19687.1010, 39862.5664)  train/nll_loss: 16745.1582 (22895.9211, 15381.5234)  train/rec_loss: 0.0727 (0.0994, 0.0668)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0194, -0.0185)
2025-02-06 18:00:08,627 train INFO: [960/46609/10000]  lr: 9.594100000000001e-05  eta: 0:19:18  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0183)  train/logits_fake: 0.0194 (0.0194, 0.0202)  train/total_loss: 16745.1875 (22762.6201, 15105.4648)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 34210.0234 (20235.9619, 46931.8281)  train/nll_loss: 16745.1582 (22762.5999, 15105.4180)  train/rec_loss: 0.0727 (0.0988, 0.0656)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0194, -0.0202)
2025-02-06 18:00:11,158 train INFO: [980/46609/10000]  lr: 9.792100000000001e-05  eta: 0:19:15  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0190)  train/logits_fake: 0.0196 (0.0194, 0.0199)  train/total_loss: 16622.1973 (22621.8842, 15227.3262)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 35905.2383 (20891.4307, 37573.7344)  train/nll_loss: 16622.1602 (22621.8633, 15227.2891)  train/rec_loss: 0.0721 (0.0982, 0.0661)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0196 (-0.0194, -0.0199)
2025-02-06 18:00:13,698 train INFO: [1000/46609/10000]  lr: 9.9901e-05  eta: 0:19:13  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0190)  train/logits_fake: 0.0194 (0.0194, 0.0200)  train/total_loss: 16178.5508 (22477.4251, 16858.1543)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 39796.5078 (21304.0411, 37517.5273)  train/nll_loss: 16178.5156 (22477.4038, 16858.1172)  train/rec_loss: 0.0702 (0.0976, 0.0732)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0194, -0.0200)
2025-02-06 18:00:16,238 train INFO: [1020/46609/10000]  lr: 9.98985773520711e-05  eta: 0:19:10  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0202)  train/logits_fake: 0.0195 (0.0194, 0.0212)  train/total_loss: 15907.1406 (22330.6520, 16357.6670)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 42634.0391 (21706.0296, 44221.4609)  train/nll_loss: 15907.1035 (22330.6303, 16357.6230)  train/rec_loss: 0.0690 (0.0969, 0.0710)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0194, -0.0212)
2025-02-06 18:00:18,778 train INFO: [1040/46609/10000]  lr: 9.989455844775029e-05  eta: 0:19:07  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0180)  train/logits_fake: 0.0192 (0.0194, 0.0193)  train/total_loss: 15227.3262 (22188.7181, 18052.6875)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 43638.6641 (22135.0405, 43105.5664)  train/nll_loss: 15227.2891 (22188.6960, 18052.6445)  train/rec_loss: 0.0661 (0.0963, 0.0784)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0194, -0.0193)
2025-02-06 18:00:21,327 train INFO: [1060/46609/10000]  lr: 9.989046154267949e-05  eta: 0:19:04  iter_time: 0.128  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0212)  train/logits_fake: 0.0193 (0.0194, 0.0206)  train/total_loss: 15227.3262 (22085.2994, 19982.4277)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 44584.1641 (22665.4745, 51962.4062)  train/nll_loss: 15227.2891 (22085.2768, 19982.3750)  train/rec_loss: 0.0661 (0.0959, 0.0867)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0194, -0.0206)
2025-02-06 18:00:23,871 train INFO: [1080/46609/10000]  lr: 9.98862866433283e-05  eta: 0:19:02  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0174)  train/logits_fake: 0.0192 (0.0194, 0.0191)  train/total_loss: 15205.0000 (21956.5734, 14009.3145)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 44316.6875 (23084.0927, 41766.5742)  train/nll_loss: 15204.9551 (21956.5503, 14009.2725)  train/rec_loss: 0.0660 (0.0953, 0.0608)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0194, -0.0191)
2025-02-06 18:00:26,405 train INFO: [1100/46609/10000]  lr: 9.988203375628945e-05  eta: 0:18:59  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0182)  train/logits_fake: 0.0192 (0.0194, 0.0208)  train/total_loss: 15232.5498 (21832.2033, 18021.6738)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 44837.7070 (23522.2543, 51457.2656)  train/nll_loss: 15232.4980 (21832.1797, 18021.6230)  train/rec_loss: 0.0661 (0.0948, 0.0782)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0194, -0.0208)
2025-02-06 18:00:28,940 train INFO: [1120/46609/10000]  lr: 9.987770288827884e-05  eta: 0:18:56  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0190)  train/logits_fake: 0.0192 (0.0194, 0.0202)  train/total_loss: 14988.0879 (21694.6993, 12946.6348)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 45742.5078 (23961.9987, 43338.4922)  train/nll_loss: 14988.0332 (21694.6754, 12946.5918)  train/rec_loss: 0.0651 (0.0942, 0.0562)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0194, -0.0202)
2025-02-06 18:00:31,475 train INFO: [1140/46609/10000]  lr: 9.987329404613549e-05  eta: 0:18:53  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0200)  train/logits_fake: 0.0194 (0.0194, 0.0212)  train/total_loss: 15109.6377 (21579.8973, 17303.4355)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 47230.5859 (24433.4685, 49490.5547)  train/nll_loss: 15109.5820 (21579.8728, 17303.3867)  train/rec_loss: 0.0656 (0.0937, 0.0751)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0194, -0.0212)
2025-02-06 18:00:34,020 train INFO: [1160/46609/10000]  lr: 9.986880723682156e-05  eta: 0:18:51  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0214)  train/logits_fake: 0.0192 (0.0194, 0.0210)  train/total_loss: 14088.1934 (21453.8064, 13596.9570)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 48579.4688 (24917.5596, 47403.4102)  train/nll_loss: 14088.1387 (21453.7815, 13596.9092)  train/rec_loss: 0.0611 (0.0931, 0.0590)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0194, -0.0210)
2025-02-06 18:00:36,556 train INFO: [1180/46609/10000]  lr: 9.986424246742235e-05  eta: 0:18:48  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0190)  train/logits_fake: 0.0191 (0.0194, 0.0189)  train/total_loss: 13974.0068 (21322.8999, 9358.3330)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 50330.4219 (25412.4405, 38129.6250)  train/nll_loss: 13973.9609 (21322.8745, 9358.2949)  train/rec_loss: 0.0607 (0.0925, 0.0406)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0194, -0.0189)
2025-02-06 18:00:39,097 train INFO: [1200/46609/10000]  lr: 9.985959974514624e-05  eta: 0:18:45  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0187)  train/logits_fake: 0.0193 (0.0194, 0.0196)  train/total_loss: 13888.5684 (21199.4591, 11892.9287)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 50330.4219 (25812.4857, 54325.7500)  train/nll_loss: 13888.5117 (21199.4333, 11892.8740)  train/rec_loss: 0.0603 (0.0920, 0.0516)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0194, -0.0196)
2025-02-06 18:00:41,639 train INFO: [1220/46609/10000]  lr: 9.985487907732471e-05  eta: 0:18:43  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0193)  train/logits_fake: 0.0192 (0.0194, 0.0199)  train/total_loss: 13799.6475 (21077.1823, 14170.0654)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 52064.7305 (26307.6564, 49825.5078)  train/nll_loss: 13799.5986 (21077.1560, 14170.0156)  train/rec_loss: 0.0599 (0.0915, 0.0615)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0194, -0.0199)
2025-02-06 18:00:44,170 train INFO: [1240/46609/10000]  lr: 9.985008047141237e-05  eta: 0:18:40  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0182)  train/logits_fake: 0.0193 (0.0194, 0.0193)  train/total_loss: 12985.4102 (20929.3050, 10813.5039)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 52643.5273 (26738.5481, 49005.7500)  train/nll_loss: 12985.3535 (20929.2782, 10813.4551)  train/rec_loss: 0.0564 (0.0908, 0.0469)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0194, -0.0193)
2025-02-06 18:00:46,711 train INFO: [1260/46609/10000]  lr: 9.984520393498686e-05  eta: 0:18:37  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0226)  train/logits_fake: 0.0193 (0.0193, 0.0212)  train/total_loss: 12985.4102 (20818.5293, 19063.0000)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 53347.7891 (27155.0869, 43935.4141)  train/nll_loss: 12985.3535 (20818.5022, 19062.9570)  train/rec_loss: 0.0564 (0.0904, 0.0827)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0212)
2025-02-06 18:00:49,241 train INFO: [1280/46609/10000]  lr: 9.98402494757489e-05  eta: 0:18:34  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0196)  train/logits_fake: 0.0193 (0.0193, 0.0190)  train/total_loss: 13286.6143 (20719.3196, 14584.4863)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 52064.7305 (27570.5700, 65987.5938)  train/nll_loss: 13286.5635 (20719.2921, 14584.4199)  train/rec_loss: 0.0577 (0.0899, 0.0633)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0190)
2025-02-06 18:00:51,772 train INFO: [1300/46609/10000]  lr: 9.983521710152225e-05  eta: 0:18:32  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0195)  train/logits_fake: 0.0193 (0.0193, 0.0199)  train/total_loss: 13171.6113 (20604.7817, 13220.1084)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 53402.7109 (27990.1351, 57336.0898)  train/nll_loss: 13171.5537 (20604.7537, 13220.0508)  train/rec_loss: 0.0572 (0.0894, 0.0574)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0199)
2025-02-06 18:00:54,305 train INFO: [1320/46609/10000]  lr: 9.983010682025372e-05  eta: 0:18:29  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0206)  train/logits_fake: 0.0194 (0.0194, 0.0198)  train/total_loss: 12918.7793 (20482.0596, 13285.4463)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 53207.7227 (28408.1753, 53820.9492)  train/nll_loss: 12918.7217 (20482.0312, 13285.3926)  train/rec_loss: 0.0561 (0.0889, 0.0577)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0194, -0.0198)
2025-02-06 18:00:56,838 train INFO: [1340/46609/10000]  lr: 9.982491864001312e-05  eta: 0:18:26  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0181)  train/logits_fake: 0.0195 (0.0194, 0.0200)  train/total_loss: 13400.4033 (20393.6443, 18059.5195)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 53273.1406 (28810.5967, 61377.5391)  train/nll_loss: 13400.3506 (20393.6155, 18059.4590)  train/rec_loss: 0.0582 (0.0885, 0.0784)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0196 (-0.0194, -0.0200)
2025-02-06 18:00:59,369 train INFO: [1360/46609/10000]  lr: 9.981965256899335e-05  eta: 0:18:24  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0194 (0.0191, 0.0182)  train/logits_fake: 0.0195 (0.0194, 0.0179)  train/total_loss: 13153.9111 (20296.6600, 17930.9551)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 53649.2852 (29228.6997, 56136.1172)  train/nll_loss: 13153.8486 (20296.6308, 17930.8984)  train/rec_loss: 0.0571 (0.0881, 0.0778)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0194, -0.0179)
2025-02-06 18:01:01,900 train INFO: [1380/46609/10000]  lr: 9.981430861551019e-05  eta: 0:18:21  iter_time: 0.126  data: 0.001  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0195 (0.0191, 0.0194)  train/logits_fake: 0.0196 (0.0194, 0.0192)  train/total_loss: 12901.9990 (20191.0416, 10677.6396)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 55484.9062 (29696.0299, 61576.0312)  train/nll_loss: 12901.9248 (20191.0119, 10677.5781)  train/rec_loss: 0.0560 (0.0876, 0.0463)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0196 (-0.0194, -0.0192)
2025-02-06 18:01:04,429 train INFO: [1400/46609/10000]  lr: 9.980888678800252e-05  eta: 0:18:18  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0183)  train/logits_fake: 0.0195 (0.0193, 0.0178)  train/total_loss: 13149.1982 (20109.1019, 11728.2158)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 56579.1602 (30144.8320, 71448.5938)  train/nll_loss: 13149.1270 (20109.0718, 11728.1445)  train/rec_loss: 0.0571 (0.0873, 0.0509)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0178)
2025-02-06 18:01:06,958 train INFO: [1420/46609/10000]  lr: 9.980338709503211e-05  eta: 0:18:15  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0214)  train/logits_fake: 0.0194 (0.0193, 0.0199)  train/total_loss: 13609.5918 (20015.9647, 12318.6396)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 57773.8516 (30559.6560, 61126.1016)  train/nll_loss: 13609.5371 (20015.9341, 12318.5781)  train/rec_loss: 0.0591 (0.0869, 0.0535)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0199)
2025-02-06 18:01:09,489 train INFO: [1440/46609/10000]  lr: 9.979780954528376e-05  eta: 0:18:13  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0189)  train/logits_fake: 0.0191 (0.0193, 0.0185)  train/total_loss: 13121.5693 (19912.8739, 11718.7305)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 60486.4727 (30991.5418, 67057.3359)  train/nll_loss: 13121.5176 (19912.8429, 11718.6631)  train/rec_loss: 0.0570 (0.0864, 0.0509)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0185)
2025-02-06 18:01:12,017 train INFO: [1460/46609/10000]  lr: 9.979215414756515e-05  eta: 0:18:10  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0186)  train/logits_fake: 0.0191 (0.0193, 0.0185)  train/total_loss: 12912.3916 (19817.2562, 11421.4287)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 61340.1328 (31451.7704, 71901.0625)  train/nll_loss: 12912.3281 (19817.2247, 11421.3564)  train/rec_loss: 0.0560 (0.0860, 0.0496)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0185)
2025-02-06 18:01:14,554 train INFO: [1480/46609/10000]  lr: 9.978642091080696e-05  eta: 0:18:07  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0188 (0.0191, 0.0180)  train/logits_fake: 0.0190 (0.0193, 0.0180)  train/total_loss: 12465.6611 (19716.6631, 15880.8037)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 61340.1328 (31864.3823, 65362.2344)  train/nll_loss: 12465.6074 (19716.6313, 15880.7383)  train/rec_loss: 0.0541 (0.0856, 0.0689)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0180)
2025-02-06 18:01:17,097 train INFO: [1500/46609/10000]  lr: 9.978060984406272e-05  eta: 0:18:05  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0183)  train/logits_fake: 0.0191 (0.0193, 0.0193)  train/total_loss: 12240.8154 (19617.0851, 10345.9668)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 61260.1797 (32262.8420, 64680.4688)  train/nll_loss: 12240.7578 (19617.0529, 10345.9023)  train/rec_loss: 0.0531 (0.0851, 0.0449)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0193)
2025-02-06 18:01:19,626 train INFO: [1520/46609/10000]  lr: 9.977472095650893e-05  eta: 0:18:02  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0201)  train/logits_fake: 0.0191 (0.0193, 0.0198)  train/total_loss: 12008.2686 (19534.0360, 14688.7725)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 61811.3281 (32654.6721, 67315.7188)  train/nll_loss: 12008.1973 (19534.0034, 14688.7051)  train/rec_loss: 0.0521 (0.0848, 0.0638)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0198)
2025-02-06 18:01:22,160 train INFO: [1540/46609/10000]  lr: 9.976875425744491e-05  eta: 0:17:59  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0188 (0.0191, 0.0173)  train/logits_fake: 0.0191 (0.0193, 0.0185)  train/total_loss: 12129.6123 (19450.0794, 9749.6572)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 63637.4375 (33101.0133, 49818.8594)  train/nll_loss: 12129.5576 (19450.0463, 9749.6074)  train/rec_loss: 0.0526 (0.0844, 0.0423)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0185)
2025-02-06 18:01:24,696 train INFO: [1560/46609/10000]  lr: 9.976270975629292e-05  eta: 0:17:57  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0192)  train/logits_fake: 0.0191 (0.0193, 0.0190)  train/total_loss: 12346.7500 (19353.6931, 10890.5791)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 63083.3672 (33524.9963, 61194.3438)  train/nll_loss: 12346.6787 (19353.6596, 10890.5176)  train/rec_loss: 0.0536 (0.0840, 0.0473)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0190)
2025-02-06 18:01:27,229 train INFO: [1580/46609/10000]  lr: 9.975658746259806e-05  eta: 0:17:54  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0184)  train/logits_fake: 0.0192 (0.0193, 0.0187)  train/total_loss: 12383.6377 (19274.3560, 12172.4023)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 63637.4375 (33996.0278, 64264.8906)  train/nll_loss: 12383.5596 (19274.3220, 12172.3379)  train/rec_loss: 0.0537 (0.0837, 0.0528)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0187)
2025-02-06 18:01:29,753 train INFO: [1600/46609/10000]  lr: 9.975038738602823e-05  eta: 0:17:51  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0206)  train/logits_fake: 0.0192 (0.0193, 0.0205)  train/total_loss: 12761.6016 (19206.2517, 9861.1504)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 64855.8594 (34397.7912, 53880.0664)  train/nll_loss: 12761.5449 (19206.2173, 9861.0967)  train/rec_loss: 0.0554 (0.0834, 0.0428)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0205)
2025-02-06 18:01:32,287 train INFO: [1620/46609/10000]  lr: 9.974410953637422e-05  eta: 0:17:49  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0188 (0.0191, 0.0189)  train/logits_fake: 0.0190 (0.0193, 0.0183)  train/total_loss: 12823.9443 (19134.4868, 10623.5332)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 65026.3828 (34747.2159, 70449.7188)  train/nll_loss: 12823.8711 (19134.4521, 10623.4629)  train/rec_loss: 0.0557 (0.0830, 0.0461)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0193, -0.0183)
2025-02-06 18:01:34,814 train INFO: [1640/46609/10000]  lr: 9.97377539235496e-05  eta: 0:17:46  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0192)  train/logits_fake: 0.0190 (0.0193, 0.0202)  train/total_loss: 12570.7383 (19052.7668, 10776.0293)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 63369.0312 (35054.8069, 48785.8359)  train/nll_loss: 12570.6738 (19052.7317, 10775.9805)  train/rec_loss: 0.0546 (0.0827, 0.0468)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0193, -0.0202)
2025-02-06 18:01:37,343 train INFO: [1660/46609/10000]  lr: 9.973132055759078e-05  eta: 0:17:43  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0197)  train/logits_fake: 0.0190 (0.0193, 0.0195)  train/total_loss: 12699.0352 (18964.2144, 11137.7451)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 63279.5000 (35383.0424, 57721.8516)  train/nll_loss: 12698.9639 (18964.1790, 11137.6875)  train/rec_loss: 0.0551 (0.0823, 0.0483)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0193, -0.0195)
2025-02-06 18:01:39,873 train INFO: [1680/46609/10000]  lr: 9.97248094486569e-05  eta: 0:17:41  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0188)  train/logits_fake: 0.0191 (0.0193, 0.0180)  train/total_loss: 11790.3213 (18865.4609, 15277.6475)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 62918.5625 (35700.0434, 81073.3906)  train/nll_loss: 11790.2480 (18865.4252, 15277.5664)  train/rec_loss: 0.0512 (0.0819, 0.0663)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0180)
2025-02-06 18:01:42,399 train INFO: [1700/46609/10000]  lr: 9.971822060702989e-05  eta: 0:17:38  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0186)  train/logits_fake: 0.0192 (0.0193, 0.0192)  train/total_loss: 11276.1270 (18781.9464, 14180.5322)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 62641.7734 (36035.2100, 85263.7969)  train/nll_loss: 11276.0645 (18781.9104, 14180.4473)  train/rec_loss: 0.0489 (0.0815, 0.0615)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0192)
2025-02-06 18:01:44,924 train INFO: [1720/46609/10000]  lr: 9.971155404311443e-05  eta: 0:17:35  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0180)  train/logits_fake: 0.0193 (0.0193, 0.0189)  train/total_loss: 11247.3701 (18704.3516, 10491.8623)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 62146.8906 (36384.6987, 69151.5312)  train/nll_loss: 11247.2930 (18704.3153, 10491.7930)  train/rec_loss: 0.0488 (0.0812, 0.0455)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0189)
2025-02-06 18:01:47,450 train INFO: [1740/46609/10000]  lr: 9.970480976743792e-05  eta: 0:17:33  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0169)  train/logits_fake: 0.0193 (0.0193, 0.0182)  train/total_loss: 11022.1074 (18621.2523, 14447.5947)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 62918.5625 (36721.3389, 51137.8789)  train/nll_loss: 11022.0342 (18621.2156, 14447.5439)  train/rec_loss: 0.0478 (0.0808, 0.0627)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0182)
2025-02-06 18:01:49,976 train INFO: [1760/46609/10000]  lr: 9.969798779065054e-05  eta: 0:17:30  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0191)  train/logits_fake: 0.0192 (0.0193, 0.0192)  train/total_loss: 11004.2188 (18547.8904, 9995.9727)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 63001.7109 (37042.0951, 64612.2930)  train/nll_loss: 11004.1572 (18547.8533, 9995.9082)  train/rec_loss: 0.0478 (0.0805, 0.0434)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0192)
2025-02-06 18:01:52,507 train INFO: [1780/46609/10000]  lr: 9.969108812352508e-05  eta: 0:17:27  iter_time: 0.127  data: 0.001  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0187)  train/logits_fake: 0.0191 (0.0193, 0.0188)  train/total_loss: 11430.9082 (18479.3338, 12398.7695)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 64768.0312 (37387.2519, 72617.6250)  train/nll_loss: 11430.8457 (18479.2965, 12398.6973)  train/rec_loss: 0.0496 (0.0802, 0.0538)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0188)
2025-02-06 18:01:55,036 train INFO: [1800/46609/10000]  lr: 9.968411077695707e-05  eta: 0:17:25  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0179)  train/logits_fake: 0.0190 (0.0193, 0.0178)  train/total_loss: 11242.0254 (18388.4104, 12496.6768)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 66203.1094 (37713.0256, 69806.5469)  train/nll_loss: 11241.9590 (18388.3727, 12496.6074)  train/rec_loss: 0.0488 (0.0798, 0.0542)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0178)
2025-02-06 18:01:57,566 train INFO: [1820/46609/10000]  lr: 9.96770557619647e-05  eta: 0:17:22  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0193)  train/logits_fake: 0.0191 (0.0193, 0.0193)  train/total_loss: 11242.0254 (18327.7336, 9308.5059)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 65845.6328 (38032.6202, 65105.1328)  train/nll_loss: 11241.9590 (18327.6956, 9308.4404)  train/rec_loss: 0.0488 (0.0795, 0.0404)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0193)
2025-02-06 18:02:00,096 train INFO: [1840/46609/10000]  lr: 9.966992308968878e-05  eta: 0:17:20  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0202)  train/logits_fake: 0.0192 (0.0193, 0.0215)  train/total_loss: 11604.9707 (18260.8706, 16391.0547)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 65845.6328 (38325.0438, 66200.0469)  train/nll_loss: 11604.8965 (18260.8323, 16390.9883)  train/rec_loss: 0.0504 (0.0793, 0.0711)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0215)
2025-02-06 18:02:02,625 train INFO: [1860/46609/10000]  lr: 9.966271277139278e-05  eta: 0:17:17  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0196)  train/logits_fake: 0.0192 (0.0193, 0.0189)  train/total_loss: 11639.3535 (18205.0675, 11034.8018)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 67343.9062 (38702.2029, 63891.9609)  train/nll_loss: 11639.2812 (18205.0288, 11034.7383)  train/rec_loss: 0.0505 (0.0790, 0.0479)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0189)
2025-02-06 18:02:05,151 train INFO: [1880/46609/10000]  lr: 9.965542481846279e-05  eta: 0:17:14  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0196)  train/logits_fake: 0.0192 (0.0193, 0.0207)  train/total_loss: 11472.3086 (18132.5756, 11369.2197)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 66307.9062 (38989.2256, 57679.6367)  train/nll_loss: 11472.2383 (18132.5366, 11369.1621)  train/rec_loss: 0.0498 (0.0787, 0.0493)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0207)
2025-02-06 18:02:07,680 train INFO: [1900/46609/10000]  lr: 9.964805924240748e-05  eta: 0:17:12  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0187)  train/logits_fake: 0.0192 (0.0193, 0.0191)  train/total_loss: 11892.7256 (18069.1507, 13745.1553)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 67692.6875 (39319.1136, 67692.6875)  train/nll_loss: 11892.6621 (18069.1114, 13745.0879)  train/rec_loss: 0.0516 (0.0784, 0.0597)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0191)
2025-02-06 18:02:10,209 train INFO: [1920/46609/10000]  lr: 9.964061605485808e-05  eta: 0:17:09  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0210)  train/logits_fake: 0.0191 (0.0193, 0.0203)  train/total_loss: 11355.2334 (17987.0405, 9835.9141)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 68176.8984 (39642.1445, 57448.0000)  train/nll_loss: 11355.1680 (17987.0008, 9835.8564)  train/rec_loss: 0.0493 (0.0781, 0.0427)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0203)
2025-02-06 18:02:12,737 train INFO: [1940/46609/10000]  lr: 9.963309526756842e-05  eta: 0:17:06  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0200)  train/logits_fake: 0.0192 (0.0193, 0.0212)  train/total_loss: 11199.5801 (17915.3924, 14117.5703)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 68920.5938 (39953.0053, 80258.4062)  train/nll_loss: 11199.5059 (17915.3524, 14117.4902)  train/rec_loss: 0.0486 (0.0778, 0.0613)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0212)
2025-02-06 18:02:15,270 train INFO: [1960/46609/10000]  lr: 9.962549689241485e-05  eta: 0:17:04  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0209)  train/logits_fake: 0.0192 (0.0193, 0.0208)  train/total_loss: 10943.2539 (17849.5522, 9979.0186)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 68645.9844 (40267.3991, 65070.2656)  train/nll_loss: 10943.1846 (17849.5119, 9978.9531)  train/rec_loss: 0.0475 (0.0775, 0.0433)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0208)
2025-02-06 18:02:17,802 train INFO: [1980/46609/10000]  lr: 9.961782094139623e-05  eta: 0:17:01  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0203)  train/logits_fake: 0.0194 (0.0193, 0.0195)  train/total_loss: 11250.6396 (17789.1663, 10487.0215)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 70102.2969 (40569.2809, 63338.8398)  train/nll_loss: 11250.5615 (17789.1258, 10486.9580)  train/rec_loss: 0.0488 (0.0772, 0.0455)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0195)
2025-02-06 18:02:20,335 train INFO: [2000/46609/10000]  lr: 9.961006742663394e-05  eta: 0:16:59  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0176)  train/logits_fake: 0.0194 (0.0193, 0.0172)  train/total_loss: 10780.2822 (17722.3281, 9878.2129)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 70892.3828 (40905.2197, 77679.7188)  train/nll_loss: 10780.2148 (17722.2872, 9878.1348)  train/rec_loss: 0.0468 (0.0769, 0.0429)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0172)
2025-02-06 18:02:22,865 train INFO: [2020/46609/10000]  lr: 9.960223636037184e-05  eta: 0:16:56  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0190)  train/logits_fake: 0.0194 (0.0193, 0.0197)  train/total_loss: 10997.8828 (17657.2955, 10601.0449)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 71132.0469 (41242.3843, 55163.2656)  train/nll_loss: 10997.8125 (17657.2542, 10600.9902)  train/rec_loss: 0.0477 (0.0766, 0.0460)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0197)
2025-02-06 18:02:25,394 train INFO: [2040/46609/10000]  lr: 9.959432775497624e-05  eta: 0:16:53  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0191)  train/logits_fake: 0.0194 (0.0193, 0.0189)  train/total_loss: 10943.2539 (17592.6456, 9379.8428)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 70892.3828 (41524.3339, 69959.3984)  train/nll_loss: 10943.1846 (17592.6041, 9379.7725)  train/rec_loss: 0.0475 (0.0764, 0.0407)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0189)
2025-02-06 18:02:27,919 train INFO: [2060/46609/10000]  lr: 9.958634162293593e-05  eta: 0:16:51  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0188)  train/logits_fake: 0.0193 (0.0193, 0.0192)  train/total_loss: 10754.0615 (17526.7352, 9796.8340)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 70936.9062 (41795.7365, 81182.6406)  train/nll_loss: 10753.9922 (17526.6934, 9796.7529)  train/rec_loss: 0.0467 (0.0761, 0.0425)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0192)
2025-02-06 18:02:30,447 train INFO: [2080/46609/10000]  lr: 9.95782779768621e-05  eta: 0:16:48  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0186)  train/logits_fake: 0.0193 (0.0193, 0.0204)  train/total_loss: 10426.8672 (17464.4499, 15857.1240)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 72425.1562 (42105.4671, 81301.8906)  train/nll_loss: 10426.7754 (17464.4078, 15857.0430)  train/rec_loss: 0.0453 (0.0758, 0.0688)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0204)
2025-02-06 18:02:32,978 train INFO: [2100/46609/10000]  lr: 9.95701368294883e-05  eta: 0:16:45  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0192)  train/logits_fake: 0.0195 (0.0193, 0.0192)  train/total_loss: 10601.0449 (17411.4283, 9798.1826)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 71993.9922 (42399.0164, 63356.2969)  train/nll_loss: 10600.9902 (17411.3860, 9798.1191)  train/rec_loss: 0.0460 (0.0756, 0.0425)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0192)
2025-02-06 18:02:35,514 train INFO: [2120/46609/10000]  lr: 9.956191819367058e-05  eta: 0:16:43  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0181)  train/logits_fake: 0.0195 (0.0193, 0.0198)  train/total_loss: 10793.6514 (17359.3829, 16091.0352)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 71993.9922 (42721.5516, 70460.0703)  train/nll_loss: 10793.5781 (17359.3402, 16090.9648)  train/rec_loss: 0.0468 (0.0753, 0.0698)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0198)
2025-02-06 18:02:38,053 train INFO: [2140/46609/10000]  lr: 9.955362208238724e-05  eta: 0:16:40  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0200)  train/logits_fake: 0.0195 (0.0193, 0.0191)  train/total_loss: 10784.1689 (17288.0590, 10148.7256)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 73931.1953 (43000.1296, 65274.6094)  train/nll_loss: 10784.0918 (17288.0160, 10148.6602)  train/rec_loss: 0.0468 (0.0750, 0.0440)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0191)
2025-02-06 18:02:40,591 train INFO: [2160/46609/10000]  lr: 9.954524850873901e-05  eta: 0:16:38  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0195)  train/logits_fake: 0.0195 (0.0193, 0.0194)  train/total_loss: 10784.1689 (17220.5945, 12362.4795)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 74194.5625 (43282.6373, 83435.4062)  train/nll_loss: 10784.0918 (17220.5512, 12362.3965)  train/rec_loss: 0.0468 (0.0747, 0.0537)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0194)
2025-02-06 18:02:43,130 train INFO: [2180/46609/10000]  lr: 9.953679748594889e-05  eta: 0:16:35  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0191)  train/logits_fake: 0.0194 (0.0193, 0.0183)  train/total_loss: 10828.3145 (17162.4878, 8589.6631)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 74538.1328 (43576.9924, 78713.0938)  train/nll_loss: 10828.2402 (17162.4443, 8589.5840)  train/rec_loss: 0.0470 (0.0745, 0.0373)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0183)
2025-02-06 18:02:45,665 train INFO: [2200/46609/10000]  lr: 9.952826902736218e-05  eta: 0:16:33  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0201)  train/logits_fake: 0.0194 (0.0193, 0.0207)  train/total_loss: 10487.0137 (17103.3167, 12131.2412)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 74276.9062 (43853.9421, 68037.3750)  train/nll_loss: 10486.9453 (17103.2729, 12131.1729)  train/rec_loss: 0.0455 (0.0742, 0.0527)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0207)
2025-02-06 18:02:48,195 train INFO: [2220/46609/10000]  lr: 9.951966314644651e-05  eta: 0:16:30  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0230)  train/logits_fake: 0.0194 (0.0193, 0.0214)  train/total_loss: 10828.3145 (17058.6674, 12030.2256)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 74538.1328 (44153.9483, 71318.2031)  train/nll_loss: 10828.2402 (17058.6232, 12030.1543)  train/rec_loss: 0.0470 (0.0740, 0.0522)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0214)
2025-02-06 18:02:50,728 train INFO: [2240/46609/10000]  lr: 9.951097985679171e-05  eta: 0:16:27  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0194)  train/logits_fake: 0.0194 (0.0193, 0.0194)  train/total_loss: 10841.5645 (17005.1424, 8127.3413)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 76448.6250 (44473.7352, 73173.3359)  train/nll_loss: 10841.4902 (17005.0980, 8127.2681)  train/rec_loss: 0.0471 (0.0738, 0.0353)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0194)
2025-02-06 18:02:53,259 train INFO: [2260/46609/10000]  lr: 9.95022191721099e-05  eta: 0:16:25  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0188)  train/logits_fake: 0.0194 (0.0193, 0.0193)  train/total_loss: 10984.4238 (16951.3555, 9439.5791)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 77164.4375 (44749.3907, 79023.7266)  train/nll_loss: 10984.3262 (16951.3108, 9439.5000)  train/rec_loss: 0.0477 (0.0736, 0.0410)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0193)
2025-02-06 18:02:55,793 train INFO: [2280/46609/10000]  lr: 9.949338110623539e-05  eta: 0:16:22  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0197)  train/logits_fake: 0.0194 (0.0193, 0.0206)  train/total_loss: 10962.5420 (16903.2670, 15354.1172)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 77539.1484 (45055.8140, 79698.0938)  train/nll_loss: 10962.4756 (16903.2219, 15354.0371)  train/rec_loss: 0.0476 (0.0734, 0.0666)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0206)
2025-02-06 18:02:58,322 train INFO: [2300/46609/10000]  lr: 9.94844656731247e-05  eta: 0:16:20  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0196)  train/logits_fake: 0.0194 (0.0193, 0.0190)  train/total_loss: 11401.4121 (16862.1901, 10498.2139)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 78744.5781 (45351.3168, 44481.2188)  train/nll_loss: 11401.3232 (16862.1448, 10498.1689)  train/rec_loss: 0.0495 (0.0732, 0.0456)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0190)
2025-02-06 18:03:00,851 train INFO: [2320/46609/10000]  lr: 9.947547288685651e-05  eta: 0:16:17  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0189)  train/logits_fake: 0.0193 (0.0193, 0.0192)  train/total_loss: 11401.3027 (16812.2827, 6492.5234)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 79198.5703 (45664.5899, 68498.6719)  train/nll_loss: 11401.2305 (16812.2371, 6492.4551)  train/rec_loss: 0.0495 (0.0730, 0.0282)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0192)
2025-02-06 18:03:03,378 train INFO: [2340/46609/10000]  lr: 9.946640276163165e-05  eta: 0:16:14  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0229)  train/logits_fake: 0.0193 (0.0193, 0.0218)  train/total_loss: 11401.4121 (16766.9795, 19463.8730)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 79023.7266 (45934.4844, 78377.3203)  train/nll_loss: 11401.3232 (16766.9336, 19463.7949)  train/rec_loss: 0.0495 (0.0728, 0.0845)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0218)
2025-02-06 18:03:05,920 train INFO: [2360/46609/10000]  lr: 9.94572553117731e-05  eta: 0:16:12  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0210)  train/logits_fake: 0.0193 (0.0193, 0.0215)  train/total_loss: 11407.8809 (16723.7338, 9535.9180)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 80214.8203 (46210.7622, 62311.2266)  train/nll_loss: 11407.8096 (16723.6876, 9535.8555)  train/rec_loss: 0.0495 (0.0726, 0.0414)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0215)
2025-02-06 18:03:08,456 train INFO: [2380/46609/10000]  lr: 9.944803055172592e-05  eta: 0:16:09  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0174)  train/logits_fake: 0.0192 (0.0193, 0.0184)  train/total_loss: 11527.8818 (16679.0763, 10842.9834)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 81909.3750 (46557.1431, 101043.8594)  train/nll_loss: 11527.7969 (16679.0298, 10842.8828)  train/rec_loss: 0.0500 (0.0724, 0.0471)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0184)
2025-02-06 18:03:10,991 train INFO: [2400/46609/10000]  lr: 9.943872849605728e-05  eta: 0:16:07  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0192)  train/logits_fake: 0.0192 (0.0193, 0.0185)  train/total_loss: 11221.9619 (16629.5549, 7621.1108)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 82003.8594 (46856.1786, 65510.7422)  train/nll_loss: 11221.8887 (16629.5080, 7621.0454)  train/rec_loss: 0.0487 (0.0722, 0.0331)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0185)
2025-02-06 18:03:13,526 train INFO: [2420/46609/10000]  lr: 9.942934915945637e-05  eta: 0:16:04  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0209)  train/logits_fake: 0.0193 (0.0193, 0.0208)  train/total_loss: 10819.3584 (16569.3632, 7381.6152)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 82071.1484 (47152.7059, 83972.1719)  train/nll_loss: 10819.2754 (16569.3161, 7381.5312)  train/rec_loss: 0.0470 (0.0719, 0.0320)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0208)
2025-02-06 18:03:16,062 train INFO: [2440/46609/10000]  lr: 9.941989255673447e-05  eta: 0:16:01  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0197)  train/logits_fake: 0.0192 (0.0193, 0.0192)  train/total_loss: 10648.5869 (16516.1807, 10248.7188)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 83972.1719 (47446.1593, 88180.4062)  train/nll_loss: 10648.4961 (16516.1332, 10248.6309)  train/rec_loss: 0.0462 (0.0717, 0.0445)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0192)
2025-02-06 18:03:18,601 train INFO: [2460/46609/10000]  lr: 9.941035870282483e-05  eta: 0:15:59  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0195)  train/logits_fake: 0.0192 (0.0193, 0.0189)  train/total_loss: 10248.7188 (16457.5260, 7936.9834)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 83972.1719 (47738.1460, 83063.1484)  train/nll_loss: 10248.6309 (16457.4782, 7936.9004)  train/rec_loss: 0.0445 (0.0714, 0.0344)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0189)
2025-02-06 18:03:21,138 train INFO: [2480/46609/10000]  lr: 9.940074761278272e-05  eta: 0:15:56  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0204)  train/logits_fake: 0.0193 (0.0193, 0.0208)  train/total_loss: 9793.2334 (16404.3166, 9755.4160)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 83063.1484 (48033.6440, 68106.0234)  train/nll_loss: 9793.1523 (16404.2686, 9755.3477)  train/rec_loss: 0.0425 (0.0712, 0.0423)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0208)
2025-02-06 18:03:23,674 train INFO: [2500/46609/10000]  lr: 9.939105930178535e-05  eta: 0:15:54  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0190)  train/logits_fake: 0.0193 (0.0193, 0.0188)  train/total_loss: 10001.1152 (16364.7225, 10680.4707)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 83972.1719 (48329.0633, 105648.1172)  train/nll_loss: 10001.0469 (16364.6741, 10680.3652)  train/rec_loss: 0.0434 (0.0710, 0.0464)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0188)
2025-02-06 18:03:26,211 train INFO: [2520/46609/10000]  lr: 9.93812937851319e-05  eta: 0:15:51  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0185)  train/logits_fake: 0.0192 (0.0193, 0.0193)  train/total_loss: 10359.3203 (16325.3398, 12195.6816)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 84731.8750 (48602.0175, 83527.2266)  train/nll_loss: 10359.2324 (16325.2912, 12195.5977)  train/rec_loss: 0.0450 (0.0709, 0.0529)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0193)
2025-02-06 18:03:28,749 train INFO: [2540/46609/10000]  lr: 9.937145107824344e-05  eta: 0:15:49  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0199)  train/logits_fake: 0.0194 (0.0193, 0.0192)  train/total_loss: 10443.1865 (16283.4242, 11039.0537)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 84445.7031 (48898.5974, 78580.9375)  train/nll_loss: 10443.1006 (16283.3753, 11038.9756)  train/rec_loss: 0.0453 (0.0707, 0.0479)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0192)
2025-02-06 18:03:31,289 train INFO: [2560/46609/10000]  lr: 9.936153119666295e-05  eta: 0:15:46  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0178)  train/logits_fake: 0.0194 (0.0193, 0.0179)  train/total_loss: 10576.4658 (16235.2391, 10786.7617)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 84999.5312 (49194.0256, 95571.1172)  train/nll_loss: 10576.3799 (16235.1899, 10786.6660)  train/rec_loss: 0.0459 (0.0705, 0.0468)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0179)
2025-02-06 18:03:33,829 train INFO: [2580/46609/10000]  lr: 9.935153415605526e-05  eta: 0:15:44  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0197)  train/logits_fake: 0.0192 (0.0193, 0.0194)  train/total_loss: 10576.4658 (16185.9393, 9206.7676)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 84937.0938 (49485.1319, 87918.8516)  train/nll_loss: 10576.3799 (16185.8899, 9206.6797)  train/rec_loss: 0.0459 (0.0703, 0.0400)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0194)
2025-02-06 18:03:36,366 train INFO: [2600/46609/10000]  lr: 9.93414599722071e-05  eta: 0:15:41  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0183)  train/logits_fake: 0.0193 (0.0193, 0.0183)  train/total_loss: 10455.0605 (16143.2318, 10657.9365)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 85056.3906 (49774.5437, 92501.2344)  train/nll_loss: 10454.9805 (16143.1820, 10657.8438)  train/rec_loss: 0.0454 (0.0701, 0.0463)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0183)
2025-02-06 18:03:38,894 train INFO: [2620/46609/10000]  lr: 9.933130866102697e-05  eta: 0:15:38  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0197)  train/logits_fake: 0.0194 (0.0193, 0.0195)  train/total_loss: 10138.9307 (16096.4673, 8953.5684)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 85206.7500 (50027.6394, 79502.8125)  train/nll_loss: 10138.8574 (16096.4173, 8953.4893)  train/rec_loss: 0.0440 (0.0699, 0.0389)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0195)
2025-02-06 18:03:41,431 train INFO: [2640/46609/10000]  lr: 9.932108023854514e-05  eta: 0:15:36  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0197)  train/logits_fake: 0.0194 (0.0193, 0.0197)  train/total_loss: 9814.5029 (16044.9193, 6739.6260)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 84671.9453 (50291.5707, 79444.5391)  train/nll_loss: 9814.4375 (16044.8690, 6739.5464)  train/rec_loss: 0.0426 (0.0696, 0.0293)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0197)
2025-02-06 18:03:43,966 train INFO: [2660/46609/10000]  lr: 9.931077472091375e-05  eta: 0:15:33  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0194)  train/logits_fake: 0.0194 (0.0193, 0.0201)  train/total_loss: 9719.4941 (15997.4468, 8170.5444)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 84216.3906 (50560.3161, 84606.3516)  train/nll_loss: 9719.4131 (15997.3963, 8170.4600)  train/rec_loss: 0.0422 (0.0694, 0.0355)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0201)
2025-02-06 18:03:46,503 train INFO: [2680/46609/10000]  lr: 9.930039212440655e-05  eta: 0:15:31  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0195)  train/logits_fake: 0.0194 (0.0193, 0.0205)  train/total_loss: 9859.5596 (15949.6391, 10418.6504)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 85227.3672 (50838.9565, 91862.2578)  train/nll_loss: 9859.4795 (15949.5883, 10418.5586)  train/rec_loss: 0.0428 (0.0692, 0.0452)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0205)
2025-02-06 18:03:49,040 train INFO: [2700/46609/10000]  lr: 9.928993246541913e-05  eta: 0:15:28  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0178)  train/logits_fake: 0.0194 (0.0193, 0.0194)  train/total_loss: 9563.3760 (15909.2788, 11012.2578)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 85287.6016 (51107.9286, 93894.3047)  train/nll_loss: 9563.2871 (15909.2277, 11012.1641)  train/rec_loss: 0.0415 (0.0691, 0.0478)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0194)
2025-02-06 18:03:51,590 train INFO: [2720/46609/10000]  lr: 9.927939576046868e-05  eta: 0:15:26  iter_time: 0.128  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0186)  train/logits_fake: 0.0194 (0.0193, 0.0192)  train/total_loss: 10004.4141 (15868.8948, 10280.7344)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 85545.9219 (51344.4155, 95514.5781)  train/nll_loss: 10004.3301 (15868.8435, 10280.6387)  train/rec_loss: 0.0434 (0.0689, 0.0446)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0192)
2025-02-06 18:03:54,134 train INFO: [2740/46609/10000]  lr: 9.926878202619414e-05  eta: 0:15:23  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0202)  train/logits_fake: 0.0193 (0.0193, 0.0201)  train/total_loss: 10165.9717 (15825.2619, 9652.7480)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 85519.3906 (51590.4288, 79445.2656)  train/nll_loss: 10165.8926 (15825.2103, 9652.6689)  train/rec_loss: 0.0441 (0.0687, 0.0419)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0201)
2025-02-06 18:03:56,689 train INFO: [2760/46609/10000]  lr: 9.925809127935599e-05  eta: 0:15:21  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0184)  train/logits_fake: 0.0194 (0.0193, 0.0195)  train/total_loss: 10165.9717 (15782.3341, 9775.4062)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 85101.1719 (51854.4105, 83700.0391)  train/nll_loss: 10165.8926 (15782.2822, 9775.3223)  train/rec_loss: 0.0441 (0.0685, 0.0424)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0195)
2025-02-06 18:03:59,217 train INFO: [2780/46609/10000]  lr: 9.924732353683642e-05  eta: 0:15:18  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0197)  train/logits_fake: 0.0194 (0.0193, 0.0204)  train/total_loss: 9875.4258 (15734.2891, 7809.9111)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 84218.5312 (52084.3615, 76988.1250)  train/nll_loss: 9875.3477 (15734.2370, 7809.8340)  train/rec_loss: 0.0429 (0.0683, 0.0339)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0204)
2025-02-06 18:04:01,760 train INFO: [2800/46609/10000]  lr: 9.923647881563915e-05  eta: 0:15:15  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0195)  train/logits_fake: 0.0193 (0.0193, 0.0192)  train/total_loss: 9633.7471 (15689.8188, 9912.1875)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 83926.8750 (52346.0579, 85285.3281)  train/nll_loss: 9633.6582 (15689.7665, 9912.1025)  train/rec_loss: 0.0418 (0.0681, 0.0430)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0192)
2025-02-06 18:04:04,291 train INFO: [2820/46609/10000]  lr: 9.922555713288949e-05  eta: 0:15:13  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0175)  train/logits_fake: 0.0193 (0.0193, 0.0179)  train/total_loss: 9508.9238 (15648.2573, 8409.4580)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 85101.1719 (52620.7044, 96385.1094)  train/nll_loss: 9508.8242 (15648.2047, 8409.3613)  train/rec_loss: 0.0413 (0.0679, 0.0365)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0179)
2025-02-06 18:04:06,827 train INFO: [2840/46609/10000]  lr: 9.921455850583425e-05  eta: 0:15:10  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0183)  train/logits_fake: 0.0194 (0.0193, 0.0182)  train/total_loss: 9405.4209 (15602.6140, 10307.2480)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 85297.7266 (52843.1408, 99698.5938)  train/nll_loss: 9405.3184 (15602.5611, 10307.1484)  train/rec_loss: 0.0408 (0.0677, 0.0447)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0182)
2025-02-06 18:04:09,365 train INFO: [2860/46609/10000]  lr: 9.920348295184176e-05  eta: 0:15:08  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0192)  train/logits_fake: 0.0194 (0.0193, 0.0185)  train/total_loss: 9280.9854 (15558.7563, 8627.8164)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 86628.0469 (53094.1877, 82767.4531)  train/nll_loss: 9280.8887 (15558.7033, 8627.7334)  train/rec_loss: 0.0403 (0.0675, 0.0374)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0185)
2025-02-06 18:04:11,905 train INFO: [2880/46609/10000]  lr: 9.919233048840184e-05  eta: 0:15:05  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0206)  train/logits_fake: 0.0194 (0.0193, 0.0198)  train/total_loss: 9405.4209 (15519.8927, 8983.3467)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 86628.0469 (53316.4278, 82177.5469)  train/nll_loss: 9405.3184 (15519.8394, 8983.2646)  train/rec_loss: 0.0408 (0.0674, 0.0390)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0198)
2025-02-06 18:04:14,445 train INFO: [2900/46609/10000]  lr: 9.918110113312576e-05  eta: 0:15:03  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0198)  train/logits_fake: 0.0194 (0.0193, 0.0198)  train/total_loss: 9544.4678 (15485.8468, 8829.0986)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 86012.1719 (53531.0888, 72646.0234)  train/nll_loss: 9544.3818 (15485.7933, 8829.0264)  train/rec_loss: 0.0414 (0.0672, 0.0383)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0198)
2025-02-06 18:04:16,981 train INFO: [2920/46609/10000]  lr: 9.916979490374619e-05  eta: 0:15:00  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0183)  train/logits_fake: 0.0193 (0.0193, 0.0193)  train/total_loss: 9999.3721 (15461.6115, 10705.0020)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 85513.2344 (53807.3391, 105459.5547)  train/nll_loss: 9999.2930 (15461.5577, 10704.8965)  train/rec_loss: 0.0434 (0.0671, 0.0465)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0193)
2025-02-06 18:04:19,518 train INFO: [2940/46609/10000]  lr: 9.915841181811723e-05  eta: 0:14:57  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0174)  train/logits_fake: 0.0193 (0.0193, 0.0177)  train/total_loss: 10090.3682 (15420.0911, 9009.0117)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 85738.3828 (54013.0780, 89031.3438)  train/nll_loss: 10090.2812 (15420.0371, 9008.9229)  train/rec_loss: 0.0438 (0.0669, 0.0391)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0177)
2025-02-06 18:04:22,057 train INFO: [2960/46609/10000]  lr: 9.914695189421432e-05  eta: 0:14:55  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0196)  train/logits_fake: 0.0193 (0.0193, 0.0196)  train/total_loss: 10090.3682 (15376.8598, 7036.8438)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 86385.6797 (54260.2202, 84025.8594)  train/nll_loss: 10090.2812 (15376.8055, 7036.7598)  train/rec_loss: 0.0438 (0.0667, 0.0305)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0196)
2025-02-06 18:04:24,594 train INFO: [2980/46609/10000]  lr: 9.91354151501342e-05  eta: 0:14:52  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0193)  train/logits_fake: 0.0192 (0.0193, 0.0194)  train/total_loss: 9858.2373 (15338.6808, 6977.5010)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 87306.8438 (54503.6399, 86873.4453)  train/nll_loss: 9858.1602 (15338.6263, 6977.4141)  train/rec_loss: 0.0428 (0.0666, 0.0303)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0194)
2025-02-06 18:04:27,124 train INFO: [3000/46609/10000]  lr: 9.912380160409504e-05  eta: 0:14:50  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0207)  train/logits_fake: 0.0190 (0.0193, 0.0206)  train/total_loss: 9472.7275 (15299.3309, 8430.0957)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 87573.9219 (54760.6797, 92563.6094)  train/nll_loss: 9472.6406 (15299.2762, 8430.0029)  train/rec_loss: 0.0411 (0.0664, 0.0366)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0206)
2025-02-06 18:04:29,662 train INFO: [3020/46609/10000]  lr: 9.911211127443615e-05  eta: 0:14:47  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0194)  train/logits_fake: 0.0191 (0.0193, 0.0197)  train/total_loss: 9344.1182 (15275.1298, 10253.1084)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 88397.5391 (55011.6920, 88827.0938)  train/nll_loss: 9344.0156 (15275.0748, 10253.0195)  train/rec_loss: 0.0406 (0.0663, 0.0445)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0197)
2025-02-06 18:04:32,205 train INFO: [3040/46609/10000]  lr: 9.910034417961819e-05  eta: 0:14:45  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0203)  train/logits_fake: 0.0191 (0.0193, 0.0206)  train/total_loss: 9360.7588 (15236.2932, 6890.9009)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 88918.0938 (55252.4496, 73765.7656)  train/nll_loss: 9360.6709 (15236.2380, 6890.8271)  train/rec_loss: 0.0406 (0.0661, 0.0299)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0206)
2025-02-06 18:04:34,744 train INFO: [3060/46609/10000]  lr: 9.9088500338223e-05  eta: 0:14:42  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0190)  train/logits_fake: 0.0191 (0.0193, 0.0190)  train/total_loss: 9619.9424 (15201.7377, 8040.3813)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 89506.9531 (55483.6496, 97603.9297)  train/nll_loss: 9619.8428 (15201.6823, 8040.2837)  train/rec_loss: 0.0418 (0.0660, 0.0349)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0190)
2025-02-06 18:04:37,281 train INFO: [3080/46609/10000]  lr: 9.907657976895363e-05  eta: 0:14:40  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0174)  train/logits_fake: 0.0192 (0.0193, 0.0181)  train/total_loss: 9517.5908 (15161.4996, 9327.3252)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 92266.5781 (55725.8403, 77116.2969)  train/nll_loss: 9517.4961 (15161.4439, 9327.2480)  train/rec_loss: 0.0413 (0.0658, 0.0405)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0181)
2025-02-06 18:04:39,820 train INFO: [3100/46609/10000]  lr: 9.906458249063424e-05  eta: 0:14:37  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0185)  train/logits_fake: 0.0193 (0.0193, 0.0185)  train/total_loss: 10047.8906 (15134.6608, 10203.9424)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 92190.9922 (55955.6806, 91855.6562)  train/nll_loss: 10047.7793 (15134.6049, 10203.8506)  train/rec_loss: 0.0436 (0.0657, 0.0443)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0185)
2025-02-06 18:04:42,357 train INFO: [3120/46609/10000]  lr: 9.905250852221025e-05  eta: 0:14:34  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0182)  train/logits_fake: 0.0192 (0.0193, 0.0190)  train/total_loss: 9870.7207 (15101.0891, 9674.9346)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 92156.5000 (56201.7448, 98326.7969)  train/nll_loss: 9870.6250 (15101.0329, 9674.8359)  train/rec_loss: 0.0428 (0.0655, 0.0420)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0190)
2025-02-06 18:04:44,900 train INFO: [3140/46609/10000]  lr: 9.904035788274805e-05  eta: 0:14:32  iter_time: 0.128  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0188)  train/logits_fake: 0.0193 (0.0193, 0.0194)  train/total_loss: 9957.5703 (15069.0270, 10920.5811)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 91840.6328 (56397.0552, 89019.7109)  train/nll_loss: 9957.4756 (15068.9706, 10920.4922)  train/rec_loss: 0.0432 (0.0654, 0.0474)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0194)
2025-02-06 18:04:47,439 train INFO: [3160/46609/10000]  lr: 9.902813059143517e-05  eta: 0:14:29  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0203)  train/logits_fake: 0.0193 (0.0193, 0.0199)  train/total_loss: 9916.8789 (15039.3649, 10798.7656)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 91855.6562 (56622.5537, 104447.3125)  train/nll_loss: 9916.7656 (15039.3082, 10798.6611)  train/rec_loss: 0.0430 (0.0653, 0.0469)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0199)
2025-02-06 18:04:49,983 train INFO: [3180/46609/10000]  lr: 9.901582666758017e-05  eta: 0:14:27  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0195)  train/logits_fake: 0.0193 (0.0193, 0.0192)  train/total_loss: 10143.9141 (15010.0586, 11035.0742)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 91855.6562 (56848.5112, 90033.2812)  train/nll_loss: 10143.8281 (15010.0018, 11034.9844)  train/rec_loss: 0.0440 (0.0651, 0.0479)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0192)
2025-02-06 18:04:52,522 train INFO: [3200/46609/10000]  lr: 9.900344613061264e-05  eta: 0:14:24  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0184)  train/logits_fake: 0.0193 (0.0193, 0.0190)  train/total_loss: 10051.2490 (14984.7754, 8920.3359)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 91903.3516 (57061.9805, 104835.4219)  train/nll_loss: 10051.1641 (14984.7184, 8920.2314)  train/rec_loss: 0.0436 (0.0650, 0.0387)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0190)
2025-02-06 18:04:55,059 train INFO: [3220/46609/10000]  lr: 9.899098900008311e-05  eta: 0:14:22  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0183)  train/logits_fake: 0.0193 (0.0193, 0.0198)  train/total_loss: 10194.8135 (14956.1192, 10793.1689)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 90641.6953 (57284.6238, 67589.0234)  train/nll_loss: 10194.7393 (14956.0620, 10793.1016)  train/rec_loss: 0.0442 (0.0649, 0.0468)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0198)
2025-02-06 18:04:57,597 train INFO: [3240/46609/10000]  lr: 9.897845529566311e-05  eta: 0:14:19  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0190)  train/logits_fake: 0.0193 (0.0193, 0.0194)  train/total_loss: 10258.8369 (14927.0578, 9000.7432)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 92596.2109 (57503.8118, 91560.6016)  train/nll_loss: 10258.7529 (14927.0003, 9000.6514)  train/rec_loss: 0.0445 (0.0648, 0.0391)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0194)
2025-02-06 18:05:00,132 train INFO: [3260/46609/10000]  lr: 9.896584503714506e-05  eta: 0:14:17  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0168)  train/logits_fake: 0.0193 (0.0193, 0.0162)  train/total_loss: 10271.0439 (14897.7477, 10411.3008)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 92596.2109 (57742.8260, 94320.0469)  train/nll_loss: 10270.9600 (14897.6899, 10411.2061)  train/rec_loss: 0.0446 (0.0647, 0.0452)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0162)
2025-02-06 18:05:02,668 train INFO: [3280/46609/10000]  lr: 9.895315824444229e-05  eta: 0:14:14  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0180)  train/logits_fake: 0.0192 (0.0193, 0.0183)  train/total_loss: 10194.8135 (14870.8700, 9125.4766)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 91841.8828 (57961.1834, 83072.0703)  train/nll_loss: 10194.7393 (14870.8120, 9125.3936)  train/rec_loss: 0.0442 (0.0645, 0.0396)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0183)
2025-02-06 18:05:05,199 train INFO: [3300/46609/10000]  lr: 9.894039493758898e-05  eta: 0:14:11  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0188)  train/logits_fake: 0.0192 (0.0193, 0.0193)  train/total_loss: 9855.1836 (14835.3566, 8463.8320)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 91739.7969 (58147.0128, 87554.5547)  train/nll_loss: 9855.0859 (14835.2984, 8463.7441)  train/rec_loss: 0.0428 (0.0644, 0.0367)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0193)
2025-02-06 18:05:07,732 train INFO: [3320/46609/10000]  lr: 9.892755513674011e-05  eta: 0:14:09  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0191)  train/logits_fake: 0.0192 (0.0193, 0.0195)  train/total_loss: 9545.5059 (14800.1224, 9748.6689)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 91992.7500 (58359.6712, 86666.2656)  train/nll_loss: 9545.3906 (14800.0640, 9748.5820)  train/rec_loss: 0.0414 (0.0642, 0.0423)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0195)
2025-02-06 18:05:10,270 train INFO: [3340/46609/10000]  lr: 9.891463886217151e-05  eta: 0:14:06  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0203)  train/logits_fake: 0.0191 (0.0193, 0.0203)  train/total_loss: 9419.4834 (14770.0177, 8662.4053)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 94144.2031 (58627.8837, 118120.3984)  train/nll_loss: 9419.4033 (14769.9591, 8662.2871)  train/rec_loss: 0.0409 (0.0641, 0.0376)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0203)
2025-02-06 18:05:12,804 train INFO: [3360/46609/10000]  lr: 9.89016461342797e-05  eta: 0:14:04  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0171)  train/logits_fake: 0.0191 (0.0193, 0.0182)  train/total_loss: 9466.9961 (14740.8746, 10028.3359)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 97002.6719 (58859.2183, 105648.4531)  train/nll_loss: 9466.9121 (14740.8157, 10028.2305)  train/rec_loss: 0.0411 (0.0640, 0.0435)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0182)
2025-02-06 18:05:15,340 train INFO: [3380/46609/10000]  lr: 9.888857697358202e-05  eta: 0:14:01  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0185)  train/logits_fake: 0.0192 (0.0193, 0.0191)  train/total_loss: 9458.2920 (14710.3446, 7689.0459)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 96414.9609 (59073.1321, 88356.4766)  train/nll_loss: 9458.1895 (14710.2855, 7688.9575)  train/rec_loss: 0.0411 (0.0638, 0.0334)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0191)
2025-02-06 18:05:17,874 train INFO: [3400/46609/10000]  lr: 9.887543140071642e-05  eta: 0:13:59  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0211)  train/logits_fake: 0.0193 (0.0193, 0.0207)  train/total_loss: 9545.5059 (14683.6651, 9347.6572)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 97194.0469 (59293.8790, 117263.8281)  train/nll_loss: 9545.3906 (14683.6058, 9347.5400)  train/rec_loss: 0.0414 (0.0637, 0.0406)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0207)
2025-02-06 18:05:20,408 train INFO: [3420/46609/10000]  lr: 9.886220943644157e-05  eta: 0:13:56  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0189)  train/logits_fake: 0.0192 (0.0193, 0.0183)  train/total_loss: 9680.9561 (14655.3171, 9021.7305)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 97875.9531 (59546.9362, 99577.0547)  train/nll_loss: 9680.8711 (14655.2575, 9021.6309)  train/rec_loss: 0.0420 (0.0636, 0.0392)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0183)
2025-02-06 18:05:22,942 train INFO: [3440/46609/10000]  lr: 9.884891110163676e-05  eta: 0:13:54  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0199)  train/logits_fake: 0.0193 (0.0193, 0.0208)  train/total_loss: 9680.9561 (14626.1762, 8236.1270)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 97785.1562 (59792.4262, 86030.1250)  train/nll_loss: 9680.8711 (14626.1164, 8236.0410)  train/rec_loss: 0.0420 (0.0635, 0.0357)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0208)
2025-02-06 18:05:25,477 train INFO: [3460/46609/10000]  lr: 9.883553641730187e-05  eta: 0:13:51  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0177)  train/logits_fake: 0.0193 (0.0193, 0.0170)  train/total_loss: 9576.0938 (14594.8942, 8091.5488)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 99282.9219 (60041.1287, 117601.5391)  train/nll_loss: 9575.9854 (14594.8342, 8091.4312)  train/rec_loss: 0.0416 (0.0633, 0.0351)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0170)
2025-02-06 18:05:28,012 train INFO: [3480/46609/10000]  lr: 9.882208540455734e-05  eta: 0:13:48  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0204)  train/logits_fake: 0.0194 (0.0193, 0.0189)  train/total_loss: 9509.6436 (14563.8849, 10656.4111)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 100434.7031 (60241.1458, 92517.2812)  train/nll_loss: 9509.5293 (14563.8247, 10656.3184)  train/rec_loss: 0.0413 (0.0632, 0.0463)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0189)
2025-02-06 18:05:30,546 train INFO: [3500/46609/10000]  lr: 9.880855808464419e-05  eta: 0:13:46  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0195)  train/logits_fake: 0.0193 (0.0193, 0.0190)  train/total_loss: 9169.7549 (14536.5967, 6946.4814)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 100338.2969 (60445.0396, 76642.5859)  train/nll_loss: 9169.6602 (14536.5362, 6946.4048)  train/rec_loss: 0.0398 (0.0631, 0.0301)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0190)
2025-02-06 18:05:33,079 train INFO: [3520/46609/10000]  lr: 9.879495447892385e-05  eta: 0:13:43  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0187)  train/logits_fake: 0.0194 (0.0193, 0.0194)  train/total_loss: 9144.8379 (14508.7894, 9061.6436)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 99680.2266 (60662.7001, 102344.0312)  train/nll_loss: 9144.7510 (14508.7288, 9061.5410)  train/rec_loss: 0.0397 (0.0630, 0.0393)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0194)
2025-02-06 18:05:35,623 train INFO: [3540/46609/10000]  lr: 9.878127460887831e-05  eta: 0:13:41  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0223)  train/logits_fake: 0.0193 (0.0193, 0.0215)  train/total_loss: 9144.8379 (14480.6176, 10556.8037)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 98937.4453 (60878.3771, 98937.4453)  train/nll_loss: 9144.7510 (14480.5567, 10556.7051)  train/rec_loss: 0.0397 (0.0628, 0.0458)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0215)
2025-02-06 18:05:38,157 train INFO: [3560/46609/10000]  lr: 9.876751849610996e-05  eta: 0:13:38  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0213)  train/logits_fake: 0.0193 (0.0193, 0.0194)  train/total_loss: 9326.1533 (14456.0208, 10812.1064)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 97739.5625 (61097.1103, 93389.7969)  train/nll_loss: 9326.0469 (14455.9597, 10812.0127)  train/rec_loss: 0.0405 (0.0627, 0.0469)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0194)
2025-02-06 18:05:40,686 train INFO: [3580/46609/10000]  lr: 9.875368616234155e-05  eta: 0:13:36  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0202)  train/logits_fake: 0.0192 (0.0193, 0.0201)  train/total_loss: 9168.6387 (14422.0359, 9306.9824)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 98033.9062 (61312.9349, 90670.7969)  train/nll_loss: 9168.5430 (14421.9746, 9306.8916)  train/rec_loss: 0.0398 (0.0626, 0.0404)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0201)
2025-02-06 18:05:43,217 train INFO: [3600/46609/10000]  lr: 9.873977762941625e-05  eta: 0:13:33  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0187)  train/logits_fake: 0.0192 (0.0193, 0.0187)  train/total_loss: 9064.0605 (14393.7646, 9788.4951)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 98937.4453 (61543.5586, 135334.9531)  train/nll_loss: 9063.9629 (14393.7030, 9788.3594)  train/rec_loss: 0.0393 (0.0625, 0.0425)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0187)
2025-02-06 18:05:45,751 train INFO: [3620/46609/10000]  lr: 9.872579291929751e-05  eta: 0:13:31  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0194)  train/logits_fake: 0.0191 (0.0193, 0.0202)  train/total_loss: 9265.0195 (14373.0620, 10199.8037)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 97947.7500 (61753.9006, 104942.7656)  train/nll_loss: 9264.9316 (14373.0002, 10199.6992)  train/rec_loss: 0.0402 (0.0624, 0.0443)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0202)
2025-02-06 18:05:48,284 train INFO: [3640/46609/10000]  lr: 9.87117320540691e-05  eta: 0:13:28  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0186)  train/logits_fake: 0.0192 (0.0193, 0.0185)  train/total_loss: 9168.6387 (14347.2666, 6737.6416)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 99126.5469 (61996.8116, 86590.8594)  train/nll_loss: 9168.5430 (14347.2046, 6737.5552)  train/rec_loss: 0.0398 (0.0623, 0.0292)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0185)
2025-02-06 18:05:50,815 train INFO: [3660/46609/10000]  lr: 9.869759505593506e-05  eta: 0:13:25  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0182)  train/logits_fake: 0.0192 (0.0193, 0.0177)  train/total_loss: 8965.2393 (14320.8079, 8533.7031)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 99049.8594 (62204.1505, 99144.5938)  train/nll_loss: 8965.1455 (14320.7457, 8533.6035)  train/rec_loss: 0.0389 (0.0622, 0.0370)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0177)
2025-02-06 18:05:53,351 train INFO: [3680/46609/10000]  lr: 9.868338194721962e-05  eta: 0:13:23  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0187)  train/logits_fake: 0.0193 (0.0193, 0.0191)  train/total_loss: 9112.6426 (14292.4598, 7625.2983)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 99049.8594 (62391.9681, 92694.9922)  train/nll_loss: 9112.5410 (14292.3974, 7625.2056)  train/rec_loss: 0.0396 (0.0620, 0.0331)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0191)
2025-02-06 18:05:55,895 train INFO: [3700/46609/10000]  lr: 9.866909275036726e-05  eta: 0:13:20  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0178)  train/logits_fake: 0.0192 (0.0193, 0.0183)  train/total_loss: 9068.0410 (14260.2602, 7607.2065)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 98159.7656 (62575.7206, 87833.3906)  train/nll_loss: 9067.9541 (14260.1976, 7607.1187)  train/rec_loss: 0.0394 (0.0619, 0.0330)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0183)
2025-02-06 18:05:58,439 train INFO: [3720/46609/10000]  lr: 9.86547274879425e-05  eta: 0:13:18  iter_time: 0.127  data: 0.001  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0181)  train/logits_fake: 0.0194 (0.0193, 0.0177)  train/total_loss: 8449.5977 (14227.6766, 8555.8662)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 98159.7656 (62762.6836, 96961.7344)  train/nll_loss: 8449.4990 (14227.6139, 8555.7695)  train/rec_loss: 0.0367 (0.0618, 0.0371)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0177)
2025-02-06 18:06:00,984 train INFO: [3740/46609/10000]  lr: 9.86402861826301e-05  eta: 0:13:15  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0173)  train/logits_fake: 0.0193 (0.0193, 0.0181)  train/total_loss: 8316.1729 (14196.4205, 9623.1963)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 96285.2578 (62957.7027, 116122.0625)  train/nll_loss: 8316.0859 (14196.3576, 9623.0801)  train/rec_loss: 0.0361 (0.0616, 0.0418)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0181)
2025-02-06 18:06:03,525 train INFO: [3760/46609/10000]  lr: 9.862576885723485e-05  eta: 0:13:13  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0200)  train/logits_fake: 0.0193 (0.0193, 0.0199)  train/total_loss: 8316.1729 (14167.2386, 8539.6924)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 96299.1406 (63153.6375, 95505.9141)  train/nll_loss: 8316.0859 (14167.1755, 8539.5967)  train/rec_loss: 0.0361 (0.0615, 0.0371)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0199)
2025-02-06 18:06:06,066 train INFO: [3780/46609/10000]  lr: 9.861117553468158e-05  eta: 0:13:10  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0207)  train/logits_fake: 0.0190 (0.0193, 0.0202)  train/total_loss: 8131.9800 (14137.3619, 7190.6167)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 97236.0625 (63356.6374, 108462.4062)  train/nll_loss: 8131.8809 (14137.2986, 7190.5083)  train/rec_loss: 0.0353 (0.0614, 0.0312)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0202)
2025-02-06 18:06:08,603 train INFO: [3800/46609/10000]  lr: 9.859650623801515e-05  eta: 0:13:08  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0178)  train/logits_fake: 0.0191 (0.0193, 0.0173)  train/total_loss: 8491.8584 (14112.2444, 9696.5391)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 99336.8828 (63558.5065, 120416.8906)  train/nll_loss: 8491.7500 (14112.1808, 9696.4189)  train/rec_loss: 0.0369 (0.0613, 0.0421)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0173)
2025-02-06 18:06:11,138 train INFO: [3820/46609/10000]  lr: 9.858176099040036e-05  eta: 0:13:05  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0198)  train/logits_fake: 0.0190 (0.0193, 0.0206)  train/total_loss: 8581.2490 (14085.4529, 9101.0156)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 102148.7656 (63772.6593, 90300.8281)  train/nll_loss: 8581.1367 (14085.3891, 9100.9258)  train/rec_loss: 0.0372 (0.0611, 0.0395)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0206)
2025-02-06 18:06:13,676 train INFO: [3840/46609/10000]  lr: 9.856693981512198e-05  eta: 0:13:02  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0192)  train/logits_fake: 0.0190 (0.0193, 0.0201)  train/total_loss: 8985.3643 (14064.5887, 9758.8848)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 102113.5938 (63970.5780, 92606.6094)  train/nll_loss: 8985.2803 (14064.5247, 9758.7920)  train/rec_loss: 0.0390 (0.0610, 0.0424)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0201)
2025-02-06 18:06:16,205 train INFO: [3860/46609/10000]  lr: 9.855204273558467e-05  eta: 0:13:00  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0180)  train/logits_fake: 0.0190 (0.0193, 0.0179)  train/total_loss: 9322.3877 (14041.9818, 9859.4170)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 100577.7969 (64170.6293, 81569.3906)  train/nll_loss: 9322.2891 (14041.9177, 9859.3350)  train/rec_loss: 0.0405 (0.0609, 0.0428)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0193, -0.0179)
2025-02-06 18:06:18,735 train INFO: [3880/46609/10000]  lr: 9.853706977531296e-05  eta: 0:12:57  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0177)  train/logits_fake: 0.0191 (0.0193, 0.0186)  train/total_loss: 9322.3877 (14016.7621, 10004.7568)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 100419.0625 (64362.6890, 119852.9531)  train/nll_loss: 9322.2891 (14016.6977, 10004.6367)  train/rec_loss: 0.0405 (0.0608, 0.0434)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0186)
2025-02-06 18:06:21,270 train INFO: [3900/46609/10000]  lr: 9.852202095795118e-05  eta: 0:12:55  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0186)  train/logits_fake: 0.0190 (0.0193, 0.0194)  train/total_loss: 9090.6650 (13986.2272, 9972.2197)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 101157.8750 (64565.4620, 103270.0000)  train/nll_loss: 9090.5664 (13986.1627, 9972.1162)  train/rec_loss: 0.0395 (0.0607, 0.0433)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0194)
2025-02-06 18:06:23,806 train INFO: [3920/46609/10000]  lr: 9.85068963072635e-05  eta: 0:12:52  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0202)  train/logits_fake: 0.0191 (0.0193, 0.0201)  train/total_loss: 8966.2607 (13958.7749, 8349.9434)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 100851.1250 (64754.1219, 103133.2109)  train/nll_loss: 8966.1484 (13958.7101, 8349.8398)  train/rec_loss: 0.0389 (0.0606, 0.0362)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0201)
2025-02-06 18:06:26,340 train INFO: [3940/46609/10000]  lr: 9.849169584713375e-05  eta: 0:12:50  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0179)  train/logits_fake: 0.0191 (0.0193, 0.0175)  train/total_loss: 8421.9131 (13932.6757, 9170.7422)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 100577.7969 (64932.3077, 103045.0469)  train/nll_loss: 8421.8242 (13932.6108, 9170.6387)  train/rec_loss: 0.0366 (0.0605, 0.0398)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0175)
2025-02-06 18:06:28,873 train INFO: [3960/46609/10000]  lr: 9.847641960156558e-05  eta: 0:12:47  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0203)  train/logits_fake: 0.0191 (0.0193, 0.0210)  train/total_loss: 8421.9131 (13909.8727, 10851.1533)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 102835.2969 (65131.9099, 109835.4922)  train/nll_loss: 8421.8242 (13909.8075, 10851.0439)  train/rec_loss: 0.0366 (0.0604, 0.0471)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0210)
2025-02-06 18:06:31,417 train INFO: [3980/46609/10000]  lr: 9.846106759468224e-05  eta: 0:12:45  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0174)  train/logits_fake: 0.0192 (0.0193, 0.0171)  train/total_loss: 8556.9824 (13888.9562, 8208.4648)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 103170.2188 (65342.7235, 116938.2812)  train/nll_loss: 8556.8867 (13888.8908, 8208.3477)  train/rec_loss: 0.0371 (0.0603, 0.0356)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0171)
2025-02-06 18:06:33,962 train INFO: [4000/46609/10000]  lr: 9.844563985072668e-05  eta: 0:12:42  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0183)  train/logits_fake: 0.0192 (0.0193, 0.0191)  train/total_loss: 8620.8486 (13864.9295, 9603.3291)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 103045.0469 (65521.7364, 128047.9531)  train/nll_loss: 8620.7383 (13864.8640, 9603.2012)  train/rec_loss: 0.0374 (0.0602, 0.0417)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0191)
2025-02-06 18:06:36,505 train INFO: [4020/46609/10000]  lr: 9.843013639406139e-05  eta: 0:12:40  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0209)  train/logits_fake: 0.0193 (0.0193, 0.0209)  train/total_loss: 8620.8486 (13840.2319, 9387.6123)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 103504.1719 (65712.1918, 101054.1172)  train/nll_loss: 8620.7383 (13840.1662, 9387.5117)  train/rec_loss: 0.0374 (0.0601, 0.0407)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0209)
2025-02-06 18:06:39,044 train INFO: [4040/46609/10000]  lr: 9.841455724916842e-05  eta: 0:12:37  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0192)  train/logits_fake: 0.0193 (0.0193, 0.0185)  train/total_loss: 8786.8740 (13818.0950, 6172.0776)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 105650.2188 (65929.5336, 120452.0625)  train/nll_loss: 8786.7568 (13818.0291, 6171.9570)  train/rec_loss: 0.0381 (0.0600, 0.0268)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0185)
2025-02-06 18:06:41,577 train INFO: [4060/46609/10000]  lr: 9.839890244064939e-05  eta: 0:12:34  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0188)  train/logits_fake: 0.0193 (0.0193, 0.0193)  train/total_loss: 8648.3984 (13789.6893, 8919.3721)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 105730.2188 (66125.6859, 113178.5469)  train/nll_loss: 8648.3057 (13789.6232, 8919.2588)  train/rec_loss: 0.0375 (0.0599, 0.0387)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0193)
2025-02-06 18:06:44,115 train INFO: [4080/46609/10000]  lr: 9.838317199322539e-05  eta: 0:12:32  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0208)  train/logits_fake: 0.0193 (0.0193, 0.0210)  train/total_loss: 8417.5293 (13759.9766, 6607.6343)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 105650.2188 (66302.2373, 91451.2734)  train/nll_loss: 8417.4238 (13759.9103, 6607.5430)  train/rec_loss: 0.0365 (0.0597, 0.0287)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0210)
2025-02-06 18:06:46,647 train INFO: [4100/46609/10000]  lr: 9.836736593173694e-05  eta: 0:12:29  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0188)  train/logits_fake: 0.0193 (0.0193, 0.0195)  train/total_loss: 8342.5254 (13732.4990, 7793.2715)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 105730.2188 (66464.4084, 117142.0156)  train/nll_loss: 8342.4336 (13732.4326, 7793.1543)  train/rec_loss: 0.0362 (0.0596, 0.0338)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0195)
2025-02-06 18:06:49,180 train INFO: [4120/46609/10000]  lr: 9.835148428114396e-05  eta: 0:12:27  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0191)  train/logits_fake: 0.0192 (0.0193, 0.0180)  train/total_loss: 8137.6035 (13705.6635, 9116.7021)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 104493.4531 (66643.2639, 118089.5469)  train/nll_loss: 8137.5107 (13705.5969, 9116.5840)  train/rec_loss: 0.0353 (0.0595, 0.0396)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0180)
2025-02-06 18:06:51,712 train INFO: [4140/46609/10000]  lr: 9.833552706652576e-05  eta: 0:12:24  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0172)  train/logits_fake: 0.0192 (0.0193, 0.0178)  train/total_loss: 8137.6035 (13681.5878, 10149.7168)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 103059.8516 (66846.1738, 93155.2344)  train/nll_loss: 8137.5107 (13681.5209, 10149.6240)  train/rec_loss: 0.0353 (0.0594, 0.0441)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0178)
2025-02-06 18:06:54,257 train INFO: [4160/46609/10000]  lr: 9.831949431308091e-05  eta: 0:12:22  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0185)  train/logits_fake: 0.0192 (0.0193, 0.0185)  train/total_loss: 8177.7632 (13656.0674, 7986.2749)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 101625.9531 (67013.2317, 126322.1406)  train/nll_loss: 8177.6577 (13656.0004, 7986.1484)  train/rec_loss: 0.0355 (0.0593, 0.0347)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0185)
2025-02-06 18:06:56,795 train INFO: [4180/46609/10000]  lr: 9.830338604612738e-05  eta: 0:12:19  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0199)  train/logits_fake: 0.0193 (0.0193, 0.0199)  train/total_loss: 8238.0811 (13634.3250, 5923.1338)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 101118.4219 (67188.9035, 96146.6094)  train/nll_loss: 8237.9717 (13634.2578, 5923.0376)  train/rec_loss: 0.0358 (0.0592, 0.0257)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0199)
2025-02-06 18:06:59,339 train INFO: [4200/46609/10000]  lr: 9.828720229110229e-05  eta: 0:12:17  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0191)  train/logits_fake: 0.0192 (0.0193, 0.0194)  train/total_loss: 8332.8359 (13614.0843, 8332.8359)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 102283.0625 (67370.4979, 103399.6641)  train/nll_loss: 8332.7324 (13614.0169, 8332.7324)  train/rec_loss: 0.0362 (0.0591, 0.0362)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0194)
2025-02-06 18:07:01,878 train INFO: [4220/46609/10000]  lr: 9.8270943073562e-05  eta: 0:12:14  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0185)  train/logits_fake: 0.0193 (0.0193, 0.0189)  train/total_loss: 8531.2832 (13593.5319, 11410.9629)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 103399.6641 (67567.6733, 119435.9531)  train/nll_loss: 8531.1807 (13593.4644, 11410.8438)  train/rec_loss: 0.0370 (0.0590, 0.0495)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0189)
2025-02-06 18:07:04,423 train INFO: [4240/46609/10000]  lr: 9.825460841918203e-05  eta: 0:12:12  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0201)  train/logits_fake: 0.0193 (0.0193, 0.0198)  train/total_loss: 8699.6621 (13569.7298, 9629.4180)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 103668.2031 (67742.4256, 101332.9297)  train/nll_loss: 8699.5664 (13569.6621, 9629.3164)  train/rec_loss: 0.0378 (0.0589, 0.0418)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0198)
2025-02-06 18:07:06,956 train INFO: [4260/46609/10000]  lr: 9.823819835375703e-05  eta: 0:12:09  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0180)  train/logits_fake: 0.0193 (0.0193, 0.0191)  train/total_loss: 8699.6621 (13546.4631, 11454.5713)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 103668.2031 (67914.5487, 104628.4453)  train/nll_loss: 8699.5664 (13546.3952, 11454.4668)  train/rec_loss: 0.0378 (0.0588, 0.0497)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0191)
2025-02-06 18:07:09,497 train INFO: [4280/46609/10000]  lr: 9.822171290320077e-05  eta: 0:12:06  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0190)  train/logits_fake: 0.0192 (0.0193, 0.0187)  train/total_loss: 8982.5244 (13531.0779, 9523.3115)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 103668.2031 (68085.8020, 98287.6562)  train/nll_loss: 8982.4229 (13531.0099, 9523.2129)  train/rec_loss: 0.0390 (0.0587, 0.0413)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0187)
2025-02-06 18:07:12,027 train INFO: [4300/46609/10000]  lr: 9.820515209354598e-05  eta: 0:12:04  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0195)  train/logits_fake: 0.0193 (0.0193, 0.0195)  train/total_loss: 9454.7207 (13520.3119, 17439.1211)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 103638.5938 (68263.8097, 98841.7500)  train/nll_loss: 9454.6035 (13520.2437, 17439.0215)  train/rec_loss: 0.0410 (0.0587, 0.0757)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0195)
2025-02-06 18:07:14,568 train INFO: [4320/46609/10000]  lr: 9.818851595094445e-05  eta: 0:12:01  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0194)  train/logits_fake: 0.0191 (0.0193, 0.0195)  train/total_loss: 9523.3115 (13501.5543, 6993.4707)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 103628.1562 (68443.0127, 102075.9531)  train/nll_loss: 9523.2129 (13501.4859, 6993.3687)  train/rec_loss: 0.0413 (0.0586, 0.0304)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0195)
2025-02-06 18:07:17,099 train INFO: [4340/46609/10000]  lr: 9.817180450166691e-05  eta: 0:11:59  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0197)  train/logits_fake: 0.0193 (0.0193, 0.0201)  train/total_loss: 9500.8242 (13479.5566, 5630.8950)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 103638.5156 (68621.3876, 103638.5156)  train/nll_loss: 9500.7109 (13479.4879, 5630.7915)  train/rec_loss: 0.0412 (0.0585, 0.0244)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0201)
2025-02-06 18:07:19,630 train INFO: [4360/46609/10000]  lr: 9.815501777210306e-05  eta: 0:11:56  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0177)  train/logits_fake: 0.0193 (0.0193, 0.0194)  train/total_loss: 9454.7207 (13458.2814, 8738.2988)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 104150.8359 (68783.5781, 112292.2578)  train/nll_loss: 9454.6035 (13458.2126, 8738.1865)  train/rec_loss: 0.0410 (0.0584, 0.0379)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0194)
2025-02-06 18:07:22,162 train INFO: [4380/46609/10000]  lr: 9.81381557887614e-05  eta: 0:11:54  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0196)  train/logits_fake: 0.0193 (0.0193, 0.0197)  train/total_loss: 9217.5605 (13437.2312, 7368.0459)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 104207.2344 (68942.0636, 79915.0703)  train/nll_loss: 9217.4551 (13437.1623, 7367.9658)  train/rec_loss: 0.0400 (0.0583, 0.0320)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0197)
2025-02-06 18:07:24,700 train INFO: [4400/46609/10000]  lr: 9.812121857826931e-05  eta: 0:11:51  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0189)  train/logits_fake: 0.0192 (0.0193, 0.0189)  train/total_loss: 8676.5596 (13416.6616, 7771.1167)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 105860.4219 (69125.0378, 121494.7656)  train/nll_loss: 8676.4658 (13416.5924, 7770.9951)  train/rec_loss: 0.0377 (0.0582, 0.0337)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0189)
2025-02-06 18:07:27,241 train INFO: [4420/46609/10000]  lr: 9.810420616737296e-05  eta: 0:11:49  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0172)  train/logits_fake: 0.0192 (0.0193, 0.0172)  train/total_loss: 8676.5596 (13396.0440, 9434.0508)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 106956.0625 (69300.5903, 125249.2188)  train/nll_loss: 8676.4658 (13395.9747, 9433.9258)  train/rec_loss: 0.0377 (0.0581, 0.0409)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0172)
2025-02-06 18:07:29,784 train INFO: [4440/46609/10000]  lr: 9.808711858293728e-05  eta: 0:11:46  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0180)  train/logits_fake: 0.0192 (0.0193, 0.0182)  train/total_loss: 8470.2197 (13371.7358, 9447.2383)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 106956.0625 (69470.2350, 109491.9844)  train/nll_loss: 8470.1289 (13371.6664, 9447.1289)  train/rec_loss: 0.0368 (0.0580, 0.0410)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0182)
2025-02-06 18:07:32,327 train INFO: [4460/46609/10000]  lr: 9.806995585194588e-05  eta: 0:11:43  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0168)  train/logits_fake: 0.0192 (0.0193, 0.0170)  train/total_loss: 8873.0205 (13353.8542, 9357.8496)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 107249.6953 (69630.0512, 107249.6953)  train/nll_loss: 8872.9385 (13353.7846, 9357.7422)  train/rec_loss: 0.0385 (0.0580, 0.0406)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0170)
2025-02-06 18:07:34,867 train INFO: [4480/46609/10000]  lr: 9.805271800150107e-05  eta: 0:11:41  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0177)  train/logits_fake: 0.0192 (0.0193, 0.0169)  train/total_loss: 8875.4268 (13334.4557, 7460.6235)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 106956.0625 (69782.6246, 116259.4844)  train/nll_loss: 8875.3223 (13334.3860, 7460.5073)  train/rec_loss: 0.0385 (0.0579, 0.0324)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0169)
2025-02-06 18:07:37,404 train INFO: [4500/46609/10000]  lr: 9.803540505882376e-05  eta: 0:11:38  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0190)  train/logits_fake: 0.0192 (0.0193, 0.0188)  train/total_loss: 8885.4658 (13313.7277, 9194.6592)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 106939.2578 (69954.5378, 108314.2656)  train/nll_loss: 8885.3652 (13313.6578, 9194.5508)  train/rec_loss: 0.0386 (0.0578, 0.0399)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0188)
2025-02-06 18:07:39,948 train INFO: [4520/46609/10000]  lr: 9.801801705125344e-05  eta: 0:11:36  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0153)  train/logits_fake: 0.0193 (0.0193, 0.0158)  train/total_loss: 8885.4658 (13295.0597, 8890.1338)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 106939.2578 (70126.7329, 104930.4375)  train/nll_loss: 8885.3652 (13294.9895, 8890.0293)  train/rec_loss: 0.0386 (0.0577, 0.0386)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0158)
2025-02-06 18:07:42,493 train INFO: [4540/46609/10000]  lr: 9.800055400624818e-05  eta: 0:11:33  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0222)  train/logits_fake: 0.0193 (0.0193, 0.0212)  train/total_loss: 9004.9609 (13277.9629, 17448.0332)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 106378.4297 (70292.7368, 99623.9531)  train/nll_loss: 9004.8457 (13277.8926, 17447.9336)  train/rec_loss: 0.0391 (0.0576, 0.0757)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0212)
2025-02-06 18:07:45,034 train INFO: [4560/46609/10000]  lr: 9.798301595138447e-05  eta: 0:11:31  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0199)  train/logits_fake: 0.0193 (0.0193, 0.0210)  train/total_loss: 8890.1338 (13262.0215, 8880.2754)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 106825.6328 (70469.4413, 112025.2500)  train/nll_loss: 8890.0293 (13261.9511, 8880.1631)  train/rec_loss: 0.0386 (0.0576, 0.0385)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0210)
2025-02-06 18:07:47,575 train INFO: [4580/46609/10000]  lr: 9.796540291435734e-05  eta: 0:11:28  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0189)  train/logits_fake: 0.0191 (0.0193, 0.0199)  train/total_loss: 9004.9609 (13246.5399, 8993.6035)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 109243.4609 (70647.8739, 130452.1484)  train/nll_loss: 9004.8457 (13246.4692, 8993.4727)  train/rec_loss: 0.0391 (0.0575, 0.0390)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0199)
2025-02-06 18:07:50,115 train INFO: [4600/46609/10000]  lr: 9.794771492298013e-05  eta: 0:11:26  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0185)  train/logits_fake: 0.0193 (0.0193, 0.0187)  train/total_loss: 8981.0078 (13227.1589, 9390.4658)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 109243.4609 (70825.3975, 139265.3281)  train/nll_loss: 8980.8809 (13227.0881, 9390.3262)  train/rec_loss: 0.0390 (0.0574, 0.0408)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0187)
2025-02-06 18:07:52,653 train INFO: [4620/46609/10000]  lr: 9.792995200518464e-05  eta: 0:11:23  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0166)  train/logits_fake: 0.0191 (0.0193, 0.0177)  train/total_loss: 8993.6035 (13208.3746, 11206.1230)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 108493.0938 (70992.6218, 107625.3281)  train/nll_loss: 8993.4727 (13208.3036, 11206.0156)  train/rec_loss: 0.0390 (0.0573, 0.0486)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0177)
2025-02-06 18:07:55,190 train INFO: [4640/46609/10000]  lr: 9.791211418902089e-05  eta: 0:11:21  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0177)  train/logits_fake: 0.0191 (0.0193, 0.0177)  train/total_loss: 8982.3906 (13190.6377, 6564.0049)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 108187.7578 (71140.4224, 107420.6953)  train/nll_loss: 8982.2920 (13190.5666, 6563.8975)  train/rec_loss: 0.0390 (0.0573, 0.0285)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0177)
2025-02-06 18:07:57,730 train INFO: [4660/46609/10000]  lr: 9.789420150265727e-05  eta: 0:11:18  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0194)  train/logits_fake: 0.0191 (0.0193, 0.0186)  train/total_loss: 8981.0078 (13171.3422, 7010.8882)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 108493.0938 (71322.6419, 115753.2266)  train/nll_loss: 8980.8809 (13171.2709, 7010.7725)  train/rec_loss: 0.0390 (0.0572, 0.0304)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0186)
2025-02-06 18:08:00,283 train INFO: [4680/46609/10000]  lr: 9.787621397438034e-05  eta: 0:11:16  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0179)  train/logits_fake: 0.0192 (0.0193, 0.0179)  train/total_loss: 8697.0205 (13154.3768, 7931.3369)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 109172.3281 (71491.6531, 111063.6016)  train/nll_loss: 8696.9131 (13154.3053, 7931.2261)  train/rec_loss: 0.0377 (0.0571, 0.0344)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0179)
2025-02-06 18:08:02,831 train INFO: [4700/46609/10000]  lr: 9.785815163259485e-05  eta: 0:11:13  iter_time: 0.128  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0192)  train/logits_fake: 0.0191 (0.0193, 0.0205)  train/total_loss: 8907.1719 (13139.0753, 11578.1680)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 109172.3281 (71662.0368, 115655.1328)  train/nll_loss: 8907.0391 (13139.0037, 11578.0527)  train/rec_loss: 0.0387 (0.0570, 0.0503)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0205)
2025-02-06 18:08:05,371 train INFO: [4720/46609/10000]  lr: 9.784001450582375e-05  eta: 0:11:10  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0175)  train/logits_fake: 0.0191 (0.0193, 0.0184)  train/total_loss: 8714.1758 (13118.9935, 8022.9121)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 111242.5469 (71842.0066, 135966.7500)  train/nll_loss: 8714.0449 (13118.9217, 8022.7764)  train/rec_loss: 0.0378 (0.0569, 0.0348)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0184)
2025-02-06 18:08:07,908 train INFO: [4740/46609/10000]  lr: 9.782180262270797e-05  eta: 0:11:08  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0179)  train/logits_fake: 0.0191 (0.0193, 0.0178)  train/total_loss: 8714.1758 (13101.3973, 7624.9839)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 111242.5469 (71984.3735, 128028.0703)  train/nll_loss: 8714.0449 (13101.3253, 7624.8560)  train/rec_loss: 0.0378 (0.0569, 0.0331)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0178)
2025-02-06 18:08:10,447 train INFO: [4760/46609/10000]  lr: 9.78035160120066e-05  eta: 0:11:05  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0193)  train/logits_fake: 0.0191 (0.0193, 0.0195)  train/total_loss: 8880.3867 (13084.6217, 9853.1904)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 111063.6016 (72153.2246, 115240.2656)  train/nll_loss: 8880.2871 (13084.5496, 9853.0752)  train/rec_loss: 0.0385 (0.0568, 0.0428)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0195)
2025-02-06 18:08:12,991 train INFO: [4780/46609/10000]  lr: 9.77851547025967e-05  eta: 0:11:03  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0200)  train/logits_fake: 0.0191 (0.0193, 0.0185)  train/total_loss: 8966.0146 (13070.1588, 9342.3818)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 109623.1719 (72321.6341, 113380.1406)  train/nll_loss: 8965.9258 (13070.0864, 9342.2686)  train/rec_loss: 0.0389 (0.0567, 0.0405)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0185)
2025-02-06 18:08:15,538 train INFO: [4800/46609/10000]  lr: 9.776671872347327e-05  eta: 0:11:00  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0189)  train/logits_fake: 0.0191 (0.0193, 0.0189)  train/total_loss: 8853.6113 (13052.0453, 5642.2217)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 111396.2188 (72483.1379, 95464.5781)  train/nll_loss: 8853.4883 (13051.9728, 5642.1260)  train/rec_loss: 0.0384 (0.0566, 0.0245)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0189)
2025-02-06 18:08:18,085 train INFO: [4820/46609/10000]  lr: 9.774820810374925e-05  eta: 0:10:58  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0160)  train/logits_fake: 0.0192 (0.0193, 0.0167)  train/total_loss: 8853.6113 (13032.3351, 10197.8711)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 111396.2188 (72650.8400, 131240.6406)  train/nll_loss: 8853.4883 (13032.2624, 10197.7402)  train/rec_loss: 0.0384 (0.0566, 0.0443)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0167)
2025-02-06 18:08:20,623 train INFO: [4840/46609/10000]  lr: 9.77296228726554e-05  eta: 0:10:55  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0197)  train/logits_fake: 0.0192 (0.0192, 0.0191)  train/total_loss: 8725.6279 (13011.3239, 8006.1055)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 111396.2188 (72807.5545, 110373.4688)  train/nll_loss: 8725.5215 (13011.2511, 8005.9951)  train/rec_loss: 0.0379 (0.0565, 0.0347)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0191)
2025-02-06 18:08:23,169 train INFO: [4860/46609/10000]  lr: 9.771096305954038e-05  eta: 0:10:53  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0180)  train/logits_fake: 0.0192 (0.0192, 0.0182)  train/total_loss: 8635.9688 (12993.6876, 6537.0674)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 110709.2500 (72956.2831, 92624.3281)  train/nll_loss: 8635.8291 (12993.6146, 6536.9746)  train/rec_loss: 0.0375 (0.0564, 0.0284)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0182)
2025-02-06 18:08:25,710 train INFO: [4880/46609/10000]  lr: 9.769222869387056e-05  eta: 0:10:50  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0204)  train/logits_fake: 0.0192 (0.0192, 0.0209)  train/total_loss: 8335.6914 (12973.3651, 6525.5454)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 112694.6016 (73146.2759, 90170.6719)  train/nll_loss: 8335.5781 (12973.2919, 6525.4551)  train/rec_loss: 0.0362 (0.0563, 0.0283)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0209)
2025-02-06 18:08:28,256 train INFO: [4900/46609/10000]  lr: 9.767341980523007e-05  eta: 0:10:48  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0200)  train/logits_fake: 0.0193 (0.0193, 0.0209)  train/total_loss: 8335.6914 (12955.3596, 10065.8135)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 112044.2656 (73285.3707, 116512.9062)  train/nll_loss: 8335.5781 (12955.2863, 10065.6973)  train/rec_loss: 0.0362 (0.0562, 0.0437)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0209)
2025-02-06 18:08:30,791 train INFO: [4920/46609/10000]  lr: 9.765453642332069e-05  eta: 0:10:45  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0183)  train/logits_fake: 0.0192 (0.0192, 0.0178)  train/total_loss: 8295.1973 (12937.6342, 8387.5381)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 111203.3750 (73446.6183, 97991.7578)  train/nll_loss: 8295.0645 (12937.5608, 8387.4404)  train/rec_loss: 0.0360 (0.0562, 0.0364)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0178)
2025-02-06 18:08:33,323 train INFO: [4940/46609/10000]  lr: 9.763557857796189e-05  eta: 0:10:42  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0183)  train/logits_fake: 0.0192 (0.0192, 0.0192)  train/total_loss: 8295.1973 (12919.7648, 9010.6826)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 113024.3359 (73596.3119, 89793.3750)  train/nll_loss: 8295.0645 (12919.6912, 9010.5928)  train/rec_loss: 0.0360 (0.0561, 0.0391)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0192)
2025-02-06 18:08:35,866 train INFO: [4960/46609/10000]  lr: 9.761654629909068e-05  eta: 0:10:40  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0194)  train/logits_fake: 0.0192 (0.0192, 0.0201)  train/total_loss: 8335.6914 (12903.4890, 7375.7505)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 113714.0156 (73767.6300, 87441.2188)  train/nll_loss: 8335.5781 (12903.4152, 7375.6631)  train/rec_loss: 0.0362 (0.0560, 0.0320)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0201)
2025-02-06 18:08:38,403 train INFO: [4980/46609/10000]  lr: 9.759743961676163e-05  eta: 0:10:37  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0180)  train/logits_fake: 0.0192 (0.0193, 0.0183)  train/total_loss: 8218.9834 (12882.6132, 10258.5605)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 111878.0469 (73904.3934, 112974.4688)  train/nll_loss: 8218.8740 (12882.5393, 10258.4473)  train/rec_loss: 0.0357 (0.0559, 0.0445)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0183)
2025-02-06 18:08:40,945 train INFO: [5000/46609/10000]  lr: 9.757825856114678e-05  eta: 0:10:35  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0203)  train/logits_fake: 0.0191 (0.0193, 0.0201)  train/total_loss: 8218.9834 (12866.0468, 6504.2075)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 112038.2969 (74064.7742, 93314.0000)  train/nll_loss: 8218.8740 (12865.9727, 6504.1143)  train/rec_loss: 0.0357 (0.0558, 0.0282)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0201)
2025-02-06 18:08:43,475 train INFO: [5020/46609/10000]  lr: 9.755900316253567e-05  eta: 0:10:32  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0191)  train/logits_fake: 0.0192 (0.0192, 0.0175)  train/total_loss: 8150.9473 (12850.2355, 11768.4570)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 112859.6719 (74229.0159, 119809.3750)  train/nll_loss: 8150.8457 (12850.1612, 11768.3369)  train/rec_loss: 0.0354 (0.0558, 0.0511)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0175)
2025-02-06 18:08:46,011 train INFO: [5040/46609/10000]  lr: 9.753967345133516e-05  eta: 0:10:30  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0200)  train/logits_fake: 0.0192 (0.0192, 0.0193)  train/total_loss: 8290.2607 (12834.0981, 9311.4248)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 114183.0234 (74393.2874, 130091.8438)  train/nll_loss: 8290.1504 (12834.0237, 9311.2949)  train/rec_loss: 0.0360 (0.0557, 0.0404)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0193)
2025-02-06 18:08:48,547 train INFO: [5060/46609/10000]  lr: 9.752026945806955e-05  eta: 0:10:27  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0174)  train/logits_fake: 0.0192 (0.0192, 0.0197)  train/total_loss: 8210.6836 (12818.3845, 15964.7568)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 112880.2734 (74529.8602, 91054.9688)  train/nll_loss: 8210.5674 (12818.3100, 15964.6660)  train/rec_loss: 0.0356 (0.0556, 0.0693)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0197)
2025-02-06 18:08:51,084 train INFO: [5080/46609/10000]  lr: 9.750079121338035e-05  eta: 0:10:25  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0205)  train/logits_fake: 0.0192 (0.0192, 0.0206)  train/total_loss: 8495.8965 (12802.7514, 7624.2432)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 114724.1250 (74675.0208, 98218.7969)  train/nll_loss: 8495.7676 (12802.6768, 7624.1450)  train/rec_loss: 0.0369 (0.0556, 0.0331)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0206)
2025-02-06 18:08:53,621 train INFO: [5100/46609/10000]  lr: 9.748123874802639e-05  eta: 0:10:22  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0207)  train/logits_fake: 0.0192 (0.0192, 0.0198)  train/total_loss: 8646.8613 (12787.7360, 10295.6660)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 115744.5391 (74861.2502, 113098.2266)  train/nll_loss: 8646.7490 (12787.6612, 10295.5527)  train/rec_loss: 0.0375 (0.0555, 0.0447)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0198)
2025-02-06 18:08:56,156 train INFO: [5120/46609/10000]  lr: 9.746161209288368e-05  eta: 0:10:20  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0190)  train/logits_fake: 0.0193 (0.0192, 0.0197)  train/total_loss: 8646.8613 (12769.9314, 7175.0933)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 116108.1562 (75029.4692, 105358.9062)  train/nll_loss: 8646.7490 (12769.8564, 7174.9878)  train/rec_loss: 0.0375 (0.0554, 0.0311)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0197)
2025-02-06 18:08:58,694 train INFO: [5140/46609/10000]  lr: 9.74419112789454e-05  eta: 0:10:17  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0182)  train/logits_fake: 0.0193 (0.0192, 0.0184)  train/total_loss: 8626.1904 (12753.3322, 11694.0557)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 114329.7344 (75173.7317, 112015.6719)  train/nll_loss: 8626.0918 (12753.2570, 11693.9434)  train/rec_loss: 0.0374 (0.0554, 0.0508)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0184)
2025-02-06 18:09:01,232 train INFO: [5160/46609/10000]  lr: 9.742213633732179e-05  eta: 0:10:14  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0184)  train/logits_fake: 0.0194 (0.0193, 0.0198)  train/total_loss: 8382.2715 (12735.0294, 9879.4111)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 115237.3281 (75330.5935, 94505.3516)  train/nll_loss: 8382.1406 (12734.9541, 9879.3164)  train/rec_loss: 0.0364 (0.0553, 0.0429)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0198)
2025-02-06 18:09:03,766 train INFO: [5180/46609/10000]  lr: 9.740228729924023e-05  eta: 0:10:12  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0200)  train/logits_fake: 0.0192 (0.0193, 0.0196)  train/total_loss: 8213.6064 (12718.7295, 11064.6719)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 115272.0312 (75471.9721, 130005.0781)  train/nll_loss: 8213.4844 (12718.6540, 11064.5420)  train/rec_loss: 0.0356 (0.0552, 0.0480)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0196)
2025-02-06 18:09:06,298 train INFO: [5200/46609/10000]  lr: 9.7382364196045e-05  eta: 0:10:09  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0189)  train/logits_fake: 0.0192 (0.0193, 0.0180)  train/total_loss: 8096.0244 (12702.1695, 8810.0059)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 115116.1797 (75629.3358, 142771.9531)  train/nll_loss: 8095.9102 (12702.0938, 8809.8633)  train/rec_loss: 0.0351 (0.0551, 0.0382)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0180)
2025-02-06 18:09:08,835 train INFO: [5220/46609/10000]  lr: 9.736236705919744e-05  eta: 0:10:07  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0211)  train/logits_fake: 0.0192 (0.0192, 0.0211)  train/total_loss: 8414.2295 (12686.3851, 9768.8428)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 114329.7344 (75785.0366, 86919.1484)  train/nll_loss: 8414.1113 (12686.3093, 9768.7559)  train/rec_loss: 0.0365 (0.0551, 0.0424)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0211)
2025-02-06 18:09:11,373 train INFO: [5240/46609/10000]  lr: 9.734229592027576e-05  eta: 0:10:04  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0189)  train/logits_fake: 0.0193 (0.0193, 0.0187)  train/total_loss: 8439.1348 (12671.9198, 7609.0376)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 115294.3750 (75936.4224, 114180.6719)  train/nll_loss: 8439.0195 (12671.8439, 7608.9233)  train/rec_loss: 0.0366 (0.0550, 0.0330)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0187)
2025-02-06 18:09:13,907 train INFO: [5260/46609/10000]  lr: 9.732215081097501e-05  eta: 0:10:02  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0210)  train/logits_fake: 0.0193 (0.0193, 0.0207)  train/total_loss: 8513.9238 (12654.2216, 7304.3379)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 115270.6250 (76079.8580, 110311.4375)  train/nll_loss: 8513.8027 (12654.1455, 7304.2275)  train/rec_loss: 0.0370 (0.0549, 0.0317)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0207)
2025-02-06 18:09:16,443 train INFO: [5280/46609/10000]  lr: 9.73019317631071e-05  eta: 0:09:59  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0194 (0.0191, 0.0190)  train/logits_fake: 0.0193 (0.0193, 0.0191)  train/total_loss: 8250.4863 (12635.6440, 6628.2773)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 115179.3672 (76216.7713, 92693.2969)  train/nll_loss: 8250.3994 (12635.5678, 6628.1846)  train/rec_loss: 0.0358 (0.0548, 0.0288)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0191)
2025-02-06 18:09:18,974 train INFO: [5300/46609/10000]  lr: 9.728163880860061e-05  eta: 0:09:57  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0195 (0.0191, 0.0173)  train/logits_fake: 0.0195 (0.0193, 0.0190)  train/total_loss: 8190.6733 (12617.1635, 9285.3428)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 114094.8203 (76367.8892, 106053.0156)  train/nll_loss: 8190.5352 (12617.0872, 9285.2363)  train/rec_loss: 0.0355 (0.0548, 0.0403)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0190)
2025-02-06 18:09:21,511 train INFO: [5320/46609/10000]  lr: 9.726127197950094e-05  eta: 0:09:54  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0194 (0.0191, 0.0178)  train/logits_fake: 0.0195 (0.0193, 0.0177)  train/total_loss: 8012.5234 (12601.6351, 7615.3984)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 114657.9688 (76525.1016, 120318.7109)  train/nll_loss: 8012.4253 (12601.5585, 7615.2783)  train/rec_loss: 0.0348 (0.0547, 0.0331)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0177)
2025-02-06 18:09:24,047 train INFO: [5340/46609/10000]  lr: 9.724083130797005e-05  eta: 0:09:52  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0192)  train/logits_fake: 0.0195 (0.0193, 0.0183)  train/total_loss: 8014.1313 (12584.7672, 8576.9746)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 114333.2578 (76656.1719, 122936.1797)  train/nll_loss: 8014.0381 (12584.6905, 8576.8516)  train/rec_loss: 0.0348 (0.0546, 0.0372)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0183)
2025-02-06 18:09:26,595 train INFO: [5360/46609/10000]  lr: 9.722031682628658e-05  eta: 0:09:49  iter_time: 0.127  data: 0.001  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0187)  train/logits_fake: 0.0194 (0.0193, 0.0179)  train/total_loss: 7989.9629 (12567.1885, 6978.4146)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 115432.2500 (76821.5992, 147983.7031)  train/nll_loss: 7989.8442 (12567.1117, 6978.2666)  train/rec_loss: 0.0347 (0.0545, 0.0303)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0179)
2025-02-06 18:09:29,138 train INFO: [5380/46609/10000]  lr: 9.71997285668457e-05  eta: 0:09:46  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0185)  train/logits_fake: 0.0193 (0.0193, 0.0194)  train/total_loss: 8010.9619 (12551.1143, 10014.3193)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 116012.5156 (76971.8011, 113368.1953)  train/nll_loss: 8010.8306 (12551.0374, 10014.2061)  train/rec_loss: 0.0348 (0.0545, 0.0435)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0194)
2025-02-06 18:09:31,673 train INFO: [5400/46609/10000]  lr: 9.717906656215905e-05  eta: 0:09:44  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0209)  train/logits_fake: 0.0192 (0.0193, 0.0207)  train/total_loss: 7972.5430 (12534.6717, 6757.5381)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 116037.4922 (77136.6749, 101152.1406)  train/nll_loss: 7972.4277 (12534.5946, 6757.4370)  train/rec_loss: 0.0346 (0.0544, 0.0293)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0207)
2025-02-06 18:09:34,210 train INFO: [5420/46609/10000]  lr: 9.715833084485479e-05  eta: 0:09:41  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0201)  train/logits_fake: 0.0193 (0.0193, 0.0205)  train/total_loss: 7953.6543 (12518.9100, 5904.9766)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 117616.5000 (77306.0477, 89298.7500)  train/nll_loss: 7953.5503 (12518.8327, 5904.8872)  train/rec_loss: 0.0345 (0.0543, 0.0256)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0205)
2025-02-06 18:09:36,752 train INFO: [5440/46609/10000]  lr: 9.713752144767742e-05  eta: 0:09:39  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0213)  train/logits_fake: 0.0191 (0.0193, 0.0204)  train/total_loss: 7888.5903 (12502.6055, 7548.1611)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 119715.3594 (77469.0114, 114895.7266)  train/nll_loss: 7888.4688 (12502.5280, 7548.0464)  train/rec_loss: 0.0342 (0.0543, 0.0328)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0204)
2025-02-06 18:09:39,286 train INFO: [5460/46609/10000]  lr: 9.711663840348785e-05  eta: 0:09:36  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0192)  train/logits_fake: 0.0192 (0.0193, 0.0197)  train/total_loss: 7876.8110 (12486.8550, 6824.2466)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 118219.7656 (77604.2637, 90335.5938)  train/nll_loss: 7876.6968 (12486.7774, 6824.1562)  train/rec_loss: 0.0342 (0.0542, 0.0296)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0197)
2025-02-06 18:09:41,821 train INFO: [5480/46609/10000]  lr: 9.709568174526323e-05  eta: 0:09:34  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0205)  train/logits_fake: 0.0193 (0.0193, 0.0203)  train/total_loss: 7826.7603 (12470.5257, 7995.0381)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 118219.7656 (77743.9095, 121292.0078)  train/nll_loss: 7826.6377 (12470.4480, 7994.9170)  train/rec_loss: 0.0340 (0.0541, 0.0347)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0203)
2025-02-06 18:09:44,357 train INFO: [5500/46609/10000]  lr: 9.7074651506097e-05  eta: 0:09:31  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0196)  train/logits_fake: 0.0192 (0.0193, 0.0200)  train/total_loss: 7803.3013 (12452.6127, 5289.3140)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 119045.7969 (77890.0154, 86518.9531)  train/nll_loss: 7803.1821 (12452.5348, 5289.2275)  train/rec_loss: 0.0339 (0.0540, 0.0230)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0200)
2025-02-06 18:09:46,894 train INFO: [5520/46609/10000]  lr: 9.705354771919877e-05  eta: 0:09:29  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0185)  train/logits_fake: 0.0192 (0.0193, 0.0179)  train/total_loss: 7717.6870 (12437.5783, 6495.6313)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 119220.9922 (78056.2040, 132027.8438)  train/nll_loss: 7717.5649 (12437.5002, 6495.4995)  train/rec_loss: 0.0335 (0.0540, 0.0282)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0179)
2025-02-06 18:09:49,438 train INFO: [5540/46609/10000]  lr: 9.703237041789428e-05  eta: 0:09:26  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0183)  train/logits_fake: 0.0192 (0.0192, 0.0187)  train/total_loss: 7717.6870 (12422.4163, 7837.9521)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 117490.5156 (78199.6664, 117777.8281)  train/nll_loss: 7717.5649 (12422.3381, 7837.8345)  train/rec_loss: 0.0335 (0.0539, 0.0340)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0187)
2025-02-06 18:09:51,978 train INFO: [5560/46609/10000]  lr: 9.701111963562542e-05  eta: 0:09:24  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0198)  train/logits_fake: 0.0191 (0.0192, 0.0198)  train/total_loss: 7803.3013 (12406.4867, 9406.5283)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 117777.8281 (78342.5819, 108168.0781)  train/nll_loss: 7803.1821 (12406.4083, 9406.4199)  train/rec_loss: 0.0339 (0.0538, 0.0408)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0198)
2025-02-06 18:09:54,520 train INFO: [5580/46609/10000]  lr: 9.698979540595005e-05  eta: 0:09:21  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0188 (0.0191, 0.0192)  train/logits_fake: 0.0190 (0.0192, 0.0192)  train/total_loss: 7828.5020 (12392.8365, 11749.7695)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 119220.9922 (78480.1411, 107035.5703)  train/nll_loss: 7828.3784 (12392.7581, 11749.6621)  train/rec_loss: 0.0340 (0.0538, 0.0510)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0192)
2025-02-06 18:09:57,066 train INFO: [5600/46609/10000]  lr: 9.696839776254204e-05  eta: 0:09:19  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0189)  train/logits_fake: 0.0191 (0.0192, 0.0197)  train/total_loss: 7953.6860 (12378.9063, 9479.1973)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 115975.2422 (78606.9104, 129295.6562)  train/nll_loss: 7953.5698 (12378.8277, 9479.0684)  train/rec_loss: 0.0345 (0.0537, 0.0411)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0197)
2025-02-06 18:09:59,606 train INFO: [5620/46609/10000]  lr: 9.694692673919121e-05  eta: 0:09:16  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0199)  train/logits_fake: 0.0191 (0.0192, 0.0220)  train/total_loss: 7953.6860 (12364.9670, 9452.2998)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 115350.4922 (78742.5663, 132097.1406)  train/nll_loss: 7953.5698 (12364.8882, 9452.1680)  train/rec_loss: 0.0345 (0.0537, 0.0410)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0220)
2025-02-06 18:10:02,144 train INFO: [5640/46609/10000]  lr: 9.69253823698032e-05  eta: 0:09:13  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0197)  train/logits_fake: 0.0192 (0.0192, 0.0205)  train/total_loss: 7997.3203 (12352.1098, 8411.3936)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 115090.2031 (78881.3158, 107598.7422)  train/nll_loss: 7997.1943 (12352.0309, 8411.2861)  train/rec_loss: 0.0347 (0.0536, 0.0365)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0205)
2025-02-06 18:10:04,680 train INFO: [5660/46609/10000]  lr: 9.690376468839956e-05  eta: 0:09:11  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0210)  train/logits_fake: 0.0192 (0.0192, 0.0212)  train/total_loss: 8037.9937 (12338.1834, 7011.7476)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 114292.2500 (79013.7768, 121565.0312)  train/nll_loss: 8037.8823 (12338.1044, 7011.6260)  train/rec_loss: 0.0349 (0.0536, 0.0304)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0212)
2025-02-06 18:10:07,213 train INFO: [5680/46609/10000]  lr: 9.688207372911751e-05  eta: 0:09:08  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0201)  train/logits_fake: 0.0192 (0.0192, 0.0189)  train/total_loss: 8137.7568 (12323.2142, 8647.7002)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 115350.4922 (79171.7925, 122230.9844)  train/nll_loss: 8137.6641 (12323.1350, 8647.5781)  train/rec_loss: 0.0353 (0.0535, 0.0375)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0189)
2025-02-06 18:10:09,746 train INFO: [5700/46609/10000]  lr: 9.686030952621007e-05  eta: 0:09:06  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0201)  train/logits_fake: 0.0192 (0.0192, 0.0206)  train/total_loss: 7918.4097 (12305.9646, 7468.7988)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 117774.1875 (79325.8310, 110674.2031)  train/nll_loss: 7918.2578 (12305.8852, 7468.6880)  train/rec_loss: 0.0344 (0.0534, 0.0324)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0206)
2025-02-06 18:10:12,274 train INFO: [5720/46609/10000]  lr: 9.683847211404587e-05  eta: 0:09:03  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0187)  train/logits_fake: 0.0191 (0.0192, 0.0175)  train/total_loss: 7918.4097 (12292.3281, 9322.2129)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 120442.4375 (79468.7212, 117586.6562)  train/nll_loss: 7918.2578 (12292.2486, 9322.0957)  train/rec_loss: 0.0344 (0.0534, 0.0405)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0175)
2025-02-06 18:10:14,804 train INFO: [5740/46609/10000]  lr: 9.681656152710917e-05  eta: 0:09:01  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0184)  train/logits_fake: 0.0191 (0.0192, 0.0180)  train/total_loss: 7821.5703 (12275.2237, 5932.5864)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 120126.3750 (79600.5580, 112732.5312)  train/nll_loss: 7821.4502 (12275.1441, 5932.4736)  train/rec_loss: 0.0339 (0.0533, 0.0257)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0180)
2025-02-06 18:10:17,336 train INFO: [5760/46609/10000]  lr: 9.679457779999978e-05  eta: 0:08:58  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0197)  train/logits_fake: 0.0190 (0.0192, 0.0199)  train/total_loss: 7772.9561 (12261.4723, 5523.6089)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 120528.3125 (79749.5404, 115014.6406)  train/nll_loss: 7772.8057 (12261.3926, 5523.4937)  train/rec_loss: 0.0337 (0.0532, 0.0240)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0192, -0.0199)
2025-02-06 18:10:19,870 train INFO: [5780/46609/10000]  lr: 9.677252096743299e-05  eta: 0:08:56  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0199)  train/logits_fake: 0.0191 (0.0192, 0.0200)  train/total_loss: 7821.5703 (12246.4983, 6792.4595)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 114782.1562 (79861.9139, 103898.7188)  train/nll_loss: 7821.4502 (12246.4185, 6792.3555)  train/rec_loss: 0.0339 (0.0532, 0.0295)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0200)
2025-02-06 18:10:22,416 train INFO: [5800/46609/10000]  lr: 9.675039106423956e-05  eta: 0:08:53  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0180)  train/logits_fake: 0.0191 (0.0192, 0.0180)  train/total_loss: 7883.1089 (12232.9510, 7556.9023)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 114782.1562 (80007.8449, 123834.6172)  train/nll_loss: 7882.9990 (12232.8710, 7556.7783)  train/rec_loss: 0.0342 (0.0531, 0.0328)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0180)
2025-02-06 18:10:24,962 train INFO: [5820/46609/10000]  lr: 9.672818812536565e-05  eta: 0:08:51  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0204)  train/logits_fake: 0.0192 (0.0192, 0.0200)  train/total_loss: 7883.1089 (12219.0952, 8872.2051)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 116264.9531 (80148.0721, 122031.5703)  train/nll_loss: 7882.9990 (12219.0151, 8872.0830)  train/rec_loss: 0.0342 (0.0530, 0.0385)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0200)
2025-02-06 18:10:27,499 train INFO: [5840/46609/10000]  lr: 9.670591218587268e-05  eta: 0:08:48  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0180)  train/logits_fake: 0.0192 (0.0192, 0.0187)  train/total_loss: 7952.7192 (12202.3860, 8990.9180)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 116771.9375 (80288.1044, 119823.1328)  train/nll_loss: 7952.5977 (12202.3057, 8990.7979)  train/rec_loss: 0.0345 (0.0530, 0.0390)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0187)
2025-02-06 18:10:30,034 train INFO: [5860/46609/10000]  lr: 9.668356328093746e-05  eta: 0:08:45  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0196)  train/logits_fake: 0.0193 (0.0192, 0.0185)  train/total_loss: 7577.4634 (12185.0313, 7356.9414)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 116910.1875 (80438.5468, 111604.7812)  train/nll_loss: 7577.3379 (12184.9508, 7356.8296)  train/rec_loss: 0.0329 (0.0529, 0.0319)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0185)
2025-02-06 18:10:32,577 train INFO: [5880/46609/10000]  lr: 9.666114144585191e-05  eta: 0:08:43  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0192)  train/logits_fake: 0.0192 (0.0192, 0.0189)  train/total_loss: 7621.9561 (12170.8966, 8664.1807)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 119823.1328 (80584.1067, 125562.6875)  train/nll_loss: 7621.8164 (12170.8160, 8664.0547)  train/rec_loss: 0.0331 (0.0528, 0.0376)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0189)
2025-02-06 18:10:35,123 train INFO: [5900/46609/10000]  lr: 9.663864671602321e-05  eta: 0:08:40  iter_time: 0.127  data: 0.001  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0193)  train/logits_fake: 0.0192 (0.0192, 0.0187)  train/total_loss: 7830.5732 (12160.3920, 7722.7998)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 119823.1328 (80728.7157, 125809.7500)  train/nll_loss: 7830.4580 (12160.3112, 7722.6738)  train/rec_loss: 0.0340 (0.0528, 0.0335)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0187)
2025-02-06 18:10:37,669 train INFO: [5920/46609/10000]  lr: 9.661607912697357e-05  eta: 0:08:38  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0178)  train/logits_fake: 0.0190 (0.0192, 0.0167)  train/total_loss: 7973.8560 (12149.0421, 8187.5088)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 120680.1328 (80874.7123, 131432.7188)  train/nll_loss: 7973.7261 (12148.9612, 8187.3774)  train/rec_loss: 0.0346 (0.0527, 0.0355)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0192, -0.0167)
2025-02-06 18:10:40,205 train INFO: [5940/46609/10000]  lr: 9.65934387143403e-05  eta: 0:08:35  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0173)  train/logits_fake: 0.0192 (0.0192, 0.0191)  train/total_loss: 8135.8740 (12139.7832, 9278.0732)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 123579.4062 (81011.7642, 149888.7500)  train/nll_loss: 8135.7451 (12139.7022, 9277.9238)  train/rec_loss: 0.0353 (0.0527, 0.0403)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0191)
2025-02-06 18:10:42,739 train INFO: [5960/46609/10000]  lr: 9.657072551387573e-05  eta: 0:08:33  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0214)  train/logits_fake: 0.0192 (0.0192, 0.0213)  train/total_loss: 8302.0830 (12125.9985, 11222.2334)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 121495.5078 (81129.8147, 113561.1016)  train/nll_loss: 8301.9355 (12125.9174, 11222.1201)  train/rec_loss: 0.0360 (0.0526, 0.0487)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0213)
2025-02-06 18:10:45,278 train INFO: [5980/46609/10000]  lr: 9.65479395614471e-05  eta: 0:08:30  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0192)  train/logits_fake: 0.0193 (0.0192, 0.0196)  train/total_loss: 8589.7891 (12116.0762, 8580.2656)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 123103.6484 (81279.5214, 137911.7656)  train/nll_loss: 8589.6611 (12115.9949, 8580.1279)  train/rec_loss: 0.0373 (0.0526, 0.0372)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0196)
2025-02-06 18:10:47,822 train INFO: [6000/46609/10000]  lr: 9.65250808930365e-05  eta: 0:08:28  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0186)  train/logits_fake: 0.0193 (0.0192, 0.0185)  train/total_loss: 8374.0498 (12103.6332, 8087.5142)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 121286.8906 (81404.8270, 114663.5000)  train/nll_loss: 8373.9219 (12103.5518, 8087.3994)  train/rec_loss: 0.0363 (0.0525, 0.0351)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0185)
2025-02-06 18:10:50,358 train INFO: [6020/46609/10000]  lr: 9.650214954474094e-05  eta: 0:08:25  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0186)  train/logits_fake: 0.0194 (0.0192, 0.0198)  train/total_loss: 8133.1631 (12089.0582, 10248.8076)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 120717.3906 (81538.5048, 125718.0547)  train/nll_loss: 8133.0527 (12088.9766, 10248.6816)  train/rec_loss: 0.0353 (0.0525, 0.0445)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0198)
2025-02-06 18:10:52,905 train INFO: [6040/46609/10000]  lr: 9.647914555277209e-05  eta: 0:08:23  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0182)  train/logits_fake: 0.0194 (0.0192, 0.0188)  train/total_loss: 8012.5898 (12078.6844, 10851.2891)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 121495.5078 (81699.9577, 127355.2656)  train/nll_loss: 8012.4707 (12078.6027, 10851.1621)  train/rec_loss: 0.0348 (0.0524, 0.0471)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0188)
2025-02-06 18:10:55,442 train INFO: [6060/46609/10000]  lr: 9.645606895345646e-05  eta: 0:08:20  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0201)  train/logits_fake: 0.0193 (0.0192, 0.0187)  train/total_loss: 8083.3584 (12065.8106, 8134.3740)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 125194.7500 (81856.1447, 125194.7500)  train/nll_loss: 8083.2393 (12065.7287, 8134.2490)  train/rec_loss: 0.0351 (0.0524, 0.0353)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0187)
2025-02-06 18:10:57,979 train INFO: [6080/46609/10000]  lr: 9.643291978323509e-05  eta: 0:08:17  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0212)  train/logits_fake: 0.0192 (0.0192, 0.0206)  train/total_loss: 8070.3394 (12055.5152, 8135.7192)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 125056.2656 (81999.1389, 115095.7344)  train/nll_loss: 8070.2041 (12055.4332, 8135.6040)  train/rec_loss: 0.0350 (0.0523, 0.0353)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0206)
2025-02-06 18:11:00,525 train INFO: [6100/46609/10000]  lr: 9.64096980786637e-05  eta: 0:08:15  iter_time: 0.127  data: 0.001  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0194)  train/logits_fake: 0.0192 (0.0192, 0.0202)  train/total_loss: 7987.2266 (12041.6683, 10451.5488)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 125718.0547 (82129.4183, 101907.0781)  train/nll_loss: 7987.1006 (12041.5862, 10451.4473)  train/rec_loss: 0.0347 (0.0523, 0.0454)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0202)
2025-02-06 18:11:03,064 train INFO: [6120/46609/10000]  lr: 9.638640387641256e-05  eta: 0:08:12  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0184)  train/logits_fake: 0.0191 (0.0192, 0.0180)  train/total_loss: 7992.2495 (12028.8659, 6905.9287)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 127992.7812 (82278.5642, 150406.0000)  train/nll_loss: 7992.1089 (12028.7836, 6905.7783)  train/rec_loss: 0.0347 (0.0522, 0.0300)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0180)
2025-02-06 18:11:05,608 train INFO: [6140/46609/10000]  lr: 9.636303721326636e-05  eta: 0:08:10  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0209)  train/logits_fake: 0.0190 (0.0192, 0.0224)  train/total_loss: 7980.4097 (12015.5867, 9376.3564)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 125785.3047 (82409.4527, 123607.7188)  train/nll_loss: 7980.2812 (12015.5042, 9376.2324)  train/rec_loss: 0.0346 (0.0522, 0.0407)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0224)
2025-02-06 18:11:08,149 train INFO: [6160/46609/10000]  lr: 9.633959812612427e-05  eta: 0:08:07  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0189)  train/logits_fake: 0.0190 (0.0192, 0.0193)  train/total_loss: 7876.4146 (12002.2861, 8965.6699)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 125080.4141 (82551.8010, 112832.0781)  train/nll_loss: 7876.2900 (12002.2035, 8965.5566)  train/rec_loss: 0.0342 (0.0521, 0.0389)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0192, -0.0193)
2025-02-06 18:11:10,687 train INFO: [6180/46609/10000]  lr: 9.631608665199979e-05  eta: 0:08:05  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0193)  train/logits_fake: 0.0192 (0.0192, 0.0198)  train/total_loss: 7815.9199 (11990.3574, 6738.7471)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 127371.8984 (82712.4049, 119584.6562)  train/nll_loss: 7815.8057 (11990.2747, 6738.6274)  train/rec_loss: 0.0339 (0.0520, 0.0292)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0198)
2025-02-06 18:11:13,225 train INFO: [6200/46609/10000]  lr: 9.629250282802076e-05  eta: 0:08:02  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0156)  train/logits_fake: 0.0192 (0.0192, 0.0160)  train/total_loss: 7905.9468 (11977.5527, 8853.7559)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 127802.0938 (82843.0719, 148526.1094)  train/nll_loss: 7905.7920 (11977.4699, 8853.6074)  train/rec_loss: 0.0343 (0.0520, 0.0384)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0160)
2025-02-06 18:11:15,766 train INFO: [6220/46609/10000]  lr: 9.626884669142927e-05  eta: 0:08:00  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0181)  train/logits_fake: 0.0192 (0.0192, 0.0181)  train/total_loss: 8002.3423 (11966.9482, 10392.3711)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 125695.8438 (82988.9907, 140766.3750)  train/nll_loss: 8002.2251 (11966.8653, 10392.2305)  train/rec_loss: 0.0347 (0.0519, 0.0451)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0181)
2025-02-06 18:11:18,306 train INFO: [6240/46609/10000]  lr: 9.624511827958155e-05  eta: 0:07:57  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0187)  train/logits_fake: 0.0194 (0.0192, 0.0186)  train/total_loss: 8206.0859 (11957.9360, 9082.6338)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 125548.6250 (83107.3457, 108340.7031)  train/nll_loss: 8205.9648 (11957.8529, 9082.5254)  train/rec_loss: 0.0356 (0.0519, 0.0394)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0186)
2025-02-06 18:11:20,852 train INFO: [6260/46609/10000]  lr: 9.622131762994803e-05  eta: 0:07:55  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0167)  train/logits_fake: 0.0195 (0.0192, 0.0178)  train/total_loss: 8220.2422 (11945.5446, 7896.5342)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 125255.9844 (83225.1194, 146444.3438)  train/nll_loss: 8220.1328 (11945.4613, 7896.3877)  train/rec_loss: 0.0357 (0.0518, 0.0343)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0178)
2025-02-06 18:11:23,394 train INFO: [6280/46609/10000]  lr: 9.619744478011319e-05  eta: 0:07:52  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0193)  train/logits_fake: 0.0193 (0.0192, 0.0194)  train/total_loss: 8170.0200 (11932.7961, 13429.5068)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 124192.5469 (83343.2458, 127733.8125)  train/nll_loss: 8169.8784 (11932.7128, 13429.3789)  train/rec_loss: 0.0355 (0.0518, 0.0583)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0194)
2025-02-06 18:11:25,940 train INFO: [6300/46609/10000]  lr: 9.617349976777549e-05  eta: 0:07:50  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0215)  train/logits_fake: 0.0192 (0.0192, 0.0213)  train/total_loss: 8153.6631 (11920.9862, 7511.8081)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 125548.6250 (83489.6912, 135051.6094)  train/nll_loss: 8153.5488 (11920.9027, 7511.6729)  train/rec_loss: 0.0354 (0.0517, 0.0326)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0213)
2025-02-06 18:11:28,468 train INFO: [6320/46609/10000]  lr: 9.61494826307474e-05  eta: 0:07:47  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0185)  train/logits_fake: 0.0192 (0.0192, 0.0201)  train/total_loss: 8249.0820 (11911.7290, 8775.4482)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 125255.9844 (83608.4037, 104397.5938)  train/nll_loss: 8248.9561 (11911.6453, 8775.3438)  train/rec_loss: 0.0358 (0.0517, 0.0381)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0201)
2025-02-06 18:11:30,995 train INFO: [6340/46609/10000]  lr: 9.612539340695525e-05  eta: 0:07:44  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0195)  train/logits_fake: 0.0192 (0.0192, 0.0199)  train/total_loss: 8099.6631 (11899.8165, 8100.4463)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 124430.6016 (83715.2204, 126906.5156)  train/nll_loss: 8099.5532 (11899.7328, 8100.3193)  train/rec_loss: 0.0352 (0.0516, 0.0352)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0199)
2025-02-06 18:11:33,533 train INFO: [6360/46609/10000]  lr: 9.61012321344392e-05  eta: 0:07:42  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0207)  train/logits_fake: 0.0190 (0.0192, 0.0197)  train/total_loss: 8249.0820 (11890.1357, 10761.8857)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 125416.6953 (83864.8268, 137547.7812)  train/nll_loss: 8248.9561 (11890.0518, 10761.7480)  train/rec_loss: 0.0358 (0.0516, 0.0467)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0197)
2025-02-06 18:11:36,067 train INFO: [6380/46609/10000]  lr: 9.607699885135321e-05  eta: 0:07:39  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0187)  train/logits_fake: 0.0192 (0.0192, 0.0192)  train/total_loss: 8043.3989 (11877.8368, 6233.7808)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 123313.6719 (83973.5970, 110029.4844)  train/nll_loss: 8043.2734 (11877.7528, 6233.6709)  train/rec_loss: 0.0349 (0.0516, 0.0271)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0192)
2025-02-06 18:11:38,600 train INFO: [6400/46609/10000]  lr: 9.605269359596496e-05  eta: 0:07:37  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0187)  train/logits_fake: 0.0192 (0.0192, 0.0196)  train/total_loss: 8099.6631 (11865.4787, 9234.9219)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 121574.7656 (84111.5250, 114317.0469)  train/nll_loss: 8099.5532 (11865.3946, 9234.8076)  train/rec_loss: 0.0352 (0.0515, 0.0401)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0196)
2025-02-06 18:11:41,135 train INFO: [6420/46609/10000]  lr: 9.602831640665573e-05  eta: 0:07:34  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0185)  train/logits_fake: 0.0192 (0.0192, 0.0180)  train/total_loss: 7804.3892 (11855.5908, 9963.6514)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 124430.6016 (84238.2039, 133401.1250)  train/nll_loss: 7804.2979 (11855.5066, 9963.5176)  train/rec_loss: 0.0339 (0.0515, 0.0432)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0180)
2025-02-06 18:11:43,680 train INFO: [6440/46609/10000]  lr: 9.600386732192043e-05  eta: 0:07:32  iter_time: 0.128  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0218)  train/logits_fake: 0.0192 (0.0192, 0.0203)  train/total_loss: 8070.5312 (11847.6586, 9812.0322)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 124917.0625 (84364.1513, 140466.8125)  train/nll_loss: 8070.4043 (11847.5742, 9811.8916)  train/rec_loss: 0.0350 (0.0514, 0.0426)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0203)
2025-02-06 18:11:46,222 train INFO: [6460/46609/10000]  lr: 9.597934638036753e-05  eta: 0:07:29  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0186)  train/logits_fake: 0.0192 (0.0192, 0.0186)  train/total_loss: 8068.9214 (11835.9878, 8213.6162)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 124917.0625 (84500.3600, 126284.8438)  train/nll_loss: 8068.7803 (11835.9033, 8213.4902)  train/rec_loss: 0.0350 (0.0514, 0.0356)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0186)
2025-02-06 18:11:48,766 train INFO: [6480/46609/10000]  lr: 9.595475362071893e-05  eta: 0:07:27  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0187)  train/logits_fake: 0.0193 (0.0192, 0.0176)  train/total_loss: 8227.6270 (11824.2918, 11850.3027)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 126796.1250 (84652.3129, 138199.0938)  train/nll_loss: 8227.4941 (11824.2072, 11850.1641)  train/rec_loss: 0.0357 (0.0513, 0.0514)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0176)
2025-02-06 18:11:51,312 train INFO: [6500/46609/10000]  lr: 9.593008908180993e-05  eta: 0:07:24  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0196)  train/logits_fake: 0.0192 (0.0192, 0.0195)  train/total_loss: 8227.6270 (11813.3929, 8313.7656)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 126284.8438 (84775.7801, 144460.5000)  train/nll_loss: 8227.4941 (11813.3081, 8313.6211)  train/rec_loss: 0.0357 (0.0513, 0.0361)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0195)
2025-02-06 18:11:53,845 train INFO: [6520/46609/10000]  lr: 9.590535280258926e-05  eta: 0:07:22  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0184)  train/logits_fake: 0.0192 (0.0192, 0.0193)  train/total_loss: 8173.5986 (11801.3369, 9087.4141)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 127795.0312 (84921.9849, 138015.0625)  train/nll_loss: 8173.4736 (11801.2519, 9087.2764)  train/rec_loss: 0.0355 (0.0512, 0.0394)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0193)
2025-02-06 18:11:56,386 train INFO: [6540/46609/10000]  lr: 9.588054482211884e-05  eta: 0:07:19  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0195)  train/logits_fake: 0.0191 (0.0192, 0.0199)  train/total_loss: 8173.5986 (11793.1166, 10097.1875)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 130239.0312 (85061.3934, 135835.3125)  train/nll_loss: 8173.4736 (11793.0315, 10097.0518)  train/rec_loss: 0.0355 (0.0512, 0.0438)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0199)
2025-02-06 18:11:58,922 train INFO: [6560/46609/10000]  lr: 9.585566517957387e-05  eta: 0:07:16  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0199)  train/logits_fake: 0.0192 (0.0192, 0.0209)  train/total_loss: 8179.2778 (11783.9199, 9782.4092)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 128782.3125 (85178.5404, 141469.2656)  train/nll_loss: 8179.1436 (11783.8348, 9782.2676)  train/rec_loss: 0.0355 (0.0511, 0.0425)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0209)
2025-02-06 18:12:01,457 train INFO: [6580/46609/10000]  lr: 9.583071391424269e-05  eta: 0:07:14  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0197)  train/logits_fake: 0.0191 (0.0192, 0.0195)  train/total_loss: 8109.9302 (11772.5338, 5966.2417)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 126934.9219 (85308.0444, 99024.4688)  train/nll_loss: 8109.8018 (11772.4485, 5966.1426)  train/rec_loss: 0.0352 (0.0511, 0.0259)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0195)
2025-02-06 18:12:04,000 train INFO: [6600/46609/10000]  lr: 9.580569106552677e-05  eta: 0:07:11  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0191)  train/logits_fake: 0.0192 (0.0192, 0.0193)  train/total_loss: 8036.9902 (11759.7449, 4565.9087)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 130414.4844 (85442.6195, 115730.8906)  train/nll_loss: 8036.8799 (11759.6595, 4565.7930)  train/rec_loss: 0.0349 (0.0510, 0.0198)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0193)
2025-02-06 18:12:06,544 train INFO: [6620/46609/10000]  lr: 9.578059667294058e-05  eta: 0:07:09  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0204)  train/logits_fake: 0.0192 (0.0192, 0.0198)  train/total_loss: 7991.0688 (11746.5308, 7721.3389)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 130066.2422 (85569.2260, 119284.1797)  train/nll_loss: 7990.9648 (11746.4452, 7721.2197)  train/rec_loss: 0.0347 (0.0510, 0.0335)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0198)
2025-02-06 18:12:09,080 train INFO: [6640/46609/10000]  lr: 9.575543077611162e-05  eta: 0:07:06  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0182)  train/logits_fake: 0.0194 (0.0192, 0.0186)  train/total_loss: 7647.7695 (11736.7074, 6888.2065)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 127989.4062 (85717.8834, 140997.4531)  train/nll_loss: 7647.6543 (11736.6217, 6888.0654)  train/rec_loss: 0.0332 (0.0509, 0.0299)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0186)
2025-02-06 18:12:11,623 train INFO: [6660/46609/10000]  lr: 9.573019341478025e-05  eta: 0:07:04  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0196)  train/logits_fake: 0.0194 (0.0192, 0.0201)  train/total_loss: 7562.2114 (11725.7996, 5403.0864)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 131400.0156 (85860.3441, 114244.5625)  train/nll_loss: 7562.0801 (11725.7137, 5402.9722)  train/rec_loss: 0.0328 (0.0509, 0.0235)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0201)
2025-02-06 18:12:14,172 train INFO: [6680/46609/10000]  lr: 9.570488462879973e-05  eta: 0:07:01  iter_time: 0.128  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0184)  train/logits_fake: 0.0194 (0.0192, 0.0190)  train/total_loss: 7562.2114 (11715.8481, 8944.5615)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 130572.2188 (85979.4405, 145619.7188)  train/nll_loss: 7562.0801 (11715.7621, 8944.4160)  train/rec_loss: 0.0328 (0.0508, 0.0388)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0190)
2025-02-06 18:12:16,711 train INFO: [6700/46609/10000]  lr: 9.567950445813609e-05  eta: 0:06:59  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0194)  train/logits_fake: 0.0193 (0.0192, 0.0195)  train/total_loss: 7441.1455 (11702.9760, 8140.1035)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 128709.0938 (86102.9887, 145577.3750)  train/nll_loss: 7440.9922 (11702.8899, 8139.9580)  train/rec_loss: 0.0323 (0.0508, 0.0353)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0195)
2025-02-06 18:12:19,253 train INFO: [6720/46609/10000]  lr: 9.565405294286806e-05  eta: 0:06:56  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0185)  train/logits_fake: 0.0193 (0.0192, 0.0194)  train/total_loss: 7758.6924 (11693.2708, 6577.2363)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 128737.4609 (86237.9490, 144642.6250)  train/nll_loss: 7758.5781 (11693.1845, 6577.0918)  train/rec_loss: 0.0337 (0.0508, 0.0285)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0194)
2025-02-06 18:12:21,799 train INFO: [6740/46609/10000]  lr: 9.562853012318705e-05  eta: 0:06:54  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0182)  train/logits_fake: 0.0191 (0.0192, 0.0197)  train/total_loss: 8016.7812 (11683.4771, 9092.6367)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 127664.8359 (86364.2026, 131055.4062)  train/nll_loss: 8016.6396 (11683.3907, 9092.5059)  train/rec_loss: 0.0348 (0.0507, 0.0395)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0197)
2025-02-06 18:12:24,339 train INFO: [6760/46609/10000]  lr: 9.560293603939711e-05  eta: 0:06:51  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0180)  train/logits_fake: 0.0191 (0.0192, 0.0183)  train/total_loss: 7789.8481 (11669.7202, 6163.2822)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 125363.9062 (86478.0324, 143882.6719)  train/nll_loss: 7789.7227 (11669.6338, 6163.1382)  train/rec_loss: 0.0338 (0.0506, 0.0267)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0183)
2025-02-06 18:12:26,885 train INFO: [6780/46609/10000]  lr: 9.557727073191479e-05  eta: 0:06:49  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0191)  train/logits_fake: 0.0191 (0.0192, 0.0213)  train/total_loss: 7704.8452 (11659.6413, 14288.1836)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 127007.4062 (86605.1116, 144298.9219)  train/nll_loss: 7704.7041 (11659.5547, 14288.0391)  train/rec_loss: 0.0334 (0.0506, 0.0620)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0213)
2025-02-06 18:12:29,425 train INFO: [6800/46609/10000]  lr: 9.555153424126908e-05  eta: 0:06:46  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0196)  train/logits_fake: 0.0191 (0.0192, 0.0192)  train/total_loss: 7701.4580 (11647.1224, 10200.9932)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 125363.9062 (86710.8922, 123372.6172)  train/nll_loss: 7701.3262 (11647.0357, 10200.8701)  train/rec_loss: 0.0334 (0.0506, 0.0443)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0192)
2025-02-06 18:12:31,969 train INFO: [6820/46609/10000]  lr: 9.552572660810145e-05  eta: 0:06:43  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0180)  train/logits_fake: 0.0192 (0.0192, 0.0191)  train/total_loss: 7572.3145 (11635.3144, 9032.8936)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 125470.2266 (86838.7046, 119150.5859)  train/nll_loss: 7572.1914 (11635.2275, 9032.7744)  train/rec_loss: 0.0329 (0.0505, 0.0392)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0191)
2025-02-06 18:12:34,501 train INFO: [6840/46609/10000]  lr: 9.549984787316565e-05  eta: 0:06:41  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0194 (0.0191, 0.0192)  train/logits_fake: 0.0192 (0.0192, 0.0196)  train/total_loss: 7305.1636 (11624.5715, 7321.9336)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 128355.3125 (86977.2674, 127820.5469)  train/nll_loss: 7305.0308 (11624.4845, 7321.8057)  train/rec_loss: 0.0317 (0.0505, 0.0318)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0196)
2025-02-06 18:12:37,039 train INFO: [6860/46609/10000]  lr: 9.547389807732774e-05  eta: 0:06:38  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0194 (0.0191, 0.0190)  train/logits_fake: 0.0194 (0.0192, 0.0195)  train/total_loss: 7325.8135 (11611.4010, 6998.3589)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 127074.7344 (87085.0339, 120275.0312)  train/nll_loss: 7325.6753 (11611.3139, 6998.2388)  train/rec_loss: 0.0318 (0.0504, 0.0304)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0195)
2025-02-06 18:12:39,581 train INFO: [6880/46609/10000]  lr: 9.5447877261566e-05  eta: 0:06:36  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0194 (0.0191, 0.0165)  train/logits_fake: 0.0194 (0.0192, 0.0169)  train/total_loss: 7357.6445 (11602.6950, 12531.3115)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 127074.7344 (87203.4029, 112968.0781)  train/nll_loss: 7357.5049 (11602.6078, 12531.1982)  train/rec_loss: 0.0319 (0.0504, 0.0544)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0169)
2025-02-06 18:12:42,120 train INFO: [6900/46609/10000]  lr: 9.542178546697084e-05  eta: 0:06:33  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0194 (0.0191, 0.0185)  train/logits_fake: 0.0195 (0.0192, 0.0197)  train/total_loss: 7456.0840 (11592.7106, 9875.5908)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 128704.0234 (87321.5077, 141924.3906)  train/nll_loss: 7455.9546 (11592.6233, 9875.4492)  train/rec_loss: 0.0324 (0.0503, 0.0429)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0197)
2025-02-06 18:12:44,658 train INFO: [6920/46609/10000]  lr: 9.539562273474476e-05  eta: 0:06:31  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0188)  train/logits_fake: 0.0194 (0.0192, 0.0194)  train/total_loss: 7541.6558 (11582.3258, 7379.8262)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 128704.0234 (87448.6113, 98277.3750)  train/nll_loss: 7541.5229 (11582.2384, 7379.7280)  train/rec_loss: 0.0327 (0.0503, 0.0320)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0194)
2025-02-06 18:12:47,194 train INFO: [6940/46609/10000]  lr: 9.53693891062023e-05  eta: 0:06:28  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0200)  train/logits_fake: 0.0194 (0.0192, 0.0191)  train/total_loss: 7453.6416 (11569.1272, 7081.8525)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 127812.6641 (87554.5351, 143585.0938)  train/nll_loss: 7453.5459 (11569.0397, 7081.7090)  train/rec_loss: 0.0324 (0.0502, 0.0307)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0191)
2025-02-06 18:12:49,728 train INFO: [6960/46609/10000]  lr: 9.534308462276993e-05  eta: 0:06:26  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0189)  train/logits_fake: 0.0194 (0.0192, 0.0184)  train/total_loss: 7543.5786 (11558.0771, 5926.9282)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 128734.5859 (87668.2298, 131206.6562)  train/nll_loss: 7543.4883 (11557.9894, 5926.7969)  train/rec_loss: 0.0327 (0.0502, 0.0257)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0184)
2025-02-06 18:12:52,267 train INFO: [6980/46609/10000]  lr: 9.531670932598602e-05  eta: 0:06:23  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0186)  train/logits_fake: 0.0194 (0.0192, 0.0184)  train/total_loss: 7391.7275 (11546.1970, 7812.8564)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 130963.4922 (87806.5426, 166802.1406)  train/nll_loss: 7391.5918 (11546.1092, 7812.6895)  train/rec_loss: 0.0321 (0.0501, 0.0339)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0184)
2025-02-06 18:12:54,801 train INFO: [7000/46609/10000]  lr: 9.529026325750076e-05  eta: 0:06:21  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0187)  train/logits_fake: 0.0194 (0.0192, 0.0196)  train/total_loss: 7379.8262 (11536.9079, 7042.4741)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 128748.8828 (87911.5286, 123667.3359)  train/nll_loss: 7379.7280 (11536.8199, 7042.3506)  train/rec_loss: 0.0320 (0.0501, 0.0306)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0196)
2025-02-06 18:12:57,340 train INFO: [7020/46609/10000]  lr: 9.526374645907612e-05  eta: 0:06:18  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0199)  train/logits_fake: 0.0195 (0.0192, 0.0209)  train/total_loss: 7543.5786 (11529.6799, 10003.7852)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 129507.5469 (88059.9803, 129016.0938)  train/nll_loss: 7543.4883 (11529.5918, 10003.6562)  train/rec_loss: 0.0327 (0.0500, 0.0434)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0209)
2025-02-06 18:12:59,881 train INFO: [7040/46609/10000]  lr: 9.523715897258573e-05  eta: 0:06:16  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0194 (0.0191, 0.0208)  train/logits_fake: 0.0196 (0.0192, 0.0209)  train/total_loss: 7835.4746 (11520.7552, 6234.6450)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 131952.2812 (88205.3833, 125679.2188)  train/nll_loss: 7835.3384 (11520.6670, 6234.5195)  train/rec_loss: 0.0340 (0.0500, 0.0271)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0197 (-0.0192, -0.0209)
2025-02-06 18:13:02,419 train INFO: [7060/46609/10000]  lr: 9.521050084001487e-05  eta: 0:06:13  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0181)  train/logits_fake: 0.0195 (0.0192, 0.0177)  train/total_loss: 7984.9399 (11511.3960, 7843.7412)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 134909.5625 (88339.1854, 143432.1406)  train/nll_loss: 7984.8086 (11511.3077, 7843.5977)  train/rec_loss: 0.0347 (0.0500, 0.0340)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0177)
2025-02-06 18:13:04,955 train INFO: [7080/46609/10000]  lr: 9.518377210346035e-05  eta: 0:06:10  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0183)  train/logits_fake: 0.0194 (0.0192, 0.0182)  train/total_loss: 8081.6421 (11499.6439, 6716.3848)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 133646.8438 (88462.9339, 173613.5312)  train/nll_loss: 8081.4854 (11499.5554, 6716.2109)  train/rec_loss: 0.0351 (0.0499, 0.0292)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0182)
2025-02-06 18:13:07,495 train INFO: [7100/46609/10000]  lr: 9.51569728051305e-05  eta: 0:06:08  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0194)  train/logits_fake: 0.0193 (0.0192, 0.0201)  train/total_loss: 7982.0161 (11489.0632, 8826.6055)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 138029.2812 (88603.6225, 130909.2812)  train/nll_loss: 7981.8530 (11488.9746, 8826.4746)  train/rec_loss: 0.0346 (0.0499, 0.0383)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0201)
2025-02-06 18:13:10,035 train INFO: [7120/46609/10000]  lr: 9.513010298734508e-05  eta: 0:06:05  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0187)  train/logits_fake: 0.0192 (0.0192, 0.0188)  train/total_loss: 7780.6328 (11479.4169, 8007.1440)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 137258.5469 (88725.6278, 140145.4531)  train/nll_loss: 7780.5186 (11479.3282, 8007.0039)  train/rec_loss: 0.0338 (0.0498, 0.0348)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0188)
2025-02-06 18:13:12,574 train INFO: [7140/46609/10000]  lr: 9.51031626925352e-05  eta: 0:06:03  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0200)  train/logits_fake: 0.0191 (0.0192, 0.0194)  train/total_loss: 7596.2012 (11469.3759, 9313.3789)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 135096.1406 (88848.4705, 135200.9531)  train/nll_loss: 7596.0718 (11469.2870, 9313.2441)  train/rec_loss: 0.0330 (0.0498, 0.0404)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0194)
2025-02-06 18:13:15,111 train INFO: [7160/46609/10000]  lr: 9.507615196324327e-05  eta: 0:06:00  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0181)  train/logits_fake: 0.0191 (0.0192, 0.0181)  train/total_loss: 7429.3364 (11458.9493, 5630.9819)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 134964.4688 (88975.6879, 145082.1406)  train/nll_loss: 7429.2021 (11458.8603, 5630.8369)  train/rec_loss: 0.0322 (0.0497, 0.0244)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0181)
2025-02-06 18:13:17,662 train INFO: [7180/46609/10000]  lr: 9.50490708421229e-05  eta: 0:05:58  iter_time: 0.128  data: 0.001  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0171)  train/logits_fake: 0.0191 (0.0192, 0.0169)  train/total_loss: 7668.6226 (11448.8407, 10763.4414)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 134515.7031 (89100.8699, 173021.0625)  train/nll_loss: 7668.4932 (11448.7516, 10763.2686)  train/rec_loss: 0.0333 (0.0497, 0.0467)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0169)
2025-02-06 18:13:20,201 train INFO: [7200/46609/10000]  lr: 9.502191937193887e-05  eta: 0:05:55  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0196)  train/logits_fake: 0.0194 (0.0192, 0.0204)  train/total_loss: 7896.8281 (11442.1160, 7782.2871)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 134964.4688 (89242.1287, 109622.8750)  train/nll_loss: 7896.6836 (11442.0267, 7782.1772)  train/rec_loss: 0.0343 (0.0497, 0.0338)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0204)
2025-02-06 18:13:22,746 train INFO: [7220/46609/10000]  lr: 9.499469759556709e-05  eta: 0:05:53  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0203)  train/logits_fake: 0.0194 (0.0192, 0.0200)  train/total_loss: 7896.8281 (11432.4499, 10336.5205)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 134184.2500 (89352.6594, 122329.4688)  train/nll_loss: 7896.6836 (11432.3606, 10336.3984)  train/rec_loss: 0.0343 (0.0496, 0.0449)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0200)
2025-02-06 18:13:25,289 train INFO: [7240/46609/10000]  lr: 9.496740555599444e-05  eta: 0:05:50  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0190)  train/logits_fake: 0.0194 (0.0192, 0.0193)  train/total_loss: 7801.9155 (11421.8622, 5582.9302)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 134039.2500 (89467.5003, 118458.7656)  train/nll_loss: 7801.7812 (11421.7727, 5582.8115)  train/rec_loss: 0.0339 (0.0496, 0.0242)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0193)
2025-02-06 18:13:27,835 train INFO: [7260/46609/10000]  lr: 9.494004329631877e-05  eta: 0:05:48  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0190)  train/logits_fake: 0.0195 (0.0192, 0.0189)  train/total_loss: 7720.6895 (11410.6952, 6240.7153)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 133459.3125 (89599.7194, 141157.0312)  train/nll_loss: 7720.5166 (11410.6056, 6240.5742)  train/rec_loss: 0.0335 (0.0495, 0.0271)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0189)
2025-02-06 18:13:30,380 train INFO: [7280/46609/10000]  lr: 9.491261085974884e-05  eta: 0:05:45  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0185)  train/logits_fake: 0.0196 (0.0192, 0.0189)  train/total_loss: 7581.1274 (11401.1274, 9388.2295)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 133955.4688 (89730.7626, 127806.5000)  train/nll_loss: 7580.9946 (11401.0376, 9388.1016)  train/rec_loss: 0.0329 (0.0495, 0.0407)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0196 (-0.0192, -0.0189)
2025-02-06 18:13:32,921 train INFO: [7300/46609/10000]  lr: 9.488510828960418e-05  eta: 0:05:42  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0184)  train/logits_fake: 0.0193 (0.0192, 0.0188)  train/total_loss: 7244.4575 (11389.8378, 7534.6909)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 133955.4688 (89861.6427, 154545.5000)  train/nll_loss: 7244.3486 (11389.7479, 7534.5361)  train/rec_loss: 0.0314 (0.0494, 0.0327)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0188)
2025-02-06 18:13:35,460 train INFO: [7320/46609/10000]  lr: 9.485753562931516e-05  eta: 0:05:40  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0171)  train/logits_fake: 0.0191 (0.0192, 0.0181)  train/total_loss: 7190.5654 (11379.5930, 10153.3301)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 134057.2656 (89989.9343, 144227.0469)  train/nll_loss: 7190.4375 (11379.5030, 10153.1855)  train/rec_loss: 0.0312 (0.0494, 0.0441)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0181)
2025-02-06 18:13:37,991 train INFO: [7340/46609/10000]  lr: 9.48298929224227e-05  eta: 0:05:37  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0196)  train/logits_fake: 0.0190 (0.0192, 0.0204)  train/total_loss: 7236.7441 (11370.1817, 6183.7368)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 136522.4844 (90122.6233, 128406.1484)  train/nll_loss: 7236.5840 (11370.0916, 6183.6084)  train/rec_loss: 0.0314 (0.0493, 0.0268)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0192, -0.0204)
2025-02-06 18:13:40,527 train INFO: [7360/46609/10000]  lr: 9.480218021257847e-05  eta: 0:05:35  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0194)  train/logits_fake: 0.0191 (0.0192, 0.0195)  train/total_loss: 7367.9800 (11359.4433, 8171.2896)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 136522.4844 (90243.1078, 175102.1250)  train/nll_loss: 7367.8818 (11359.3530, 8171.1143)  train/rec_loss: 0.0320 (0.0493, 0.0355)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0195)
2025-02-06 18:13:43,066 train INFO: [7380/46609/10000]  lr: 9.477439754354459e-05  eta: 0:05:32  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0194)  train/logits_fake: 0.0192 (0.0192, 0.0198)  train/total_loss: 7629.6128 (11352.9013, 8564.9795)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 137048.9531 (90371.3073, 140030.6719)  train/nll_loss: 7629.4727 (11352.8110, 8564.8398)  train/rec_loss: 0.0331 (0.0493, 0.0372)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0198)
2025-02-06 18:13:45,610 train INFO: [7400/46609/10000]  lr: 9.47465449591937e-05  eta: 0:05:30  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0192)  train/logits_fake: 0.0193 (0.0192, 0.0198)  train/total_loss: 7974.1665 (11345.8678, 8461.1084)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 137594.9844 (90514.0047, 160854.4375)  train/nll_loss: 7974.0264 (11345.7773, 8460.9473)  train/rec_loss: 0.0346 (0.0492, 0.0367)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0198)
2025-02-06 18:13:48,145 train INFO: [7420/46609/10000]  lr: 9.471862250350882e-05  eta: 0:05:27  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0199)  train/logits_fake: 0.0193 (0.0192, 0.0200)  train/total_loss: 8171.2896 (11339.0820, 8470.6611)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 137861.0312 (90656.9097, 151586.4688)  train/nll_loss: 8171.1143 (11338.9913, 8470.5098)  train/rec_loss: 0.0355 (0.0492, 0.0368)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0200)
2025-02-06 18:13:50,680 train INFO: [7440/46609/10000]  lr: 9.469063022058334e-05  eta: 0:05:25  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0178)  train/logits_fake: 0.0194 (0.0192, 0.0186)  train/total_loss: 8165.3296 (11330.0866, 9785.0020)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 137861.0312 (90795.0288, 161821.7969)  train/nll_loss: 8165.1768 (11329.9958, 9784.8398)  train/rec_loss: 0.0354 (0.0492, 0.0425)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0186)
2025-02-06 18:13:53,224 train INFO: [7460/46609/10000]  lr: 9.466256815462087e-05  eta: 0:05:22  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0193)  train/logits_fake: 0.0193 (0.0192, 0.0202)  train/total_loss: 8506.0176 (11324.9069, 13727.0527)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 138813.9375 (90935.0375, 142168.3750)  train/nll_loss: 8505.8613 (11324.8160, 13726.9102)  train/rec_loss: 0.0369 (0.0492, 0.0596)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0202)
2025-02-06 18:13:55,763 train INFO: [7480/46609/10000]  lr: 9.463443634993526e-05  eta: 0:05:20  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0191)  train/logits_fake: 0.0191 (0.0192, 0.0195)  train/total_loss: 8352.8262 (11316.0639, 7201.5327)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 138463.6719 (91043.6185, 119424.9375)  train/nll_loss: 8352.6914 (11315.9728, 7201.4131)  train/rec_loss: 0.0363 (0.0491, 0.0313)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0195)
2025-02-06 18:13:58,300 train INFO: [7500/46609/10000]  lr: 9.460623485095045e-05  eta: 0:05:17  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0173)  train/logits_fake: 0.0190 (0.0192, 0.0179)  train/total_loss: 7960.2500 (11304.3062, 6975.9922)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 137623.9688 (91170.7458, 159393.9062)  train/nll_loss: 7960.1084 (11304.2150, 6975.8330)  train/rec_loss: 0.0345 (0.0491, 0.0303)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0179)
2025-02-06 18:14:00,839 train INFO: [7520/46609/10000]  lr: 9.457796370220048e-05  eta: 0:05:15  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0176)  train/logits_fake: 0.0190 (0.0192, 0.0172)  train/total_loss: 7594.3657 (11293.9493, 6891.8364)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 138768.3438 (91306.1399, 144837.0156)  train/nll_loss: 7594.2471 (11293.8580, 6891.6914)  train/rec_loss: 0.0330 (0.0490, 0.0299)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0192, -0.0172)
2025-02-06 18:14:03,369 train INFO: [7540/46609/10000]  lr: 9.454962294832933e-05  eta: 0:05:12  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0191)  train/logits_fake: 0.0190 (0.0192, 0.0191)  train/total_loss: 7753.5693 (11286.6419, 5832.1953)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 136410.4219 (91406.0529, 108827.2500)  train/nll_loss: 7753.4453 (11286.5505, 5832.0864)  train/rec_loss: 0.0337 (0.0490, 0.0253)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0192, -0.0191)
2025-02-06 18:14:05,913 train INFO: [7560/46609/10000]  lr: 9.452121263409094e-05  eta: 0:05:09  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0196)  train/logits_fake: 0.0191 (0.0192, 0.0182)  train/total_loss: 7594.3657 (11277.4741, 7074.3921)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 137291.1250 (91545.6874, 149744.9219)  train/nll_loss: 7594.2471 (11277.3825, 7074.2422)  train/rec_loss: 0.0330 (0.0489, 0.0307)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0182)
2025-02-06 18:14:08,454 train INFO: [7580/46609/10000]  lr: 9.449273280434908e-05  eta: 0:05:07  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0186)  train/logits_fake: 0.0190 (0.0192, 0.0193)  train/total_loss: 7594.3657 (11268.8461, 11092.5908)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 139165.6562 (91668.4643, 178879.8750)  train/nll_loss: 7594.2471 (11268.7544, 11092.4121)  train/rec_loss: 0.0330 (0.0489, 0.0481)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0193)
2025-02-06 18:14:10,995 train INFO: [7600/46609/10000]  lr: 9.446418350407724e-05  eta: 0:05:04  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0177)  train/logits_fake: 0.0189 (0.0192, 0.0178)  train/total_loss: 7863.1338 (11259.9568, 6233.5396)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 139783.9375 (91800.6093, 108909.6016)  train/nll_loss: 7862.9980 (11259.8650, 6233.4307)  train/rec_loss: 0.0341 (0.0489, 0.0271)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0178)
2025-02-06 18:14:13,526 train INFO: [7620/46609/10000]  lr: 9.443556477835872e-05  eta: 0:05:02  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0189)  train/logits_fake: 0.0191 (0.0192, 0.0188)  train/total_loss: 7860.9014 (11250.0515, 7050.1426)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 139759.6250 (91930.1369, 120292.2734)  train/nll_loss: 7860.7290 (11249.9596, 7050.0225)  train/rec_loss: 0.0341 (0.0488, 0.0306)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0188)
2025-02-06 18:14:16,059 train INFO: [7640/46609/10000]  lr: 9.440687667238635e-05  eta: 0:04:59  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0187)  train/logits_fake: 0.0192 (0.0192, 0.0188)  train/total_loss: 7686.3125 (11239.7928, 5211.0913)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 139759.6250 (92039.2107, 107451.9688)  train/nll_loss: 7686.1572 (11239.7008, 5210.9839)  train/rec_loss: 0.0334 (0.0488, 0.0226)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0188)
2025-02-06 18:14:18,597 train INFO: [7660/46609/10000]  lr: 9.437811923146262e-05  eta: 0:04:57  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0194)  train/logits_fake: 0.0191 (0.0192, 0.0202)  train/total_loss: 7523.8496 (11231.6577, 6979.9917)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 135178.4531 (92141.0237, 112701.8828)  train/nll_loss: 7523.7197 (11231.5656, 6979.8789)  train/rec_loss: 0.0327 (0.0487, 0.0303)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0202)
2025-02-06 18:14:21,139 train INFO: [7680/46609/10000]  lr: 9.434929250099939e-05  eta: 0:04:54  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0179)  train/logits_fake: 0.0192 (0.0192, 0.0191)  train/total_loss: 7468.4556 (11220.7966, 7915.1821)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 136900.3594 (92257.6073, 142040.5625)  train/nll_loss: 7468.3252 (11220.7044, 7915.0400)  train/rec_loss: 0.0324 (0.0487, 0.0344)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0191)
2025-02-06 18:14:23,677 train INFO: [7700/46609/10000]  lr: 9.432039652651805e-05  eta: 0:04:52  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0209)  train/logits_fake: 0.0194 (0.0192, 0.0202)  train/total_loss: 7372.1792 (11211.3336, 9723.6484)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 135825.4531 (92361.1656, 135260.4062)  train/nll_loss: 7372.0278 (11211.2413, 9723.5127)  train/rec_loss: 0.0320 (0.0487, 0.0422)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0202)
2025-02-06 18:14:26,211 train INFO: [7720/46609/10000]  lr: 9.429143135364926e-05  eta: 0:04:49  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0180)  train/logits_fake: 0.0194 (0.0192, 0.0183)  train/total_loss: 7453.5068 (11202.2577, 7838.6743)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 135260.4062 (92483.9376, 153842.7188)  train/nll_loss: 7453.3677 (11202.1652, 7838.5205)  train/rec_loss: 0.0323 (0.0486, 0.0340)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0183)
2025-02-06 18:14:28,744 train INFO: [7740/46609/10000]  lr: 9.426239702813299e-05  eta: 0:04:47  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0194)  train/logits_fake: 0.0194 (0.0192, 0.0197)  train/total_loss: 7453.5068 (11192.9675, 7273.1797)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 134865.7031 (92586.6349, 132218.9844)  train/nll_loss: 7453.3677 (11192.8749, 7273.0474)  train/rec_loss: 0.0323 (0.0486, 0.0316)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0197)
2025-02-06 18:14:31,280 train INFO: [7760/46609/10000]  lr: 9.42332935958184e-05  eta: 0:04:44  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0182)  train/logits_fake: 0.0192 (0.0192, 0.0194)  train/total_loss: 7390.1553 (11182.6235, 10143.5674)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 136550.1562 (92716.1811, 146902.1562)  train/nll_loss: 7390.0322 (11182.5308, 10143.4209)  train/rec_loss: 0.0321 (0.0485, 0.0440)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0194)
2025-02-06 18:14:33,825 train INFO: [7780/46609/10000]  lr: 9.42041211026638e-05  eta: 0:04:41  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0185)  train/logits_fake: 0.0193 (0.0192, 0.0179)  train/total_loss: 7378.0322 (11171.9213, 9054.7012)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 135825.4531 (92821.9891, 132655.5469)  train/nll_loss: 7377.8901 (11171.8285, 9054.5684)  train/rec_loss: 0.0320 (0.0485, 0.0393)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0179)
2025-02-06 18:14:36,369 train INFO: [7800/46609/10000]  lr: 9.417487959473651e-05  eta: 0:04:39  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0165)  train/logits_fake: 0.0192 (0.0192, 0.0172)  train/total_loss: 7378.0322 (11162.4916, 6319.2622)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 136007.8594 (92952.8015, 147965.3125)  train/nll_loss: 7377.8901 (11162.3986, 6319.1143)  train/rec_loss: 0.0320 (0.0484, 0.0274)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0172)
2025-02-06 18:14:38,913 train INFO: [7820/46609/10000]  lr: 9.41455691182129e-05  eta: 0:04:36  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0197)  train/logits_fake: 0.0193 (0.0192, 0.0199)  train/total_loss: 7233.2300 (11152.6573, 12954.9141)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 134749.0000 (93046.4047, 144418.9375)  train/nll_loss: 7233.0825 (11152.5642, 12954.7695)  train/rec_loss: 0.0314 (0.0484, 0.0562)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0199)
2025-02-06 18:14:41,453 train INFO: [7840/46609/10000]  lr: 9.411618971937817e-05  eta: 0:04:34  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0195)  train/logits_fake: 0.0193 (0.0192, 0.0201)  train/total_loss: 7000.0376 (11142.2869, 5798.4941)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 135158.0312 (93146.1412, 133671.8125)  train/nll_loss: 6999.9141 (11142.1937, 5798.3604)  train/rec_loss: 0.0304 (0.0484, 0.0252)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0201)
2025-02-06 18:14:43,997 train INFO: [7860/46609/10000]  lr: 9.408674144462642e-05  eta: 0:04:31  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0173)  train/logits_fake: 0.0193 (0.0192, 0.0172)  train/total_loss: 7182.6348 (11134.4705, 7796.9561)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 134768.1719 (93257.8689, 171812.3281)  train/nll_loss: 7182.4937 (11134.3772, 7796.7842)  train/rec_loss: 0.0312 (0.0483, 0.0338)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0172)
2025-02-06 18:14:46,539 train INFO: [7880/46609/10000]  lr: 9.405722434046051e-05  eta: 0:04:29  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0205)  train/logits_fake: 0.0192 (0.0192, 0.0203)  train/total_loss: 7271.9438 (11125.2921, 6452.0820)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 134557.9688 (93365.5119, 149503.0625)  train/nll_loss: 7271.8418 (11125.1987, 6451.9326)  train/rec_loss: 0.0316 (0.0483, 0.0280)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0203)
2025-02-06 18:14:49,077 train INFO: [7900/46609/10000]  lr: 9.402763845349195e-05  eta: 0:04:26  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0191)  train/logits_fake: 0.0193 (0.0192, 0.0196)  train/total_loss: 7156.2461 (11114.8047, 6936.9355)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 134751.0312 (93477.7059, 132768.0625)  train/nll_loss: 7156.1152 (11114.7113, 6936.8027)  train/rec_loss: 0.0311 (0.0482, 0.0301)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0196)
2025-02-06 18:14:51,603 train INFO: [7920/46609/10000]  lr: 9.399798383044092e-05  eta: 0:04:24  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0187)  train/logits_fake: 0.0192 (0.0192, 0.0183)  train/total_loss: 7150.6797 (11104.5858, 7689.1401)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 136332.2500 (93590.3961, 153864.8906)  train/nll_loss: 7150.5605 (11104.4922, 7688.9863)  train/rec_loss: 0.0310 (0.0482, 0.0334)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0183)
2025-02-06 18:14:54,126 train INFO: [7940/46609/10000]  lr: 9.396826051813611e-05  eta: 0:04:21  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0197)  train/logits_fake: 0.0192 (0.0192, 0.0184)  train/total_loss: 7150.6797 (11094.1829, 7461.0742)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 137218.4844 (93696.5224, 130050.7266)  train/nll_loss: 7150.5605 (11094.0892, 7460.9443)  train/rec_loss: 0.0310 (0.0482, 0.0324)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0184)
2025-02-06 18:14:56,653 train INFO: [7960/46609/10000]  lr: 9.393846856351466e-05  eta: 0:04:19  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0194)  train/logits_fake: 0.0193 (0.0192, 0.0190)  train/total_loss: 6921.9160 (11083.9646, 6461.4731)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 135508.3594 (93793.2700, 129171.7344)  train/nll_loss: 6921.7695 (11083.8708, 6461.3438)  train/rec_loss: 0.0300 (0.0481, 0.0280)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0190)
2025-02-06 18:14:59,181 train INFO: [7980/46609/10000]  lr: 9.390860801362217e-05  eta: 0:04:16  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0184)  train/logits_fake: 0.0192 (0.0192, 0.0177)  train/total_loss: 6846.5981 (11074.2750, 7519.1978)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 137218.4844 (93899.8483, 156212.1719)  train/nll_loss: 6846.4575 (11074.1811, 7519.0415)  train/rec_loss: 0.0297 (0.0481, 0.0326)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0177)
2025-02-06 18:15:01,714 train INFO: [8000/46609/10000]  lr: 9.38786789156125e-05  eta: 0:04:14  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0185)  train/logits_fake: 0.0193 (0.0192, 0.0190)  train/total_loss: 7025.9131 (11066.5614, 9106.3857)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 137562.1250 (94014.0261, 141476.8438)  train/nll_loss: 7025.7930 (11066.4674, 9106.2441)  train/rec_loss: 0.0305 (0.0480, 0.0395)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0190)
2025-02-06 18:15:04,248 train INFO: [8020/46609/10000]  lr: 9.384868131674781e-05  eta: 0:04:11  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0170)  train/logits_fake: 0.0193 (0.0192, 0.0177)  train/total_loss: 7333.4224 (11058.8175, 8174.9849)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 137562.1250 (94121.4011, 112984.3594)  train/nll_loss: 7333.2891 (11058.7234, 8174.8721)  train/rec_loss: 0.0318 (0.0480, 0.0355)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0177)
2025-02-06 18:15:06,785 train INFO: [8040/46609/10000]  lr: 9.381861526439836e-05  eta: 0:04:08  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0201)  train/logits_fake: 0.0193 (0.0192, 0.0199)  train/total_loss: 7334.9785 (11048.7501, 7674.0503)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 138059.5000 (94229.8214, 152040.8281)  train/nll_loss: 7334.8384 (11048.6559, 7673.8984)  train/rec_loss: 0.0318 (0.0480, 0.0333)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0199)
2025-02-06 18:15:09,320 train INFO: [8060/46609/10000]  lr: 9.37884808060426e-05  eta: 0:04:06  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0187)  train/logits_fake: 0.0192 (0.0192, 0.0180)  train/total_loss: 7519.1978 (11040.6102, 7223.9463)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 139025.0625 (94358.5044, 153591.9062)  train/nll_loss: 7519.0415 (11040.5158, 7223.7925)  train/rec_loss: 0.0326 (0.0479, 0.0314)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0180)
2025-02-06 18:15:11,856 train INFO: [8080/46609/10000]  lr: 9.375827798926689e-05  eta: 0:04:03  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0193)  train/logits_fake: 0.0192 (0.0192, 0.0193)  train/total_loss: 7455.1509 (11031.0836, 8324.7754)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 139473.1875 (94455.4723, 135018.6562)  train/nll_loss: 7455.0283 (11030.9891, 8324.6406)  train/rec_loss: 0.0324 (0.0479, 0.0361)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0193)
2025-02-06 18:15:14,397 train INFO: [8100/46609/10000]  lr: 9.372800686176567e-05  eta: 0:04:01  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0190)  train/logits_fake: 0.0192 (0.0192, 0.0194)  train/total_loss: 7424.0454 (11023.1212, 10929.5566)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 138642.7656 (94552.0012, 141448.4531)  train/nll_loss: 7423.9121 (11023.0267, 10929.4150)  train/rec_loss: 0.0322 (0.0478, 0.0474)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0194)
2025-02-06 18:15:16,929 train INFO: [8120/46609/10000]  lr: 9.369766747134113e-05  eta: 0:03:58  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0189)  train/logits_fake: 0.0193 (0.0192, 0.0187)  train/total_loss: 7352.0254 (11013.9067, 6592.3447)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 137980.2500 (94663.0568, 170745.8125)  train/nll_loss: 7351.8843 (11013.8121, 6592.1738)  train/rec_loss: 0.0319 (0.0478, 0.0286)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0187)
2025-02-06 18:15:19,470 train INFO: [8140/46609/10000]  lr: 9.366725986590334e-05  eta: 0:03:56  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0197)  train/logits_fake: 0.0193 (0.0192, 0.0192)  train/total_loss: 7368.3643 (11005.1322, 6455.1982)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 137730.1562 (94771.4327, 127841.5781)  train/nll_loss: 7368.2461 (11005.0375, 6455.0703)  train/rec_loss: 0.0320 (0.0478, 0.0280)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0192)
2025-02-06 18:15:22,010 train INFO: [8160/46609/10000]  lr: 9.363678409347004e-05  eta: 0:03:53  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0185)  train/logits_fake: 0.0193 (0.0192, 0.0184)  train/total_loss: 7017.3135 (10994.0631, 6771.1011)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 136528.2500 (94872.0912, 148359.5469)  train/nll_loss: 7017.1660 (10993.9683, 6770.9526)  train/rec_loss: 0.0305 (0.0477, 0.0294)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0184)
2025-02-06 18:15:24,550 train INFO: [8180/46609/10000]  lr: 9.360624020216665e-05  eta: 0:03:51  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0196)  train/logits_fake: 0.0193 (0.0192, 0.0198)  train/total_loss: 6771.1011 (10982.7668, 6564.4570)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 137195.3125 (94987.4512, 138827.8125)  train/nll_loss: 6770.9526 (10982.6718, 6564.3184)  train/rec_loss: 0.0294 (0.0477, 0.0285)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0198)
2025-02-06 18:15:27,095 train INFO: [8200/46609/10000]  lr: 9.357562824022613e-05  eta: 0:03:48  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0194)  train/logits_fake: 0.0193 (0.0192, 0.0195)  train/total_loss: 6662.9409 (10973.7956, 7091.5127)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 137195.3125 (95103.7220, 185564.5000)  train/nll_loss: 6662.8203 (10973.7005, 7091.3271)  train/rec_loss: 0.0289 (0.0476, 0.0308)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0195)
2025-02-06 18:15:29,636 train INFO: [8220/46609/10000]  lr: 9.354494825598895e-05  eta: 0:03:46  iter_time: 0.127  data: 0.001  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0179)  train/logits_fake: 0.0192 (0.0192, 0.0184)  train/total_loss: 6712.3989 (10965.0882, 6772.0811)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 136922.0938 (95206.5615, 141803.9375)  train/nll_loss: 6712.2705 (10964.9930, 6771.9395)  train/rec_loss: 0.0291 (0.0476, 0.0294)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0184)
2025-02-06 18:15:32,176 train INFO: [8240/46609/10000]  lr: 9.351420029790299e-05  eta: 0:03:43  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0205)  train/logits_fake: 0.0191 (0.0192, 0.0203)  train/total_loss: 6723.4634 (10956.2837, 6185.0562)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 136879.3594 (95314.6581, 115250.0859)  train/nll_loss: 6723.3296 (10956.1884, 6184.9409)  train/rec_loss: 0.0292 (0.0476, 0.0268)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0203)
2025-02-06 18:15:34,710 train INFO: [8260/46609/10000]  lr: 9.348338441452349e-05  eta: 0:03:41  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0197)  train/logits_fake: 0.0192 (0.0192, 0.0198)  train/total_loss: 7058.4937 (10947.8755, 7605.5190)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 137955.4062 (95425.2426, 122507.8828)  train/nll_loss: 7058.3379 (10947.7800, 7605.3965)  train/rec_loss: 0.0306 (0.0475, 0.0330)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0198)
2025-02-06 18:15:37,259 train INFO: [8280/46609/10000]  lr: 9.345250065451291e-05  eta: 0:03:38  iter_time: 0.128  data: 0.001  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0189)  train/logits_fake: 0.0193 (0.0192, 0.0188)  train/total_loss: 7284.7603 (10938.0210, 6520.2842)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 136282.0469 (95521.1394, 148740.3750)  train/nll_loss: 7284.6094 (10937.9255, 6520.1353)  train/rec_loss: 0.0316 (0.0475, 0.0283)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0188)
2025-02-06 18:15:39,805 train INFO: [8300/46609/10000]  lr: 9.342154906664095e-05  eta: 0:03:35  iter_time: 0.128  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0198)  train/logits_fake: 0.0192 (0.0192, 0.0192)  train/total_loss: 7284.7603 (10929.1527, 6626.9614)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 138348.0625 (95628.2943, 136899.7344)  train/nll_loss: 7284.6094 (10929.0571, 6626.8247)  train/rec_loss: 0.0316 (0.0474, 0.0288)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0192)
2025-02-06 18:15:42,361 train INFO: [8320/46609/10000]  lr: 9.339052969978439e-05  eta: 0:03:33  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0186)  train/logits_fake: 0.0193 (0.0192, 0.0195)  train/total_loss: 7107.7891 (10920.4191, 6687.6987)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 140863.5312 (95735.7670, 160527.8438)  train/nll_loss: 7107.6465 (10920.3234, 6687.5381)  train/rec_loss: 0.0308 (0.0474, 0.0290)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0195)
2025-02-06 18:15:44,913 train INFO: [8340/46609/10000]  lr: 9.335944260292699e-05  eta: 0:03:30  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0189)  train/logits_fake: 0.0193 (0.0192, 0.0191)  train/total_loss: 7099.2231 (10911.4298, 8786.0713)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 138552.2500 (95824.6423, 141648.0469)  train/nll_loss: 7099.0850 (10911.3340, 8785.9297)  train/rec_loss: 0.0308 (0.0474, 0.0381)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0191)
2025-02-06 18:15:47,464 train INFO: [8360/46609/10000]  lr: 9.332828782515959e-05  eta: 0:03:28  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0190)  train/logits_fake: 0.0192 (0.0192, 0.0194)  train/total_loss: 6808.9058 (10900.7362, 6048.6484)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 138452.4375 (95915.7365, 151239.0625)  train/nll_loss: 6808.7485 (10900.6403, 6048.4971)  train/rec_loss: 0.0296 (0.0473, 0.0263)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0194)
2025-02-06 18:15:50,007 train INFO: [8380/46609/10000]  lr: 9.329706541567982e-05  eta: 0:03:25  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0171)  train/logits_fake: 0.0192 (0.0192, 0.0167)  train/total_loss: 6838.1162 (10893.1086, 8149.9043)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 137298.9375 (96014.0144, 165302.5938)  train/nll_loss: 6837.9941 (10893.0126, 8149.7388)  train/rec_loss: 0.0297 (0.0473, 0.0354)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0167)
2025-02-06 18:15:52,542 train INFO: [8400/46609/10000]  lr: 9.326577542379208e-05  eta: 0:03:23  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0177)  train/logits_fake: 0.0192 (0.0192, 0.0185)  train/total_loss: 6876.9717 (10884.1319, 6296.4141)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 138300.5000 (96140.0095, 151344.9219)  train/nll_loss: 6876.8481 (10884.0357, 6296.2627)  train/rec_loss: 0.0298 (0.0472, 0.0273)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0185)
2025-02-06 18:15:55,077 train INFO: [8420/46609/10000]  lr: 9.32344178989076e-05  eta: 0:03:20  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0176)  train/logits_fake: 0.0192 (0.0192, 0.0187)  train/total_loss: 6889.3491 (10874.8849, 7382.7417)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 137830.2812 (96256.9124, 151013.4219)  train/nll_loss: 6889.2129 (10874.7887, 7382.5908)  train/rec_loss: 0.0299 (0.0472, 0.0320)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0187)
2025-02-06 18:15:57,622 train INFO: [8440/46609/10000]  lr: 9.320299289054416e-05  eta: 0:03:18  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0199)  train/logits_fake: 0.0193 (0.0192, 0.0195)  train/total_loss: 6961.1567 (10866.3557, 5814.0312)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 140127.1562 (96354.8098, 116288.4922)  train/nll_loss: 6961.0049 (10866.2593, 5813.9150)  train/rec_loss: 0.0302 (0.0472, 0.0252)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0195)
2025-02-06 18:16:00,162 train INFO: [8460/46609/10000]  lr: 9.317150044832614e-05  eta: 0:03:15  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0190)  train/logits_fake: 0.0195 (0.0192, 0.0188)  train/total_loss: 7099.7544 (10857.5559, 6428.6543)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 140282.8438 (96467.3401, 125136.4062)  train/nll_loss: 7099.6177 (10857.4595, 6428.5293)  train/rec_loss: 0.0308 (0.0471, 0.0279)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0188)
2025-02-06 18:16:02,707 train INFO: [8480/46609/10000]  lr: 9.313994062198441e-05  eta: 0:03:13  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0185)  train/logits_fake: 0.0194 (0.0192, 0.0189)  train/total_loss: 7129.6641 (10849.4279, 9535.9189)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 142692.3594 (96560.2946, 113979.1641)  train/nll_loss: 7129.5073 (10849.3314, 9535.8047)  train/rec_loss: 0.0309 (0.0471, 0.0414)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0189)
2025-02-06 18:16:05,264 train INFO: [8500/46609/10000]  lr: 9.310831346135623e-05  eta: 0:03:10  iter_time: 0.128  data: 0.001  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0201)  train/logits_fake: 0.0195 (0.0192, 0.0200)  train/total_loss: 7018.9561 (10839.3975, 5120.5635)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 137871.4375 (96644.1338, 111626.1875)  train/nll_loss: 7018.8135 (10839.3009, 5120.4517)  train/rec_loss: 0.0305 (0.0470, 0.0222)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0200)
2025-02-06 18:16:07,806 train INFO: [8520/46609/10000]  lr: 9.307661901638523e-05  eta: 0:03:07  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0194 (0.0191, 0.0196)  train/logits_fake: 0.0195 (0.0192, 0.0197)  train/total_loss: 6976.6836 (10829.6953, 7853.1611)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 137781.7188 (96746.4104, 145903.3438)  train/nll_loss: 6976.5571 (10829.5986, 7853.0151)  train/rec_loss: 0.0303 (0.0470, 0.0341)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0197)
2025-02-06 18:16:10,347 train INFO: [8540/46609/10000]  lr: 9.304485733712123e-05  eta: 0:03:05  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0189)  train/logits_fake: 0.0195 (0.0192, 0.0196)  train/total_loss: 6974.8838 (10820.8649, 9925.9639)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 137781.7188 (96865.6904, 178034.6094)  train/nll_loss: 6974.7271 (10820.7680, 9925.7861)  train/rec_loss: 0.0303 (0.0470, 0.0431)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0196)
2025-02-06 18:16:12,894 train INFO: [8560/46609/10000]  lr: 9.30130284737203e-05  eta: 0:03:02  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0195)  train/logits_fake: 0.0193 (0.0192, 0.0189)  train/total_loss: 6850.4165 (10811.5711, 9205.8330)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 140980.7812 (96978.2910, 142053.9062)  train/nll_loss: 6850.2686 (10811.4741, 9205.6914)  train/rec_loss: 0.0297 (0.0469, 0.0400)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0189)
2025-02-06 18:16:15,440 train INFO: [8580/46609/10000]  lr: 9.298113247644452e-05  eta: 0:03:00  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0205)  train/logits_fake: 0.0192 (0.0192, 0.0211)  train/total_loss: 6739.0688 (10801.5227, 6109.7461)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 139512.5938 (97072.4476, 128293.7266)  train/nll_loss: 6738.9326 (10801.4256, 6109.6177)  train/rec_loss: 0.0292 (0.0469, 0.0265)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0211)
2025-02-06 18:16:17,983 train INFO: [8600/46609/10000]  lr: 9.294916939566204e-05  eta: 0:02:57  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0193)  train/logits_fake: 0.0191 (0.0192, 0.0194)  train/total_loss: 6806.9727 (10793.6585, 5394.5747)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 139913.7500 (97166.1007, 134387.4688)  train/nll_loss: 6806.8242 (10793.5613, 5394.4404)  train/rec_loss: 0.0295 (0.0468, 0.0234)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0194)
2025-02-06 18:16:20,523 train INFO: [8620/46609/10000]  lr: 9.291713928184693e-05  eta: 0:02:55  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0183)  train/logits_fake: 0.0191 (0.0192, 0.0176)  train/total_loss: 6797.9282 (10783.9729, 5028.9980)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 139913.7500 (97276.1426, 172792.9375)  train/nll_loss: 6797.7822 (10783.8757, 5028.8252)  train/rec_loss: 0.0295 (0.0468, 0.0218)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0176)
2025-02-06 18:16:23,062 train INFO: [8640/46609/10000]  lr: 9.28850421855791e-05  eta: 0:02:52  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0175)  train/logits_fake: 0.0191 (0.0192, 0.0175)  train/total_loss: 6739.0688 (10774.8301, 4869.7354)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 139784.7188 (97379.1975, 148401.7188)  train/nll_loss: 6738.9326 (10774.7327, 4869.5869)  train/rec_loss: 0.0292 (0.0468, 0.0211)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0175)
2025-02-06 18:16:25,603 train INFO: [8660/46609/10000]  lr: 9.285287815754427e-05  eta: 0:02:50  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0194)  train/logits_fake: 0.0191 (0.0192, 0.0194)  train/total_loss: 6774.8154 (10767.7508, 8452.3193)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 139399.1094 (97486.4906, 145607.8281)  train/nll_loss: 6774.6982 (10767.6533, 8452.1738)  train/rec_loss: 0.0294 (0.0467, 0.0367)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0194)
2025-02-06 18:16:28,140 train INFO: [8680/46609/10000]  lr: 9.28206472485338e-05  eta: 0:02:47  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0184)  train/logits_fake: 0.0190 (0.0192, 0.0179)  train/total_loss: 6833.6787 (10760.1137, 6105.8496)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 145607.8281 (97618.7155, 164681.0781)  train/nll_loss: 6833.5273 (10760.0161, 6105.6851)  train/rec_loss: 0.0297 (0.0467, 0.0265)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0179)
2025-02-06 18:16:30,669 train INFO: [8700/46609/10000]  lr: 9.278834950944472e-05  eta: 0:02:45  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0207)  train/logits_fake: 0.0190 (0.0192, 0.0205)  train/total_loss: 6774.8154 (10751.8627, 7264.9814)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 147539.8438 (97738.8461, 143451.6406)  train/nll_loss: 6774.6982 (10751.7650, 7264.8379)  train/rec_loss: 0.0294 (0.0467, 0.0315)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0192, -0.0205)
2025-02-06 18:16:33,197 train INFO: [8720/46609/10000]  lr: 9.275598499127956e-05  eta: 0:02:42  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0187)  train/logits_fake: 0.0190 (0.0192, 0.0191)  train/total_loss: 6821.2148 (10741.9478, 4600.2026)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 148249.3750 (97849.5202, 176328.9062)  train/nll_loss: 6821.0830 (10741.8499, 4600.0264)  train/rec_loss: 0.0296 (0.0466, 0.0200)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0192, -0.0191)
2025-02-06 18:16:35,730 train INFO: [8740/46609/10000]  lr: 9.272355374514631e-05  eta: 0:02:40  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0190)  train/logits_fake: 0.0191 (0.0192, 0.0190)  train/total_loss: 6927.6699 (10732.6540, 6464.1074)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 148406.1875 (97958.1422, 151572.5000)  train/nll_loss: 6927.5215 (10732.5561, 6463.9561)  train/rec_loss: 0.0301 (0.0466, 0.0281)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0190)
2025-02-06 18:16:38,262 train INFO: [8760/46609/10000]  lr: 9.269105582225833e-05  eta: 0:02:37  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0175)  train/logits_fake: 0.0191 (0.0192, 0.0175)  train/total_loss: 6709.6431 (10722.9585, 6934.8838)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 148249.3750 (98069.7396, 161140.0000)  train/nll_loss: 6709.4824 (10722.8604, 6934.7227)  train/rec_loss: 0.0291 (0.0465, 0.0301)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0175)
2025-02-06 18:16:40,797 train INFO: [8780/46609/10000]  lr: 9.265849127393429e-05  eta: 0:02:34  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0183)  train/logits_fake: 0.0192 (0.0192, 0.0182)  train/total_loss: 6944.3774 (10716.2337, 8948.4443)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 145512.8438 (98180.4809, 145374.0625)  train/nll_loss: 6944.2285 (10716.1355, 8948.2988)  train/rec_loss: 0.0301 (0.0465, 0.0388)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0182)
2025-02-06 18:16:43,345 train INFO: [8800/46609/10000]  lr: 9.262586015159802e-05  eta: 0:02:32  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0160)  train/logits_fake: 0.0193 (0.0192, 0.0161)  train/total_loss: 6580.1123 (10706.7904, 9281.0791)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 143553.3906 (98277.0227, 166580.3438)  train/nll_loss: 6579.9619 (10706.6921, 9280.9121)  train/rec_loss: 0.0286 (0.0465, 0.0403)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0161)
2025-02-06 18:16:45,872 train INFO: [8820/46609/10000]  lr: 9.259316250677857e-05  eta: 0:02:29  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0179)  train/logits_fake: 0.0193 (0.0192, 0.0171)  train/total_loss: 6499.4214 (10696.5272, 6078.3662)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 142881.9375 (98386.5216, 137903.7031)  train/nll_loss: 6499.2974 (10696.4288, 6078.2285)  train/rec_loss: 0.0282 (0.0464, 0.0264)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0171)
2025-02-06 18:16:48,404 train INFO: [8840/46609/10000]  lr: 9.256039839110996e-05  eta: 0:02:27  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0220)  train/logits_fake: 0.0192 (0.0192, 0.0214)  train/total_loss: 6638.6836 (10687.8532, 7323.5981)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 144493.1562 (98509.1995, 135958.0469)  train/nll_loss: 6638.5332 (10687.7546, 7323.4624)  train/rec_loss: 0.0288 (0.0464, 0.0318)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0214)
2025-02-06 18:16:50,936 train INFO: [8860/46609/10000]  lr: 9.252756785633119e-05  eta: 0:02:24  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0185)  train/logits_fake: 0.0193 (0.0192, 0.0182)  train/total_loss: 6322.2358 (10676.6472, 5563.9126)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 145374.0625 (98622.8208, 166347.9062)  train/nll_loss: 6322.0840 (10676.5486, 5563.7461)  train/rec_loss: 0.0274 (0.0463, 0.0241)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0182)
2025-02-06 18:16:53,470 train INFO: [8880/46609/10000]  lr: 9.249467095428616e-05  eta: 0:02:22  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0185)  train/logits_fake: 0.0193 (0.0192, 0.0183)  train/total_loss: 6260.2983 (10667.6900, 6297.2949)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 145907.4062 (98724.8736, 115352.2500)  train/nll_loss: 6260.1768 (10667.5913, 6297.1797)  train/rec_loss: 0.0272 (0.0463, 0.0273)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0183)
2025-02-06 18:16:56,004 train INFO: [8900/46609/10000]  lr: 9.246170773692357e-05  eta: 0:02:19  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0188)  train/logits_fake: 0.0191 (0.0192, 0.0187)  train/total_loss: 6218.9810 (10658.8574, 5419.5518)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 146016.8125 (98823.5905, 162608.7812)  train/nll_loss: 6218.8203 (10658.7586, 5419.3892)  train/rec_loss: 0.0270 (0.0463, 0.0235)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0187)
2025-02-06 18:16:58,538 train INFO: [8920/46609/10000]  lr: 9.242867825629686e-05  eta: 0:02:17  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0198)  train/logits_fake: 0.0191 (0.0192, 0.0203)  train/total_loss: 6220.5889 (10649.8894, 5556.7114)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 146137.5781 (98931.9238, 126618.9219)  train/nll_loss: 6220.4448 (10649.7905, 5556.5850)  train/rec_loss: 0.0270 (0.0462, 0.0241)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0203)
2025-02-06 18:17:01,078 train INFO: [8940/46609/10000]  lr: 9.239558256456405e-05  eta: 0:02:14  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0190)  train/logits_fake: 0.0192 (0.0192, 0.0191)  train/total_loss: 6218.9810 (10641.9285, 8111.8125)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 146137.5781 (99049.6307, 122399.0156)  train/nll_loss: 6218.8203 (10641.8294, 8111.6899)  train/rec_loss: 0.0270 (0.0462, 0.0352)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0191)
2025-02-06 18:17:03,617 train INFO: [8960/46609/10000]  lr: 9.23624207139878e-05  eta: 0:02:12  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0195)  train/logits_fake: 0.0192 (0.0192, 0.0196)  train/total_loss: 6318.2100 (10632.3042, 6405.6797)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 145514.2812 (99156.2565, 125194.8438)  train/nll_loss: 6318.0801 (10632.2050, 6405.5547)  train/rec_loss: 0.0274 (0.0461, 0.0278)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0196)
2025-02-06 18:17:06,162 train INFO: [8980/46609/10000]  lr: 9.232919275693516e-05  eta: 0:02:09  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0177)  train/logits_fake: 0.0191 (0.0192, 0.0179)  train/total_loss: 6213.8359 (10622.8285, 5788.6323)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 146465.4375 (99277.5444, 135991.6719)  train/nll_loss: 6213.6670 (10622.7292, 5788.4961)  train/rec_loss: 0.0270 (0.0461, 0.0251)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0179)
2025-02-06 18:17:08,703 train INFO: [9000/46609/10000]  lr: 9.229589874587763e-05  eta: 0:02:07  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0200)  train/logits_fake: 0.0191 (0.0192, 0.0201)  train/total_loss: 6295.5742 (10614.3284, 6676.3350)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 147666.1250 (99384.4815, 147164.2812)  train/nll_loss: 6295.4385 (10614.2290, 6676.1880)  train/rec_loss: 0.0273 (0.0461, 0.0290)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0201)
2025-02-06 18:17:11,242 train INFO: [9020/46609/10000]  lr: 9.226253873339098e-05  eta: 0:02:04  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0197)  train/logits_fake: 0.0191 (0.0192, 0.0202)  train/total_loss: 6318.2100 (10604.8516, 6256.1523)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 145980.8750 (99486.9427, 130941.2969)  train/nll_loss: 6318.0801 (10604.7521, 6256.0215)  train/rec_loss: 0.0274 (0.0460, 0.0272)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0202)
2025-02-06 18:17:13,780 train INFO: [9040/46609/10000]  lr: 9.222911277215525e-05  eta: 0:02:01  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0202)  train/logits_fake: 0.0192 (0.0192, 0.0204)  train/total_loss: 6328.5210 (10596.0959, 6153.0151)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 145659.3281 (99584.6140, 152166.2812)  train/nll_loss: 6328.4087 (10595.9963, 6152.8628)  train/rec_loss: 0.0275 (0.0460, 0.0267)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0204)
2025-02-06 18:17:16,317 train INFO: [9060/46609/10000]  lr: 9.219562091495456e-05  eta: 0:01:59  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0222)  train/logits_fake: 0.0192 (0.0192, 0.0225)  train/total_loss: 6341.6689 (10586.8093, 6288.4868)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 145915.5625 (99684.3528, 144953.7656)  train/nll_loss: 6341.5332 (10586.7096, 6288.3418)  train/rec_loss: 0.0275 (0.0459, 0.0273)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0225)
2025-02-06 18:17:18,854 train INFO: [9080/46609/10000]  lr: 9.216206321467716e-05  eta: 0:01:56  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0183)  train/logits_fake: 0.0192 (0.0192, 0.0179)  train/total_loss: 6341.6689 (10577.2416, 7426.6963)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 145233.2344 (99782.7030, 149666.5000)  train/nll_loss: 6341.5332 (10577.1418, 7426.5464)  train/rec_loss: 0.0275 (0.0459, 0.0322)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0179)
2025-02-06 18:17:21,392 train INFO: [9100/46609/10000]  lr: 9.212843972431522e-05  eta: 0:01:54  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0208)  train/logits_fake: 0.0193 (0.0192, 0.0205)  train/total_loss: 6360.2935 (10569.8353, 5597.8955)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 145155.1250 (99884.2108, 152773.0938)  train/nll_loss: 6360.1191 (10569.7354, 5597.7427)  train/rec_loss: 0.0276 (0.0459, 0.0243)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0205)
2025-02-06 18:17:23,928 train INFO: [9120/46609/10000]  lr: 9.209475049696483e-05  eta: 0:01:51  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0191)  train/logits_fake: 0.0192 (0.0192, 0.0184)  train/total_loss: 6300.2690 (10560.4544, 6828.3896)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 146913.3594 (99994.1810, 148638.8594)  train/nll_loss: 6300.1523 (10560.3544, 6828.2412)  train/rec_loss: 0.0273 (0.0458, 0.0296)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0184)
2025-02-06 18:17:26,471 train INFO: [9140/46609/10000]  lr: 9.206099558582587e-05  eta: 0:01:49  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0175)  train/logits_fake: 0.0191 (0.0192, 0.0176)  train/total_loss: 6288.4868 (10551.6465, 5566.0908)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 147426.1250 (100095.6112, 143246.4531)  train/nll_loss: 6288.3418 (10551.5464, 5565.9478)  train/rec_loss: 0.0273 (0.0458, 0.0242)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0176)
2025-02-06 18:17:29,021 train INFO: [9160/46609/10000]  lr: 9.202717504420194e-05  eta: 0:01:46  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0197)  train/logits_fake: 0.0192 (0.0192, 0.0192)  train/total_loss: 6274.4541 (10542.6438, 12904.8125)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 145744.2500 (100183.3703, 104881.0000)  train/nll_loss: 6274.3091 (10542.5437, 12904.7080)  train/rec_loss: 0.0272 (0.0458, 0.0560)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0192)
2025-02-06 18:17:31,565 train INFO: [9180/46609/10000]  lr: 9.199328892550032e-05  eta: 0:01:44  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0186)  train/logits_fake: 0.0192 (0.0192, 0.0192)  train/total_loss: 6423.5977 (10535.9273, 7587.2617)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 145787.7188 (100283.4151, 126196.0391)  train/nll_loss: 6423.4365 (10535.8270, 7587.1357)  train/rec_loss: 0.0279 (0.0457, 0.0329)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0192)
2025-02-06 18:17:34,103 train INFO: [9200/46609/10000]  lr: 9.195933728323181e-05  eta: 0:01:41  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0196)  train/logits_fake: 0.0191 (0.0192, 0.0191)  train/total_loss: 6442.1011 (10528.3123, 6759.8071)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 147192.9062 (100386.2980, 147192.9062)  train/nll_loss: 6441.9639 (10528.2119, 6759.6602)  train/rec_loss: 0.0280 (0.0457, 0.0293)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0191)
2025-02-06 18:17:36,645 train INFO: [9220/46609/10000]  lr: 9.192532017101067e-05  eta: 0:01:39  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0186)  train/logits_fake: 0.0192 (0.0192, 0.0186)  train/total_loss: 6577.5615 (10521.5502, 8264.6885)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 145787.7188 (100496.5599, 120030.7031)  train/nll_loss: 6577.4141 (10521.4497, 8264.5684)  train/rec_loss: 0.0285 (0.0457, 0.0359)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0186)
2025-02-06 18:17:39,189 train INFO: [9240/46609/10000]  lr: 9.189123764255458e-05  eta: 0:01:36  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0187)  train/logits_fake: 0.0194 (0.0192, 0.0188)  train/total_loss: 6434.5054 (10511.4833, 7842.1182)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 143564.8906 (100586.3108, 129699.0156)  train/nll_loss: 6434.3662 (10511.3827, 7841.9883)  train/rec_loss: 0.0279 (0.0456, 0.0340)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0188)
2025-02-06 18:17:41,723 train INFO: [9260/46609/10000]  lr: 9.185708975168449e-05  eta: 0:01:33  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0204)  train/logits_fake: 0.0194 (0.0192, 0.0200)  train/total_loss: 6607.0908 (10504.6573, 7370.8599)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 145374.2188 (100689.6053, 148156.1562)  train/nll_loss: 6606.9067 (10504.5567, 7370.7119)  train/rec_loss: 0.0287 (0.0456, 0.0320)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0200)
2025-02-06 18:17:44,262 train INFO: [9280/46609/10000]  lr: 9.182287655232461e-05  eta: 0:01:31  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0206)  train/logits_fake: 0.0194 (0.0192, 0.0208)  train/total_loss: 6406.1304 (10495.5194, 6066.9561)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 147318.0625 (100791.2495, 150421.3438)  train/nll_loss: 6405.9941 (10495.4186, 6066.8057)  train/rec_loss: 0.0278 (0.0456, 0.0263)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0208)
2025-02-06 18:17:46,801 train INFO: [9300/46609/10000]  lr: 9.178859809850221e-05  eta: 0:01:28  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0170)  train/logits_fake: 0.0194 (0.0192, 0.0174)  train/total_loss: 6275.3521 (10488.0341, 9889.2676)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 147094.8125 (100899.5956, 163909.0312)  train/nll_loss: 6275.2046 (10487.9332, 9889.1035)  train/rec_loss: 0.0272 (0.0455, 0.0429)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0174)
2025-02-06 18:17:49,335 train INFO: [9320/46609/10000]  lr: 9.175425444434769e-05  eta: 0:01:26  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0175)  train/logits_fake: 0.0192 (0.0192, 0.0177)  train/total_loss: 6324.6094 (10479.6458, 5784.0859)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 147585.0625 (101021.1013, 164210.5000)  train/nll_loss: 6324.4536 (10479.5447, 5783.9219)  train/rec_loss: 0.0274 (0.0455, 0.0251)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0177)
2025-02-06 18:17:51,959 train INFO: [9340/46609/10000]  lr: 9.171984564409432e-05  eta: 0:01:23  iter_time: 0.138  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0174)  train/logits_fake: 0.0190 (0.0192, 0.0170)  train/total_loss: 6489.7480 (10471.2271, 7536.7153)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 155487.7812 (101164.4960, 180367.6562)  train/nll_loss: 6489.6343 (10471.1259, 7536.5352)  train/rec_loss: 0.0282 (0.0454, 0.0327)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0192, -0.0170)
2025-02-06 18:17:54,486 train INFO: [9360/46609/10000]  lr: 9.168537175207834e-05  eta: 0:01:21  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0204)  train/logits_fake: 0.0190 (0.0192, 0.0204)  train/total_loss: 6391.7788 (10462.7915, 5393.2642)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 155844.7812 (101271.4383, 123480.0547)  train/nll_loss: 6391.6084 (10462.6902, 5393.1406)  train/rec_loss: 0.0277 (0.0454, 0.0234)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0192, -0.0204)
2025-02-06 18:17:57,013 train INFO: [9380/46609/10000]  lr: 9.165083282273869e-05  eta: 0:01:18  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0194)  train/logits_fake: 0.0191 (0.0192, 0.0195)  train/total_loss: 6411.5825 (10454.5951, 6417.4155)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 156640.5312 (101382.9872, 116020.3594)  train/nll_loss: 6411.4219 (10454.4937, 6417.2993)  train/rec_loss: 0.0278 (0.0454, 0.0279)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0195)
2025-02-06 18:17:59,538 train INFO: [9400/46609/10000]  lr: 9.161622891061709e-05  eta: 0:01:16  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0194)  train/logits_fake: 0.0192 (0.0192, 0.0193)  train/total_loss: 6340.5415 (10445.5629, 6896.2134)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 158252.7188 (101497.9162, 139059.0000)  train/nll_loss: 6340.3535 (10445.4614, 6896.0742)  train/rec_loss: 0.0275 (0.0453, 0.0299)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0193)
2025-02-06 18:18:02,077 train INFO: [9420/46609/10000]  lr: 9.158156007035782e-05  eta: 0:01:13  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0184)  train/logits_fake: 0.0192 (0.0192, 0.0186)  train/total_loss: 6229.6782 (10438.0862, 7199.9170)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 158341.0781 (101631.7729, 190876.2188)  train/nll_loss: 6229.5063 (10437.9846, 7199.7261)  train/rec_loss: 0.0270 (0.0453, 0.0312)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0186)
2025-02-06 18:18:04,621 train INFO: [9440/46609/10000]  lr: 9.154682635670772e-05  eta: 0:01:11  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0196)  train/logits_fake: 0.0192 (0.0192, 0.0201)  train/total_loss: 6242.0161 (10430.8143, 5673.5547)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 156941.0938 (101738.1324, 131399.1250)  train/nll_loss: 6241.8159 (10430.7126, 5673.4233)  train/rec_loss: 0.0271 (0.0453, 0.0246)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0201)
2025-02-06 18:18:07,160 train INFO: [9460/46609/10000]  lr: 9.151202782451605e-05  eta: 0:01:08  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0201)  train/logits_fake: 0.0193 (0.0192, 0.0199)  train/total_loss: 6330.4683 (10422.9537, 15370.2822)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 157796.2188 (101863.8016, 139200.4062)  train/nll_loss: 6330.3184 (10422.8518, 15370.1426)  train/rec_loss: 0.0275 (0.0452, 0.0667)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0199)
2025-02-06 18:18:09,699 train INFO: [9480/46609/10000]  lr: 9.147716452873446e-05  eta: 0:01:06  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0233)  train/logits_fake: 0.0191 (0.0192, 0.0235)  train/total_loss: 6317.8413 (10414.9333, 7095.6172)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 157934.5625 (101983.3109, 159208.1250)  train/nll_loss: 6317.6738 (10414.8313, 7095.4580)  train/rec_loss: 0.0274 (0.0452, 0.0308)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0235)
2025-02-06 18:18:12,238 train INFO: [9500/46609/10000]  lr: 9.144223652441683e-05  eta: 0:01:03  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0177)  train/logits_fake: 0.0190 (0.0192, 0.0173)  train/total_loss: 6507.0659 (10407.4148, 6102.8286)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 157484.0469 (102101.2112, 145853.0312)  train/nll_loss: 6506.9268 (10407.3128, 6102.6826)  train/rec_loss: 0.0282 (0.0452, 0.0265)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0192, -0.0173)
2025-02-06 18:18:14,779 train INFO: [9520/46609/10000]  lr: 9.140724386671929e-05  eta: 0:01:00  iter_time: 0.128  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0192)  train/logits_fake: 0.0190 (0.0192, 0.0199)  train/total_loss: 6658.5005 (10400.8532, 7189.2217)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 154899.5312 (102199.4748, 200894.8750)  train/nll_loss: 6658.3350 (10400.7510, 7189.0210)  train/rec_loss: 0.0289 (0.0451, 0.0312)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0192, -0.0199)
2025-02-06 18:18:17,319 train INFO: [9540/46609/10000]  lr: 9.137218661089997e-05  eta: 0:00:58  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0191)  train/logits_fake: 0.0192 (0.0192, 0.0192)  train/total_loss: 6504.8286 (10392.8600, 13710.2744)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 154025.3125 (102307.9077, 178829.3906)  train/nll_loss: 6504.6953 (10392.7577, 13710.0957)  train/rec_loss: 0.0282 (0.0451, 0.0595)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0192)
2025-02-06 18:18:19,860 train INFO: [9560/46609/10000]  lr: 9.13370648123191e-05  eta: 0:00:55  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0187)  train/logits_fake: 0.0192 (0.0192, 0.0192)  train/total_loss: 6335.2832 (10383.9302, 7139.1860)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 151939.7812 (102394.7307, 168698.8438)  train/nll_loss: 6335.1201 (10383.8278, 7139.0176)  train/rec_loss: 0.0275 (0.0451, 0.0310)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0192)
2025-02-06 18:18:22,398 train INFO: [9580/46609/10000]  lr: 9.130187852643877e-05  eta: 0:00:53  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0187)  train/logits_fake: 0.0193 (0.0192, 0.0180)  train/total_loss: 6299.6333 (10375.2855, 7660.5195)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 151381.2188 (102500.4310, 140600.5469)  train/nll_loss: 6299.4648 (10375.1830, 7660.3789)  train/rec_loss: 0.0273 (0.0450, 0.0332)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0180)
2025-02-06 18:18:24,934 train INFO: [9600/46609/10000]  lr: 9.126662780882294e-05  eta: 0:00:50  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0193)  train/logits_fake: 0.0193 (0.0192, 0.0191)  train/total_loss: 6040.9053 (10366.4957, 5148.2349)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 150029.0312 (102605.5796, 133515.4375)  train/nll_loss: 6040.7271 (10366.3931, 5148.1016)  train/rec_loss: 0.0262 (0.0450, 0.0223)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0191)
2025-02-06 18:18:27,469 train INFO: [9620/46609/10000]  lr: 9.123131271513731e-05  eta: 0:00:48  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0192)  train/logits_fake: 0.0192 (0.0192, 0.0200)  train/total_loss: 6040.9053 (10358.6114, 4891.4673)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 151588.1250 (102710.9567, 146244.3438)  train/nll_loss: 6040.7271 (10358.5086, 4891.3208)  train/rec_loss: 0.0262 (0.0450, 0.0212)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0200)
2025-02-06 18:18:30,011 train INFO: [9640/46609/10000]  lr: 9.119593330114921e-05  eta: 0:00:45  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0192)  train/logits_fake: 0.0191 (0.0192, 0.0188)  train/total_loss: 6171.4819 (10351.7008, 9204.4248)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 152995.0625 (102823.9341, 153522.8438)  train/nll_loss: 6171.3418 (10351.5980, 9204.2715)  train/rec_loss: 0.0268 (0.0449, 0.0399)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0188)
2025-02-06 18:18:32,553 train INFO: [9660/46609/10000]  lr: 9.11604896227276e-05  eta: 0:00:43  iter_time: 0.127  data: 0.001  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0180)  train/logits_fake: 0.0191 (0.0192, 0.0184)  train/total_loss: 6171.4819 (10341.7949, 4862.9478)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 153522.8438 (102911.8641, 122423.9844)  train/nll_loss: 6171.3418 (10341.6920, 4862.8252)  train/rec_loss: 0.0268 (0.0449, 0.0211)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0184)
2025-02-06 18:18:35,104 train INFO: [9680/46609/10000]  lr: 9.112498173584287e-05  eta: 0:00:40  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0198)  train/logits_fake: 0.0190 (0.0192, 0.0196)  train/total_loss: 6179.8589 (10333.0745, 4774.0718)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 154201.6562 (103022.3393, 119439.1016)  train/nll_loss: 6179.7061 (10332.9715, 4773.9521)  train/rec_loss: 0.0268 (0.0448, 0.0207)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0196)
2025-02-06 18:18:37,647 train INFO: [9700/46609/10000]  lr: 9.108940969656679e-05  eta: 0:00:38  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0199)  train/logits_fake: 0.0191 (0.0192, 0.0201)  train/total_loss: 5944.9878 (10323.7992, 4437.5972)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 153246.8125 (103116.4266, 136031.1875)  train/nll_loss: 5944.8218 (10323.6961, 4437.4609)  train/rec_loss: 0.0258 (0.0448, 0.0193)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0201)
2025-02-06 18:18:40,193 train INFO: [9720/46609/10000]  lr: 9.105377356107251e-05  eta: 0:00:35  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0210)  train/logits_fake: 0.0193 (0.0192, 0.0205)  train/total_loss: 5947.9888 (10317.2075, 6601.5928)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 154201.6562 (103222.1781, 140809.7656)  train/nll_loss: 5947.8467 (10317.1043, 6601.4521)  train/rec_loss: 0.0258 (0.0448, 0.0287)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0205)
2025-02-06 18:18:42,740 train INFO: [9740/46609/10000]  lr: 9.101807338563434e-05  eta: 0:00:33  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0194 (0.0191, 0.0202)  train/logits_fake: 0.0194 (0.0192, 0.0202)  train/total_loss: 5801.8247 (10308.6870, 7313.9214)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 153246.8125 (103333.8463, 183866.5000)  train/nll_loss: 5801.6572 (10308.5837, 7313.7373)  train/rec_loss: 0.0252 (0.0447, 0.0317)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0202)
2025-02-06 18:18:45,285 train INFO: [9760/46609/10000]  lr: 9.098230922662772e-05  eta: 0:00:30  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0194 (0.0191, 0.0194)  train/logits_fake: 0.0194 (0.0192, 0.0200)  train/total_loss: 5807.9502 (10299.4299, 4812.2373)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 155401.9375 (103436.8942, 143695.8750)  train/nll_loss: 5807.7778 (10299.3264, 4812.0938)  train/rec_loss: 0.0252 (0.0447, 0.0209)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0200)
2025-02-06 18:18:47,825 train INFO: [9780/46609/10000]  lr: 9.094648114052913e-05  eta: 0:00:27  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0195 (0.0191, 0.0198)  train/logits_fake: 0.0194 (0.0192, 0.0201)  train/total_loss: 5798.5688 (10290.3411, 6724.8135)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 153878.1875 (103542.9092, 162415.0312)  train/nll_loss: 5798.4043 (10290.2375, 6724.6509)  train/rec_loss: 0.0252 (0.0447, 0.0292)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0201)
2025-02-06 18:18:50,367 train INFO: [9800/46609/10000]  lr: 9.091058918391603e-05  eta: 0:00:25  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0195 (0.0191, 0.0200)  train/logits_fake: 0.0196 (0.0192, 0.0203)  train/total_loss: 5898.6650 (10281.3669, 5716.4839)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 156906.0000 (103658.0919, 136326.9062)  train/nll_loss: 5898.5342 (10281.2633, 5716.3477)  train/rec_loss: 0.0256 (0.0446, 0.0248)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0196 (-0.0192, -0.0203)
2025-02-06 18:18:52,904 train INFO: [9820/46609/10000]  lr: 9.087463341346672e-05  eta: 0:00:22  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0194 (0.0191, 0.0173)  train/logits_fake: 0.0194 (0.0192, 0.0181)  train/total_loss: 5770.1860 (10272.4588, 7039.8486)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 157125.3750 (103769.6968, 171048.3438)  train/nll_loss: 5770.0278 (10272.3550, 7039.6777)  train/rec_loss: 0.0250 (0.0446, 0.0306)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0181)
2025-02-06 18:18:55,439 train INFO: [9840/46609/10000]  lr: 9.083861388596024e-05  eta: 0:00:20  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0194 (0.0191, 0.0176)  train/logits_fake: 0.0195 (0.0192, 0.0180)  train/total_loss: 5794.9092 (10263.6646, 7611.8535)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 157125.3750 (103876.6945, 173766.4375)  train/nll_loss: 5794.7549 (10263.5607, 7611.6797)  train/rec_loss: 0.0252 (0.0445, 0.0330)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0180)
2025-02-06 18:18:57,962 train INFO: [9860/46609/10000]  lr: 9.080253065827637e-05  eta: 0:00:17  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0202)  train/logits_fake: 0.0195 (0.0192, 0.0204)  train/total_loss: 5793.3931 (10255.4535, 5506.2056)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 159664.8750 (104013.2345, 159530.4531)  train/nll_loss: 5793.2461 (10255.3495, 5506.0459)  train/rec_loss: 0.0251 (0.0445, 0.0239)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0204)
2025-02-06 18:19:00,485 train INFO: [9880/46609/10000]  lr: 9.076638378739544e-05  eta: 0:00:15  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0194)  train/logits_fake: 0.0195 (0.0192, 0.0191)  train/total_loss: 5794.9092 (10247.7184, 6368.2344)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 158752.5000 (104120.0224, 201379.7188)  train/nll_loss: 5794.7549 (10247.6143, 6368.0332)  train/rec_loss: 0.0252 (0.0445, 0.0276)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0191)
2025-02-06 18:19:03,013 train INFO: [9900/46609/10000]  lr: 9.073017333039831e-05  eta: 0:00:12  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0176)  train/logits_fake: 0.0192 (0.0192, 0.0184)  train/total_loss: 6093.4956 (10240.2597, 9057.6719)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 159530.4531 (104237.9446, 154137.0625)  train/nll_loss: 6093.3320 (10240.1555, 9057.5176)  train/rec_loss: 0.0264 (0.0444, 0.0393)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0184)
2025-02-06 18:19:05,550 train INFO: [9920/46609/10000]  lr: 9.069389934446619e-05  eta: 0:00:10  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0193)  train/logits_fake: 0.0191 (0.0192, 0.0190)  train/total_loss: 6209.3965 (10232.9129, 5729.7310)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 158192.6250 (104340.2743, 135951.3125)  train/nll_loss: 6209.2402 (10232.8086, 5729.5952)  train/rec_loss: 0.0269 (0.0444, 0.0249)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0190)
2025-02-06 18:19:08,088 train INFO: [9940/46609/10000]  lr: 9.065756188688072e-05  eta: 0:00:07  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0186)  train/logits_fake: 0.0192 (0.0192, 0.0188)  train/total_loss: 6274.2080 (10226.0034, 4748.4795)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 160369.8906 (104464.3989, 182822.2812)  train/nll_loss: 6274.0659 (10225.8990, 4748.2969)  train/rec_loss: 0.0272 (0.0444, 0.0206)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0188)
2025-02-06 18:19:10,639 train INFO: [9960/46609/10000]  lr: 9.062116101502362e-05  eta: 0:00:05  iter_time: 0.128  data: 0.001  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0180)  train/logits_fake: 0.0191 (0.0192, 0.0179)  train/total_loss: 6274.2080 (10217.7002, 5890.8213)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 158468.8750 (104579.9042, 201020.6406)  train/nll_loss: 6274.0659 (10217.5956, 5890.6201)  train/rec_loss: 0.0272 (0.0443, 0.0256)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0179)
2025-02-06 18:19:13,180 train INFO: [9980/46609/10000]  lr: 9.058469678637693e-05  eta: 0:00:02  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0217)  train/logits_fake: 0.0190 (0.0192, 0.0214)  train/total_loss: 6219.3345 (10208.5366, 4625.4570)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 158718.1406 (104686.8323, 144642.8438)  train/nll_loss: 6219.1631 (10208.4319, 4625.3125)  train/rec_loss: 0.0270 (0.0443, 0.0201)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0192, -0.0214)
2025-02-06 18:19:15,720 train INFO: [10000/46609/10000]  lr: 9.054816925852258e-05  eta: 0:00:00  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0208)  train/logits_fake: 0.0192 (0.0192, 0.0204)  train/total_loss: 6011.7437 (10199.5297, 7687.7261)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 158379.9375 (104796.6103, 178272.1094)  train/nll_loss: 6011.5674 (10199.4249, 7687.5479)  train/rec_loss: 0.0261 (0.0443, 0.0334)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0204)
2025-02-06 18:55:08,141 train INFO: Epoch [1.21](val stats)  val/disc_loss: 0.0000 (0.0000, 0.0000)  val/logits_real: 0.0182 (0.0191, 0.0227)  val/logits_fake: 0.0186 (0.0193, 0.0188)  val/total_loss: 8525.4355 (6536.3181, 19964.9102)  val/logvar: 0.0000 (0.0000, 0.0000)  val/kl_loss: 170139.8906 (154154.5510, 155839.2344)  val/nll_loss: 8525.2529 (6536.1640, 19964.7539)  val/rec_loss: 0.0370 (0.0284, 0.0867)  val/d_weight: 0.0000 (0.0000, 0.0000)  val/disc_factor: 0.0000 (0.0000, 0.0000)  val/g_loss: -0.0186 (-0.0193, -0.0188)  MSE: 0.0036 (0.0022, 0.0215)
