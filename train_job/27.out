/home/exouser/YuZheng/experiments/autoencoder_kl_gan/world_size1-hmdb_autoencoder
load yaml from config
Launching processes...
2025-02-06 16:45:51,206 train INFO: Building config ...
2025-02-06 16:45:51,206 train INFO: Building dataloaders ...
Total frames in dataset: 186436
2025-02-06 16:46:48,273 train INFO: Train dataloaders build complete
Total frames in dataset: 186436
2025-02-06 16:47:46,552 train INFO: Valid dataloaders build complete
2025-02-06 16:47:46,552 train INFO: Building models ...
2025-02-06 16:47:47,262 train INFO: finetune checkpoint path not exist
2025-02-06 16:47:47,462 train INFO: params autoencoder_kl: 55912619
2025-02-06 16:47:47,462 train INFO: params lpipsWithDisc: 2765634
2025-02-06 16:47:47,462 train INFO: begin training ...
2025-02-06 16:47:51,517 train INFO: [20/46609/10000]  lr: 2.881e-06  eta: 0:33:42  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0192, 0.0193)  train/logits_fake: 0.0165 (0.0165, 0.0165)  train/total_loss: 77274.3438 (77418.3854, 61890.3516)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 1029.6680 (990.2441, 1440.2336)  train/nll_loss: 77274.3438 (77418.3854, 61890.3516)  train/rec_loss: 0.3354 (0.3360, 0.2686)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0165 (-0.0165, -0.0165)
2025-02-06 16:47:54,037 train INFO: [40/46609/10000]  lr: 4.8610000000000006e-06  eta: 0:27:16  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0201)  train/logits_fake: 0.0167 (0.0170, 0.0194)  train/total_loss: 59703.1016 (66339.6301, 50114.7344)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 1349.0759 (1293.9130, 1998.3875)  train/nll_loss: 59703.1016 (66339.6299, 50114.7305)  train/rec_loss: 0.2591 (0.2879, 0.2175)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0167 (-0.0170, -0.0194)
2025-02-06 16:47:56,555 train INFO: [60/46609/10000]  lr: 6.841e-06  eta: 0:25:06  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0192, 0.0200)  train/logits_fake: 0.0175 (0.0178, 0.0194)  train/total_loss: 54939.3047 (57757.8602, 34564.0117)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 1571.9786 (1759.9185, 4037.5503)  train/nll_loss: 54939.3047 (57757.8588, 34564.0078)  train/rec_loss: 0.2385 (0.2507, 0.1500)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0176 (-0.0178, -0.0194)
2025-02-06 16:47:59,077 train INFO: [80/46609/10000]  lr: 8.821000000000002e-06  eta: 0:24:00  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0193, 0.0181)  train/logits_fake: 0.0187 (0.0185, 0.0212)  train/total_loss: 48000.0312 (51724.5589, 33155.2305)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 2068.5952 (2361.3467, 4493.7031)  train/nll_loss: 48000.0273 (51724.5568, 33155.2266)  train/rec_loss: 0.2083 (0.2245, 0.1439)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0189 (-0.0185, -0.0212)
2025-02-06 16:48:01,606 train INFO: [100/46609/10000]  lr: 1.0801000000000002e-05  eta: 0:23:20  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0192, 0.0170)  train/logits_fake: 0.0192 (0.0187, 0.0184)  train/total_loss: 39382.6758 (47519.9471, 33660.6914)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 2580.1299 (2827.8540, 4795.7900)  train/nll_loss: 39382.6719 (47519.9445, 33660.6875)  train/rec_loss: 0.1709 (0.2062, 0.1461)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0187, -0.0184)
2025-02-06 16:48:04,150 train INFO: [120/46609/10000]  lr: 1.2781000000000002e-05  eta: 0:22:53  iter_time: 0.127  data: 0.001  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0192, 0.0188)  train/logits_fake: 0.0196 (0.0189, 0.0187)  train/total_loss: 34516.8242 (44234.3050, 27449.7363)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 4071.4204 (3379.0720, 7121.3398)  train/nll_loss: 34516.8203 (44234.3019, 27449.7285)  train/rec_loss: 0.1498 (0.1920, 0.1191)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0196 (-0.0189, -0.0187)
2025-02-06 16:48:06,681 train INFO: [140/46609/10000]  lr: 1.4761000000000003e-05  eta: 0:22:33  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0192, 0.0182)  train/logits_fake: 0.0199 (0.0190, 0.0205)  train/total_loss: 31113.7383 (41757.4598, 25680.7422)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 4816.2109 (3951.2491, 6968.7998)  train/nll_loss: 31113.7344 (41757.4560, 25680.7344)  train/rec_loss: 0.1350 (0.1812, 0.1115)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0199 (-0.0190, -0.0205)
2025-02-06 16:48:09,212 train INFO: [160/46609/10000]  lr: 1.6741e-05  eta: 0:22:17  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0192, 0.0191)  train/logits_fake: 0.0200 (0.0191, 0.0199)  train/total_loss: 28042.5977 (39802.4239, 22357.4375)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 6123.3638 (4444.3472, 8234.8242)  train/nll_loss: 28042.5938 (39802.4196, 22357.4297)  train/rec_loss: 0.1217 (0.1728, 0.0970)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0200 (-0.0191, -0.0199)
2025-02-06 16:48:11,751 train INFO: [180/46609/10000]  lr: 1.8721000000000003e-05  eta: 0:22:05  iter_time: 0.127  data: 0.001  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0192, 0.0194)  train/logits_fake: 0.0199 (0.0192, 0.0204)  train/total_loss: 26622.4727 (37980.9287, 19054.9434)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 7325.7139 (4920.5205, 8833.5303)  train/nll_loss: 26622.4668 (37980.9239, 19054.9336)  train/rec_loss: 0.1155 (0.1648, 0.0827)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0199 (-0.0192, -0.0204)
2025-02-06 16:48:14,290 train INFO: [200/46609/10000]  lr: 2.0701000000000004e-05  eta: 0:21:54  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0192, 0.0206)  train/logits_fake: 0.0198 (0.0192, 0.0202)  train/total_loss: 25085.0625 (36525.8912, 25600.9453)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 7863.3018 (5335.7657, 9575.4736)  train/nll_loss: 25085.0547 (36525.8860, 25600.9355)  train/rec_loss: 0.1089 (0.1585, 0.1111)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0199 (-0.0192, -0.0202)
2025-02-06 16:48:16,826 train INFO: [220/46609/10000]  lr: 2.2681000000000002e-05  eta: 0:21:45  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0170)  train/logits_fake: 0.0197 (0.0192, 0.0204)  train/total_loss: 24398.7129 (35466.7684, 32375.7148)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 8553.1064 (5742.6983, 10873.6777)  train/nll_loss: 24398.7051 (35466.7628, 32375.7031)  train/rec_loss: 0.1059 (0.1539, 0.1405)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0197 (-0.0192, -0.0204)
2025-02-06 16:48:19,357 train INFO: [240/46609/10000]  lr: 2.4661000000000003e-05  eta: 0:21:36  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0193)  train/logits_fake: 0.0196 (0.0192, 0.0201)  train/total_loss: 24015.7051 (34568.0607, 22348.6953)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 9169.7129 (6216.4268, 11366.1641)  train/nll_loss: 24015.6953 (34568.0545, 22348.6836)  train/rec_loss: 0.1042 (0.1500, 0.0970)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0196 (-0.0192, -0.0201)
2025-02-06 16:48:21,889 train INFO: [260/46609/10000]  lr: 2.6641000000000005e-05  eta: 0:21:29  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0203)  train/logits_fake: 0.0195 (0.0192, 0.0204)  train/total_loss: 23481.9570 (33666.3064, 26945.4570)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 9721.7812 (6673.2135, 12409.9561)  train/nll_loss: 23481.9453 (33666.2998, 26945.4453)  train/rec_loss: 0.1019 (0.1461, 0.1170)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0204)
2025-02-06 16:48:24,417 train INFO: [280/46609/10000]  lr: 2.8621000000000003e-05  eta: 0:21:22  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0180)  train/logits_fake: 0.0195 (0.0193, 0.0208)  train/total_loss: 23069.0254 (32812.9934, 21380.1660)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 11335.9863 (7129.2967, 12731.9023)  train/nll_loss: 23069.0156 (32812.9863, 21380.1523)  train/rec_loss: 0.1001 (0.1424, 0.0928)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0208)
2025-02-06 16:48:26,944 train INFO: [300/46609/10000]  lr: 3.0601e-05  eta: 0:21:16  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0193)  train/logits_fake: 0.0194 (0.0193, 0.0204)  train/total_loss: 22691.4863 (32112.7589, 22691.4863)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 12226.4111 (7515.2483, 13248.2422)  train/nll_loss: 22691.4727 (32112.7515, 22691.4727)  train/rec_loss: 0.0985 (0.1394, 0.0985)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0204)
2025-02-06 16:48:29,471 train INFO: [320/46609/10000]  lr: 3.2581e-05  eta: 0:21:10  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0189)  train/logits_fake: 0.0196 (0.0193, 0.0194)  train/total_loss: 21985.9844 (31381.0471, 21643.1484)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 12616.8711 (7946.4687, 14782.8867)  train/nll_loss: 21985.9727 (31381.0392, 21643.1328)  train/rec_loss: 0.0954 (0.1362, 0.0939)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0196 (-0.0193, -0.0194)
2025-02-06 16:48:31,997 train INFO: [340/46609/10000]  lr: 3.4561e-05  eta: 0:21:05  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0186)  train/logits_fake: 0.0196 (0.0193, 0.0183)  train/total_loss: 21643.1484 (30754.6133, 25980.6133)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 13165.9688 (8425.1872, 15364.1709)  train/nll_loss: 21643.1328 (30754.6049, 25980.5977)  train/rec_loss: 0.0939 (0.1335, 0.1128)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0197 (-0.0193, -0.0183)
2025-02-06 16:48:34,524 train INFO: [360/46609/10000]  lr: 3.6541e-05  eta: 0:21:00  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0194 (0.0192, 0.0176)  train/logits_fake: 0.0198 (0.0194, 0.0197)  train/total_loss: 21380.1660 (30269.8930, 26724.0469)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 13990.1797 (8770.3324, 15073.8672)  train/nll_loss: 21380.1523 (30269.8843, 26724.0312)  train/rec_loss: 0.0928 (0.1314, 0.1160)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0198 (-0.0194, -0.0197)
2025-02-06 16:48:37,052 train INFO: [380/46609/10000]  lr: 3.8521e-05  eta: 0:20:55  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0200)  train/logits_fake: 0.0198 (0.0193, 0.0210)  train/total_loss: 21643.1484 (29877.7107, 20651.8184)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 14877.7676 (9214.6752, 18992.5664)  train/nll_loss: 21643.1328 (29877.7015, 20651.7988)  train/rec_loss: 0.0939 (0.1297, 0.0896)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0198 (-0.0193, -0.0210)
2025-02-06 16:48:39,592 train INFO: [400/46609/10000]  lr: 4.0501000000000004e-05  eta: 0:20:51  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0167)  train/logits_fake: 0.0197 (0.0193, 0.0189)  train/total_loss: 20701.0586 (29388.0489, 21081.4805)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 15625.5664 (9673.6470, 20143.6562)  train/nll_loss: 20701.0430 (29388.0393, 21081.4609)  train/rec_loss: 0.0898 (0.1276, 0.0915)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0197 (-0.0193, -0.0189)
2025-02-06 16:48:42,128 train INFO: [420/46609/10000]  lr: 4.2481e-05  eta: 0:20:46  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0190)  train/logits_fake: 0.0198 (0.0193, 0.0188)  train/total_loss: 20613.2793 (28882.1414, 13076.8398)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 17157.3984 (10075.8310, 19613.9121)  train/nll_loss: 20613.2617 (28882.1314, 13076.8203)  train/rec_loss: 0.0895 (0.1254, 0.0568)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0198 (-0.0193, -0.0188)
2025-02-06 16:48:44,656 train INFO: [440/46609/10000]  lr: 4.4461e-05  eta: 0:20:42  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0203)  train/logits_fake: 0.0196 (0.0193, 0.0198)  train/total_loss: 20201.5312 (28420.2128, 14151.8604)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 17692.2773 (10477.8183, 18876.7578)  train/nll_loss: 20201.5117 (28420.2023, 14151.8418)  train/rec_loss: 0.0877 (0.1234, 0.0614)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0196 (-0.0193, -0.0198)
2025-02-06 16:48:47,191 train INFO: [460/46609/10000]  lr: 4.6441000000000005e-05  eta: 0:20:38  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0207)  train/logits_fake: 0.0195 (0.0194, 0.0194)  train/total_loss: 19773.5684 (28041.2616, 19930.8945)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 18460.3711 (10908.7458, 20810.1543)  train/nll_loss: 19773.5488 (28041.2507, 19930.8730)  train/rec_loss: 0.0858 (0.1217, 0.0865)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0196 (-0.0194, -0.0194)
2025-02-06 16:48:49,727 train INFO: [480/46609/10000]  lr: 4.8421e-05  eta: 0:20:34  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0210)  train/logits_fake: 0.0196 (0.0194, 0.0199)  train/total_loss: 18794.3379 (27650.8163, 18462.6152)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 19054.1758 (11298.4161, 20327.6914)  train/nll_loss: 18794.3203 (27650.8050, 18462.5957)  train/rec_loss: 0.0816 (0.1200, 0.0801)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0196 (-0.0194, -0.0199)
2025-02-06 16:48:52,267 train INFO: [500/46609/10000]  lr: 5.0401e-05  eta: 0:20:31  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0192)  train/logits_fake: 0.0196 (0.0194, 0.0191)  train/total_loss: 18350.3574 (27238.0282, 13516.8018)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 19516.7578 (11685.4422, 20163.1426)  train/nll_loss: 18350.3359 (27238.0166, 13516.7812)  train/rec_loss: 0.0796 (0.1182, 0.0587)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0196 (-0.0194, -0.0191)
2025-02-06 16:48:54,794 train INFO: [520/46609/10000]  lr: 5.2381000000000006e-05  eta: 0:20:27  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0193)  train/logits_fake: 0.0194 (0.0194, 0.0188)  train/total_loss: 18462.6152 (26939.4105, 20910.2832)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 20311.8340 (12052.7985, 20869.5488)  train/nll_loss: 18462.5957 (26939.3984, 20910.2617)  train/rec_loss: 0.0801 (0.1169, 0.0908)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0194, -0.0188)
2025-02-06 16:48:57,326 train INFO: [540/46609/10000]  lr: 5.4361000000000004e-05  eta: 0:20:23  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0187)  train/logits_fake: 0.0193 (0.0193, 0.0181)  train/total_loss: 18350.3574 (26623.0313, 15970.5439)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 20745.5840 (12373.1756, 22650.9336)  train/nll_loss: 18350.3359 (26623.0190, 15970.5215)  train/rec_loss: 0.0796 (0.1156, 0.0693)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0181)
2025-02-06 16:48:59,857 train INFO: [560/46609/10000]  lr: 5.6341e-05  eta: 0:20:20  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0180)  train/logits_fake: 0.0193 (0.0193, 0.0207)  train/total_loss: 18315.5684 (26322.9127, 19366.9707)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 20936.1367 (12703.1110, 22864.7109)  train/nll_loss: 18315.5469 (26322.9000, 19366.9473)  train/rec_loss: 0.0795 (0.1142, 0.0841)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0207)
2025-02-06 16:49:02,387 train INFO: [580/46609/10000]  lr: 5.8321000000000006e-05  eta: 0:20:16  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0195)  train/logits_fake: 0.0193 (0.0194, 0.0206)  train/total_loss: 18350.3574 (26054.5653, 19386.6816)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 21329.0625 (13049.1608, 22364.7148)  train/nll_loss: 18350.3359 (26054.5523, 19386.6602)  train/rec_loss: 0.0796 (0.1131, 0.0841)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0194, -0.0206)
2025-02-06 16:49:04,921 train INFO: [600/46609/10000]  lr: 6.0301000000000004e-05  eta: 0:20:13  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0184)  train/logits_fake: 0.0194 (0.0194, 0.0205)  train/total_loss: 18580.0410 (25850.1975, 23080.3027)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 21957.1211 (13474.4976, 28192.5586)  train/nll_loss: 18580.0156 (25850.1841, 23080.2754)  train/rec_loss: 0.0806 (0.1122, 0.1002)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0194, -0.0205)
2025-02-06 16:49:07,446 train INFO: [620/46609/10000]  lr: 6.228100000000001e-05  eta: 0:20:10  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0189)  train/logits_fake: 0.0196 (0.0194, 0.0197)  train/total_loss: 18684.4043 (25630.6155, 16719.1250)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 22786.1230 (13840.0857, 25936.5137)  train/nll_loss: 18684.3809 (25630.6017, 16719.0996)  train/rec_loss: 0.0811 (0.1112, 0.0726)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0196 (-0.0194, -0.0197)
2025-02-06 16:49:09,988 train INFO: [640/46609/10000]  lr: 6.4261e-05  eta: 0:20:06  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0175)  train/logits_fake: 0.0196 (0.0194, 0.0198)  train/total_loss: 18753.1934 (25473.4233, 19764.1387)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 24260.7559 (14422.1624, 60105.5859)  train/nll_loss: 18753.1699 (25473.4089, 19764.0781)  train/rec_loss: 0.0814 (0.1106, 0.0858)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0196 (-0.0194, -0.0198)
2025-02-06 16:49:12,522 train INFO: [660/46609/10000]  lr: 6.6241e-05  eta: 0:20:03  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0195)  train/logits_fake: 0.0195 (0.0194, 0.0197)  train/total_loss: 18753.1934 (25252.9690, 18694.4336)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 25934.0508 (14837.4685, 27239.5977)  train/nll_loss: 18753.1699 (25252.9542, 18694.4062)  train/rec_loss: 0.0814 (0.1096, 0.0811)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0194, -0.0197)
2025-02-06 16:49:15,052 train INFO: [680/46609/10000]  lr: 6.822100000000001e-05  eta: 0:20:00  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0187)  train/logits_fake: 0.0195 (0.0194, 0.0199)  train/total_loss: 18701.8477 (25014.1883, 22154.3691)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 26066.2852 (15151.5015, 24273.8438)  train/nll_loss: 18701.8242 (25014.1732, 22154.3457)  train/rec_loss: 0.0812 (0.1086, 0.0962)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0194, -0.0199)
2025-02-06 16:49:17,587 train INFO: [700/46609/10000]  lr: 7.0201e-05  eta: 0:19:57  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0190)  train/logits_fake: 0.0194 (0.0194, 0.0185)  train/total_loss: 17833.5410 (24778.0875, 19231.1016)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 25952.5508 (15442.1972, 23687.0117)  train/nll_loss: 17833.5156 (24778.0720, 19231.0781)  train/rec_loss: 0.0774 (0.1075, 0.0835)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0194, -0.0185)
2025-02-06 16:49:20,126 train INFO: [720/46609/10000]  lr: 7.2181e-05  eta: 0:19:54  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0213)  train/logits_fake: 0.0194 (0.0194, 0.0196)  train/total_loss: 17422.9062 (24557.8312, 17872.9375)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 26914.0762 (15857.4013, 30233.7578)  train/nll_loss: 17422.8809 (24557.8153, 17872.9082)  train/rec_loss: 0.0756 (0.1066, 0.0776)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0194, -0.0196)
2025-02-06 16:49:22,657 train INFO: [740/46609/10000]  lr: 7.416100000000001e-05  eta: 0:19:51  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0155)  train/logits_fake: 0.0194 (0.0194, 0.0197)  train/total_loss: 17274.9570 (24432.7922, 21130.7109)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 27466.3477 (16275.3303, 52531.0273)  train/nll_loss: 17274.9336 (24432.7759, 21130.6582)  train/rec_loss: 0.0750 (0.1060, 0.0917)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0194, -0.0197)
2025-02-06 16:49:25,190 train INFO: [760/46609/10000]  lr: 7.6141e-05  eta: 0:19:48  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0185)  train/logits_fake: 0.0195 (0.0194, 0.0188)  train/total_loss: 17274.9570 (24277.6397, 22253.3770)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 28435.8984 (16707.6146, 33663.4219)  train/nll_loss: 17274.9336 (24277.6231, 22253.3438)  train/rec_loss: 0.0750 (0.1054, 0.0966)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0194, -0.0188)
2025-02-06 16:49:27,722 train INFO: [780/46609/10000]  lr: 7.8121e-05  eta: 0:19:45  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0188)  train/logits_fake: 0.0193 (0.0194, 0.0181)  train/total_loss: 17274.9570 (24086.3980, 18200.2305)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 29964.8691 (17093.2819, 28276.6445)  train/nll_loss: 17274.9336 (24086.3809, 18200.2031)  train/rec_loss: 0.0750 (0.1045, 0.0790)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0194, -0.0181)
2025-02-06 16:49:30,262 train INFO: [800/46609/10000]  lr: 8.010100000000001e-05  eta: 0:19:42  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0160)  train/logits_fake: 0.0192 (0.0194, 0.0182)  train/total_loss: 17108.0566 (23879.5028, 17013.5176)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 31197.4590 (17486.8800, 33865.8711)  train/nll_loss: 17108.0273 (23879.4853, 17013.4844)  train/rec_loss: 0.0743 (0.1036, 0.0738)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0194, -0.0182)
2025-02-06 16:49:32,804 train INFO: [820/46609/10000]  lr: 8.2081e-05  eta: 0:19:39  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0200)  train/logits_fake: 0.0193 (0.0194, 0.0183)  train/total_loss: 17108.0566 (23718.3013, 14398.0146)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 32577.3320 (17900.5450, 37328.0312)  train/nll_loss: 17108.0273 (23718.2834, 14397.9775)  train/rec_loss: 0.0743 (0.1029, 0.0625)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0194, -0.0183)
2025-02-06 16:49:35,344 train INFO: [840/46609/10000]  lr: 8.406100000000001e-05  eta: 0:19:36  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0194)  train/logits_fake: 0.0193 (0.0194, 0.0188)  train/total_loss: 16816.2148 (23551.1279, 21591.5469)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 33962.8828 (19305.2163, 38544.8086)  train/nll_loss: 16816.1797 (23551.1086, 21591.5078)  train/rec_loss: 0.0730 (0.1022, 0.0937)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0194, -0.0188)
2025-02-06 16:49:37,875 train INFO: [860/46609/10000]  lr: 8.604100000000001e-05  eta: 0:19:33  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0199)  train/logits_fake: 0.0194 (0.0194, 0.0196)  train/total_loss: 16364.0850 (23356.9274, 16364.0850)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 34246.3438 (19688.8758, 36463.0391)  train/nll_loss: 16364.0488 (23356.9077, 16364.0488)  train/rec_loss: 0.0710 (0.1014, 0.0710)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0194, -0.0196)
2025-02-06 16:49:40,406 train INFO: [880/46609/10000]  lr: 8.8021e-05  eta: 0:19:30  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0201)  train/logits_fake: 0.0193 (0.0193, 0.0192)  train/total_loss: 16364.0850 (23227.5840, 13235.3477)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 35427.5234 (20040.0007, 31184.1367)  train/nll_loss: 16364.0488 (23227.5640, 13235.3164)  train/rec_loss: 0.0710 (0.1008, 0.0574)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0192)
2025-02-06 16:49:42,942 train INFO: [900/46609/10000]  lr: 9.000100000000001e-05  eta: 0:19:27  iter_time: 0.127  data: 0.001  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0186)  train/logits_fake: 0.0194 (0.0194, 0.0196)  train/total_loss: 16477.0605 (23097.6784, 16062.7207)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 36592.8047 (20425.3511, 31352.5898)  train/nll_loss: 16477.0234 (23097.6580, 16062.6895)  train/rec_loss: 0.0715 (0.1003, 0.0697)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0194, -0.0196)
2025-02-06 16:49:45,480 train INFO: [920/46609/10000]  lr: 9.198100000000001e-05  eta: 0:19:24  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0194)  train/logits_fake: 0.0192 (0.0194, 0.0181)  train/total_loss: 16747.1934 (22992.1448, 14734.5176)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 36755.2500 (20813.3575, 38273.5078)  train/nll_loss: 16747.1445 (22992.1240, 14734.4795)  train/rec_loss: 0.0727 (0.0998, 0.0640)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0194, -0.0181)
2025-02-06 16:49:48,015 train INFO: [940/46609/10000]  lr: 9.3961e-05  eta: 0:19:21  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0177)  train/logits_fake: 0.0193 (0.0194, 0.0176)  train/total_loss: 16521.1445 (22843.7378, 14378.4658)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 36725.3164 (21169.7610, 36362.0547)  train/nll_loss: 16521.1094 (22843.7166, 14378.4297)  train/rec_loss: 0.0717 (0.0991, 0.0624)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0194, -0.0176)
2025-02-06 16:49:50,555 train INFO: [960/46609/10000]  lr: 9.594100000000001e-05  eta: 0:19:19  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0183)  train/logits_fake: 0.0193 (0.0194, 0.0188)  train/total_loss: 16477.0605 (22664.8754, 13785.3457)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 37425.7461 (21563.6782, 37232.4414)  train/nll_loss: 16477.0234 (22664.8539, 13785.3086)  train/rec_loss: 0.0715 (0.0984, 0.0598)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0194, -0.0188)
2025-02-06 16:49:53,102 train INFO: [980/46609/10000]  lr: 9.792100000000001e-05  eta: 0:19:16  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0190)  train/logits_fake: 0.0194 (0.0194, 0.0188)  train/total_loss: 15660.9678 (22497.2344, 15027.1592)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 38330.6641 (21950.2129, 37790.9062)  train/nll_loss: 15660.9219 (22497.2125, 15027.1211)  train/rec_loss: 0.0680 (0.0976, 0.0652)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0194, -0.0188)
2025-02-06 16:49:55,632 train INFO: [1000/46609/10000]  lr: 9.9901e-05  eta: 0:19:13  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0190)  train/logits_fake: 0.0193 (0.0193, 0.0199)  train/total_loss: 15640.5332 (22373.0629, 17783.2402)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 38913.8906 (22365.3057, 36395.7656)  train/nll_loss: 15640.4941 (22373.0406, 17783.2031)  train/rec_loss: 0.0679 (0.0971, 0.0772)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0199)
2025-02-06 16:49:58,178 train INFO: [1020/46609/10000]  lr: 9.98985773520711e-05  eta: 0:19:10  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0202)  train/logits_fake: 0.0194 (0.0194, 0.0209)  train/total_loss: 15027.1592 (22220.5585, 14806.1436)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 39453.0977 (22718.8442, 45996.4023)  train/nll_loss: 15027.1211 (22220.5358, 14806.0977)  train/rec_loss: 0.0652 (0.0964, 0.0643)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0194, -0.0209)
2025-02-06 16:50:00,718 train INFO: [1040/46609/10000]  lr: 9.989455844775029e-05  eta: 0:19:08  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0180)  train/logits_fake: 0.0191 (0.0193, 0.0177)  train/total_loss: 14653.1689 (22063.3415, 16002.7598)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 41711.8750 (23144.3572, 49099.7812)  train/nll_loss: 14653.1309 (22063.3183, 16002.7109)  train/rec_loss: 0.0636 (0.0958, 0.0695)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0177)
2025-02-06 16:50:03,258 train INFO: [1060/46609/10000]  lr: 9.989046154267949e-05  eta: 0:19:05  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0212)  train/logits_fake: 0.0191 (0.0193, 0.0198)  train/total_loss: 14798.8955 (21929.3845, 15001.6299)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 43523.2070 (23588.7969, 48314.8594)  train/nll_loss: 14798.8516 (21929.3609, 15001.5820)  train/rec_loss: 0.0642 (0.0952, 0.0651)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0198)
2025-02-06 16:50:05,794 train INFO: [1080/46609/10000]  lr: 9.98862866433283e-05  eta: 0:19:02  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0174)  train/logits_fake: 0.0191 (0.0193, 0.0192)  train/total_loss: 14798.8955 (21792.5406, 13096.4365)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 44492.7969 (24026.5788, 43761.4375)  train/nll_loss: 14798.8516 (21792.5166, 13096.3926)  train/rec_loss: 0.0642 (0.0946, 0.0568)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0192)
2025-02-06 16:50:08,328 train INFO: [1100/46609/10000]  lr: 9.988203375628945e-05  eta: 0:18:59  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0182)  train/logits_fake: 0.0192 (0.0193, 0.0190)  train/total_loss: 14383.7812 (21672.2122, 13040.5742)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 45241.9062 (24504.5237, 62315.0938)  train/nll_loss: 14383.7354 (21672.1877, 13040.5117)  train/rec_loss: 0.0624 (0.0941, 0.0566)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0190)
2025-02-06 16:50:10,864 train INFO: [1120/46609/10000]  lr: 9.987770288827884e-05  eta: 0:18:56  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0190)  train/logits_fake: 0.0193 (0.0193, 0.0198)  train/total_loss: 14081.2979 (21533.5195, 12598.0000)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 47828.5469 (24973.9188, 45208.7695)  train/nll_loss: 14081.2471 (21533.4945, 12597.9551)  train/rec_loss: 0.0611 (0.0935, 0.0547)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0198)
2025-02-06 16:50:13,401 train INFO: [1140/46609/10000]  lr: 9.987329404613549e-05  eta: 0:18:54  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0200)  train/logits_fake: 0.0195 (0.0193, 0.0213)  train/total_loss: 14172.2832 (21421.2900, 16872.6406)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 49568.5820 (25500.9371, 51509.4570)  train/nll_loss: 14172.2227 (21421.2645, 16872.5898)  train/rec_loss: 0.0615 (0.0930, 0.0732)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0213)
2025-02-06 16:50:15,936 train INFO: [1160/46609/10000]  lr: 9.986880723682156e-05  eta: 0:18:51  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0214)  train/logits_fake: 0.0194 (0.0193, 0.0201)  train/total_loss: 14172.2832 (21294.5114, 15764.8438)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 50806.5625 (26014.0347, 48455.6016)  train/nll_loss: 14172.2227 (21294.4854, 15764.7949)  train/rec_loss: 0.0615 (0.0924, 0.0684)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0201)
2025-02-06 16:50:18,472 train INFO: [1180/46609/10000]  lr: 9.986424246742235e-05  eta: 0:18:48  iter_time: 0.127  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0190)  train/logits_fake: 0.0192 (0.0193, 0.0188)  train/total_loss: 14081.2979 (21175.7313, 8477.1982)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 52413.8438 (26513.7264, 38072.6250)  train/nll_loss: 14081.2471 (21175.7048, 8477.1602)  train/rec_loss: 0.0611 (0.0919, 0.0368)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0188)
2025-02-06 16:50:21,006 train INFO: [1200/46609/10000]  lr: 9.985959974514624e-05  eta: 0:18:45  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0187)  train/logits_fake: 0.0192 (0.0193, 0.0203)  train/total_loss: 14021.2549 (21062.1920, 12063.1035)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 52413.8438 (26912.8885, 53166.3984)  train/nll_loss: 14021.2031 (21062.1652, 12063.0508)  train/rec_loss: 0.0609 (0.0914, 0.0524)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0203)
2025-02-06 16:50:23,535 train INFO: [1220/46609/10000]  lr: 9.985487907732471e-05  eta: 0:18:43  iter_time: 0.126  data: 0.000  memory: 7892  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0193)  train/logits_fake: 0.0192 (0.0193, 0.0195)  train/total_loss: 13989.6416 (20942.4820, 14722.7725)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 54885.5703 (27809.2135, 51541.2578)  train/nll_loss: 13989.5996 (20942.4543, 14722.7207)  train/rec_loss: 0.0607 (0.0909, 0.0639)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0195)
2025-02-06 16:50:26,067 train INFO: [1240/46609/10000]  lr: 9.985008047141237e-05  eta: 0:18:40  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0182)  train/logits_fake: 0.0192 (0.0193, 0.0195)  train/total_loss: 12873.7686 (20796.2994, 10360.6748)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 54991.9258 (28239.5541, 49323.1641)  train/nll_loss: 12873.7168 (20796.2712, 10360.6250)  train/rec_loss: 0.0559 (0.0903, 0.0450)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0195)
2025-02-06 16:50:28,597 train INFO: [1260/46609/10000]  lr: 9.984520393498686e-05  eta: 0:18:37  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0226)  train/logits_fake: 0.0192 (0.0193, 0.0210)  train/total_loss: 12873.7686 (20683.9551, 16353.9570)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 54642.3555 (28664.9880, 46458.2812)  train/nll_loss: 12873.7168 (20683.9265, 16353.9102)  train/rec_loss: 0.0559 (0.0898, 0.0710)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0210)
2025-02-06 16:50:31,129 train INFO: [1280/46609/10000]  lr: 9.98402494757489e-05  eta: 0:18:34  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0196)  train/logits_fake: 0.0192 (0.0193, 0.0202)  train/total_loss: 12811.8486 (20564.7717, 14436.3350)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 54352.2578 (29070.0941, 63199.0938)  train/nll_loss: 12811.8027 (20564.7427, 14436.2715)  train/rec_loss: 0.0556 (0.0893, 0.0627)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0202)
2025-02-06 16:50:33,667 train INFO: [1300/46609/10000]  lr: 9.983521710152225e-05  eta: 0:18:32  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0195)  train/logits_fake: 0.0193 (0.0193, 0.0195)  train/total_loss: 12811.8486 (20455.9368, 13102.9766)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 55088.1641 (29459.2800, 57752.2422)  train/nll_loss: 12811.8027 (20455.9073, 13102.9189)  train/rec_loss: 0.0556 (0.0888, 0.0569)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0195)
2025-02-06 16:50:36,198 train INFO: [1320/46609/10000]  lr: 9.983010682025372e-05  eta: 0:18:29  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0206)  train/logits_fake: 0.0194 (0.0193, 0.0189)  train/total_loss: 12793.5127 (20349.6347, 16431.9648)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 54493.6094 (29870.0081, 54957.9844)  train/nll_loss: 12793.4482 (20349.6049, 16431.9102)  train/rec_loss: 0.0555 (0.0883, 0.0713)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0189)
2025-02-06 16:50:38,728 train INFO: [1340/46609/10000]  lr: 9.982491864001312e-05  eta: 0:18:26  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0181)  train/logits_fake: 0.0194 (0.0193, 0.0191)  train/total_loss: 13102.9766 (20241.3565, 16131.0273)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 54352.2578 (30235.9369, 56004.8906)  train/nll_loss: 13102.9189 (20241.3263, 16130.9717)  train/rec_loss: 0.0569 (0.0879, 0.0700)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0191)
2025-02-06 16:50:41,254 train INFO: [1360/46609/10000]  lr: 9.981965256899335e-05  eta: 0:18:24  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0194 (0.0191, 0.0182)  train/logits_fake: 0.0195 (0.0193, 0.0181)  train/total_loss: 13102.9766 (20163.3783, 18033.2402)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 54630.7812 (30629.8632, 55412.2344)  train/nll_loss: 13102.9189 (20163.3477, 18033.1855)  train/rec_loss: 0.0569 (0.0875, 0.0783)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0181)
2025-02-06 16:50:43,782 train INFO: [1380/46609/10000]  lr: 9.981430861551019e-05  eta: 0:18:21  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0195 (0.0191, 0.0194)  train/logits_fake: 0.0195 (0.0193, 0.0193)  train/total_loss: 13102.9766 (20064.8322, 12769.0791)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 55507.5391 (31161.7005, 68413.7812)  train/nll_loss: 13102.9189 (20064.8010, 12769.0107)  train/rec_loss: 0.0569 (0.0871, 0.0554)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0193)
2025-02-06 16:50:46,312 train INFO: [1400/46609/10000]  lr: 9.980888678800252e-05  eta: 0:18:18  iter_time: 0.126  data: 0.001  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0183)  train/logits_fake: 0.0193 (0.0193, 0.0179)  train/total_loss: 13174.1904 (19974.7057, 10750.6367)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 58310.3750 (31630.6829, 73742.3438)  train/nll_loss: 13174.1221 (19974.6741, 10750.5625)  train/rec_loss: 0.0572 (0.0867, 0.0467)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0179)
2025-02-06 16:50:48,840 train INFO: [1420/46609/10000]  lr: 9.980338709503211e-05  eta: 0:18:15  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0214)  train/logits_fake: 0.0192 (0.0193, 0.0199)  train/total_loss: 13003.8633 (19874.2304, 11881.9912)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 59523.8281 (32057.3250, 60047.3984)  train/nll_loss: 13003.8086 (19874.1983, 11881.9316)  train/rec_loss: 0.0564 (0.0863, 0.0516)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0199)
2025-02-06 16:50:51,371 train INFO: [1440/46609/10000]  lr: 9.979780954528376e-05  eta: 0:18:13  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0189)  train/logits_fake: 0.0193 (0.0193, 0.0186)  train/total_loss: 12613.4922 (19765.5302, 12270.5898)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 61965.8281 (32475.2873, 67235.5469)  train/nll_loss: 12613.4297 (19765.4978, 12270.5225)  train/rec_loss: 0.0547 (0.0858, 0.0533)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0186)
2025-02-06 16:50:53,900 train INFO: [1460/46609/10000]  lr: 9.979215414756515e-05  eta: 0:18:10  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0186)  train/logits_fake: 0.0192 (0.0193, 0.0182)  train/total_loss: 12216.2744 (19659.2179, 11684.9004)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 62801.5430 (32884.1046, 69129.8750)  train/nll_loss: 12216.2090 (19659.1850, 11684.8311)  train/rec_loss: 0.0530 (0.0853, 0.0507)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0182)
2025-02-06 16:50:56,428 train INFO: [1480/46609/10000]  lr: 9.978642091080696e-05  eta: 0:18:07  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0188 (0.0191, 0.0180)  train/logits_fake: 0.0192 (0.0193, 0.0166)  train/total_loss: 12159.0742 (19552.5469, 14362.2393)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 62305.6641 (33273.3753, 60845.1445)  train/nll_loss: 12159.0059 (19552.5137, 14362.1787)  train/rec_loss: 0.0528 (0.0849, 0.0623)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0166)
2025-02-06 16:50:58,952 train INFO: [1500/46609/10000]  lr: 9.978060984406272e-05  eta: 0:18:05  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0183)  train/logits_fake: 0.0193 (0.0193, 0.0200)  train/total_loss: 11836.0723 (19453.2419, 11836.0723)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 60845.1445 (33636.2972, 62698.2383)  train/nll_loss: 11836.0098 (19453.2083, 11836.0098)  train/rec_loss: 0.0514 (0.0844, 0.0514)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0200)
2025-02-06 16:51:01,476 train INFO: [1520/46609/10000]  lr: 9.977472095650893e-05  eta: 0:18:02  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0201)  train/logits_fake: 0.0193 (0.0193, 0.0197)  train/total_loss: 11836.0723 (19369.1991, 13136.9316)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 61351.9336 (33994.2842, 64496.6211)  train/nll_loss: 11836.0098 (19369.1651, 13136.8672)  train/rec_loss: 0.0514 (0.0841, 0.0570)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0197)
2025-02-06 16:51:04,002 train INFO: [1540/46609/10000]  lr: 9.976875425744491e-05  eta: 0:17:59  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0188 (0.0191, 0.0173)  train/logits_fake: 0.0192 (0.0193, 0.0177)  train/total_loss: 11861.5586 (19278.2178, 9485.0195)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 60845.1445 (34371.1589, 46777.0469)  train/nll_loss: 11861.4863 (19278.1834, 9484.9727)  train/rec_loss: 0.0515 (0.0837, 0.0412)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0177)
2025-02-06 16:51:06,526 train INFO: [1560/46609/10000]  lr: 9.976270975629292e-05  eta: 0:17:56  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0192)  train/logits_fake: 0.0192 (0.0193, 0.0194)  train/total_loss: 11939.2637 (19180.4947, 11247.7383)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 60845.1445 (34730.1891, 58535.4375)  train/nll_loss: 11939.2070 (19180.4600, 11247.6797)  train/rec_loss: 0.0518 (0.0832, 0.0488)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0194)
2025-02-06 16:51:09,052 train INFO: [1580/46609/10000]  lr: 9.975658746259806e-05  eta: 0:17:54  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0184)  train/logits_fake: 0.0192 (0.0193, 0.0172)  train/total_loss: 12056.3887 (19107.8793, 12095.2588)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 61936.5312 (35180.6540, 65887.6641)  train/nll_loss: 12056.3242 (19107.8441, 12095.1934)  train/rec_loss: 0.0523 (0.0829, 0.0525)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0172)
2025-02-06 16:51:11,581 train INFO: [1600/46609/10000]  lr: 9.975038738602823e-05  eta: 0:17:51  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0206)  train/logits_fake: 0.0191 (0.0193, 0.0211)  train/total_loss: 12482.7500 (19053.3349, 11537.8594)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 62506.1562 (35540.9630, 52471.8750)  train/nll_loss: 12482.6934 (19053.2994, 11537.8066)  train/rec_loss: 0.0542 (0.0827, 0.0501)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0211)
2025-02-06 16:51:14,106 train INFO: [1620/46609/10000]  lr: 9.974410953637422e-05  eta: 0:17:48  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0188 (0.0191, 0.0189)  train/logits_fake: 0.0190 (0.0193, 0.0188)  train/total_loss: 12487.4746 (18991.2650, 9964.4834)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 63360.6719 (35865.9208, 72892.5938)  train/nll_loss: 12487.4033 (18991.2291, 9964.4102)  train/rec_loss: 0.0542 (0.0824, 0.0432)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0193, -0.0188)
2025-02-06 16:51:16,633 train INFO: [1640/46609/10000]  lr: 9.97377539235496e-05  eta: 0:17:46  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0192)  train/logits_fake: 0.0191 (0.0193, 0.0203)  train/total_loss: 12484.2881 (18908.4293, 11370.7529)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 62648.1836 (36174.8471, 47869.5078)  train/nll_loss: 12484.2236 (18908.3931, 11370.7051)  train/rec_loss: 0.0542 (0.0821, 0.0494)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0203)
2025-02-06 16:51:19,162 train INFO: [1660/46609/10000]  lr: 9.973132055759078e-05  eta: 0:17:43  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0197)  train/logits_fake: 0.0191 (0.0193, 0.0188)  train/total_loss: 12895.8428 (18831.3572, 11417.1367)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 63305.5586 (36507.1549, 56835.8867)  train/nll_loss: 12895.7812 (18831.3207, 11417.0801)  train/rec_loss: 0.0560 (0.0817, 0.0496)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0188)
2025-02-06 16:51:21,691 train INFO: [1680/46609/10000]  lr: 9.97248094486569e-05  eta: 0:17:40  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0188)  train/logits_fake: 0.0192 (0.0193, 0.0197)  train/total_loss: 12406.1260 (18753.0034, 15156.9209)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 62159.4883 (36813.9864, 86533.3125)  train/nll_loss: 12406.0664 (18752.9666, 15156.8340)  train/rec_loss: 0.0538 (0.0814, 0.0658)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0197)
2025-02-06 16:51:24,216 train INFO: [1700/46609/10000]  lr: 9.971822060702989e-05  eta: 0:17:38  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0186)  train/logits_fake: 0.0193 (0.0193, 0.0192)  train/total_loss: 12106.4160 (18681.3312, 14542.3652)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 62648.1836 (37156.6372, 87161.3203)  train/nll_loss: 12106.3477 (18681.2940, 14542.2783)  train/rec_loss: 0.0525 (0.0811, 0.0631)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0192)
2025-02-06 16:51:26,745 train INFO: [1720/46609/10000]  lr: 9.971155404311443e-05  eta: 0:17:35  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0180)  train/logits_fake: 0.0195 (0.0193, 0.0189)  train/total_loss: 11988.4248 (18611.5554, 10255.6689)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 63521.7812 (37521.1157, 70181.4531)  train/nll_loss: 11988.3770 (18611.5179, 10255.5986)  train/rec_loss: 0.0520 (0.0808, 0.0445)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0189)
2025-02-06 16:51:29,272 train INFO: [1740/46609/10000]  lr: 9.970480976743792e-05  eta: 0:17:32  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0169)  train/logits_fake: 0.0194 (0.0193, 0.0181)  train/total_loss: 11971.6230 (18528.7862, 11757.2783)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 65193.3867 (37880.1238, 56005.3086)  train/nll_loss: 11971.5566 (18528.7483, 11757.2227)  train/rec_loss: 0.0520 (0.0804, 0.0510)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0181)
2025-02-06 16:51:31,797 train INFO: [1760/46609/10000]  lr: 9.969798779065054e-05  eta: 0:17:30  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0191)  train/logits_fake: 0.0194 (0.0193, 0.0196)  train/total_loss: 12005.3896 (18453.9027, 13248.8662)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 65486.5234 (38200.7005, 69703.2734)  train/nll_loss: 12005.3164 (18453.8646, 13248.7969)  train/rec_loss: 0.0521 (0.0801, 0.0575)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0196)
2025-02-06 16:51:34,322 train INFO: [1780/46609/10000]  lr: 9.969108812352508e-05  eta: 0:17:27  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0187)  train/logits_fake: 0.0191 (0.0193, 0.0176)  train/total_loss: 12203.5820 (18394.0267, 15482.7100)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 66329.9844 (38550.2464, 73358.0234)  train/nll_loss: 12203.5195 (18393.9881, 15482.6367)  train/rec_loss: 0.0530 (0.0798, 0.0672)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0176)
2025-02-06 16:51:36,848 train INFO: [1800/46609/10000]  lr: 9.968411077695707e-05  eta: 0:17:24  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0179)  train/logits_fake: 0.0190 (0.0193, 0.0181)  train/total_loss: 12136.1836 (18318.4330, 10809.7881)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 68615.0078 (38877.8329, 77273.8281)  train/nll_loss: 12136.1113 (18318.3942, 10809.7109)  train/rec_loss: 0.0527 (0.0795, 0.0469)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0193, -0.0181)
2025-02-06 16:51:39,371 train INFO: [1820/46609/10000]  lr: 9.96770557619647e-05  eta: 0:17:22  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0193)  train/logits_fake: 0.0193 (0.0193, 0.0189)  train/total_loss: 12005.3896 (18258.2161, 9309.9619)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 68615.0078 (39216.3736, 67564.7188)  train/nll_loss: 12005.3164 (18258.1769, 9309.8945)  train/rec_loss: 0.0521 (0.0792, 0.0404)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0189)
2025-02-06 16:51:41,897 train INFO: [1840/46609/10000]  lr: 9.966992308968878e-05  eta: 0:17:19  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0202)  train/logits_fake: 0.0192 (0.0193, 0.0211)  train/total_loss: 11757.2490 (18183.8430, 14997.5947)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 67833.9531 (39501.9578, 65893.9688)  train/nll_loss: 11757.1855 (18183.8036, 14997.5293)  train/rec_loss: 0.0510 (0.0789, 0.0651)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0211)
2025-02-06 16:51:44,424 train INFO: [1860/46609/10000]  lr: 9.966271277139278e-05  eta: 0:17:17  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0196)  train/logits_fake: 0.0191 (0.0193, 0.0187)  train/total_loss: 11757.2490 (18118.6221, 9191.1309)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 68438.3750 (39851.4950, 57748.0977)  train/nll_loss: 11757.1855 (18118.5822, 9191.0732)  train/rec_loss: 0.0510 (0.0786, 0.0399)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0187)
2025-02-06 16:51:46,953 train INFO: [1880/46609/10000]  lr: 9.965542481846279e-05  eta: 0:17:14  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0196)  train/logits_fake: 0.0192 (0.0193, 0.0200)  train/total_loss: 11418.4863 (18055.9959, 12588.6396)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 67634.9531 (40128.2448, 59903.3945)  train/nll_loss: 11418.4248 (18055.9558, 12588.5801)  train/rec_loss: 0.0496 (0.0784, 0.0546)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0200)
2025-02-06 16:51:49,480 train INFO: [1900/46609/10000]  lr: 9.964805924240748e-05  eta: 0:17:11  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0187)  train/logits_fake: 0.0192 (0.0193, 0.0193)  train/total_loss: 11418.4863 (17994.2595, 12074.8799)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 66121.4531 (40421.4373, 65757.3438)  train/nll_loss: 11418.4248 (17994.2191, 12074.8145)  train/rec_loss: 0.0496 (0.0781, 0.0524)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0193)
2025-02-06 16:51:52,014 train INFO: [1920/46609/10000]  lr: 9.964061605485808e-05  eta: 0:17:09  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0210)  train/logits_fake: 0.0192 (0.0193, 0.0210)  train/total_loss: 11230.4180 (17914.6115, 9737.6406)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 66121.4531 (40713.9206, 56900.9727)  train/nll_loss: 11230.3281 (17914.5708, 9737.5840)  train/rec_loss: 0.0487 (0.0778, 0.0423)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0210)
2025-02-06 16:51:54,547 train INFO: [1940/46609/10000]  lr: 9.963309526756842e-05  eta: 0:17:06  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0200)  train/logits_fake: 0.0193 (0.0193, 0.0205)  train/total_loss: 11217.9873 (17842.3827, 11215.1924)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 68435.3125 (41010.7960, 84924.4688)  train/nll_loss: 11217.9229 (17842.3417, 11215.1074)  train/rec_loss: 0.0487 (0.0774, 0.0487)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0205)
2025-02-06 16:51:57,081 train INFO: [1960/46609/10000]  lr: 9.962549689241485e-05  eta: 0:17:03  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0209)  train/logits_fake: 0.0193 (0.0193, 0.0209)  train/total_loss: 11005.6748 (17766.2450, 10197.8184)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 68435.3125 (41329.8728, 64235.7969)  train/nll_loss: 11005.5928 (17766.2037, 10197.7539)  train/rec_loss: 0.0478 (0.0771, 0.0443)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0209)
2025-02-06 16:51:59,613 train INFO: [1980/46609/10000]  lr: 9.961782094139623e-05  eta: 0:17:01  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0203)  train/logits_fake: 0.0194 (0.0193, 0.0202)  train/total_loss: 10915.8428 (17702.9440, 10587.8984)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 69891.8516 (41658.4438, 65815.7188)  train/nll_loss: 10915.7666 (17702.9023, 10587.8330)  train/rec_loss: 0.0474 (0.0768, 0.0460)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0202)
2025-02-06 16:52:02,147 train INFO: [2000/46609/10000]  lr: 9.961006742663394e-05  eta: 0:16:58  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0176)  train/logits_fake: 0.0195 (0.0193, 0.0175)  train/total_loss: 10899.0293 (17637.0580, 9683.0664)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 73196.5000 (42018.7777, 80337.4609)  train/nll_loss: 10898.9551 (17637.0160, 9682.9863)  train/rec_loss: 0.0473 (0.0765, 0.0420)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0175)
2025-02-06 16:52:04,682 train INFO: [2020/46609/10000]  lr: 9.960223636037184e-05  eta: 0:16:56  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0190)  train/logits_fake: 0.0194 (0.0193, 0.0193)  train/total_loss: 10913.2920 (17572.2081, 10699.2109)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 73938.2031 (42360.4628, 56397.8711)  train/nll_loss: 10913.2090 (17572.1658, 10699.1543)  train/rec_loss: 0.0474 (0.0763, 0.0464)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0193)
2025-02-06 16:52:07,215 train INFO: [2040/46609/10000]  lr: 9.959432775497624e-05  eta: 0:16:53  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0191)  train/logits_fake: 0.0193 (0.0193, 0.0192)  train/total_loss: 10800.7695 (17511.1635, 9336.8271)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 74253.8438 (42648.6144, 71521.1953)  train/nll_loss: 10800.6973 (17511.1209, 9336.7559)  train/rec_loss: 0.0469 (0.0760, 0.0405)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0192)
2025-02-06 16:52:09,752 train INFO: [2060/46609/10000]  lr: 9.958634162293593e-05  eta: 0:16:50  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0188)  train/logits_fake: 0.0193 (0.0193, 0.0193)  train/total_loss: 10710.2705 (17444.5728, 9273.4033)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 74829.9922 (42929.2738, 82222.0000)  train/nll_loss: 10710.1865 (17444.5299, 9273.3213)  train/rec_loss: 0.0465 (0.0757, 0.0402)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0193)
2025-02-06 16:52:12,290 train INFO: [2080/46609/10000]  lr: 9.95782779768621e-05  eta: 0:16:48  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0186)  train/logits_fake: 0.0193 (0.0193, 0.0199)  train/total_loss: 10526.8271 (17379.4061, 11224.8330)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 75477.1719 (43240.6851, 87198.9844)  train/nll_loss: 10526.7520 (17379.3629, 11224.7461)  train/rec_loss: 0.0457 (0.0754, 0.0487)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0199)
2025-02-06 16:52:14,821 train INFO: [2100/46609/10000]  lr: 9.95701368294883e-05  eta: 0:16:45  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0192)  train/logits_fake: 0.0194 (0.0193, 0.0194)  train/total_loss: 10275.9902 (17311.1656, 9387.1709)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 74253.8438 (43537.9130, 65143.7109)  train/nll_loss: 10275.9121 (17311.1221, 9387.1055)  train/rec_loss: 0.0446 (0.0751, 0.0407)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0194)
2025-02-06 16:52:17,350 train INFO: [2120/46609/10000]  lr: 9.956191819367058e-05  eta: 0:16:43  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0181)  train/logits_fake: 0.0195 (0.0193, 0.0196)  train/total_loss: 10275.9902 (17254.7591, 15729.4590)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 73836.1953 (43854.5515, 70114.2656)  train/nll_loss: 10275.9121 (17254.7152, 15729.3887)  train/rec_loss: 0.0446 (0.0749, 0.0683)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0196)
2025-02-06 16:52:19,883 train INFO: [2140/46609/10000]  lr: 9.955362208238724e-05  eta: 0:16:40  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0200)  train/logits_fake: 0.0194 (0.0193, 0.0190)  train/total_loss: 10205.9863 (17183.8518, 10647.7070)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 75298.5000 (44123.5728, 64143.2969)  train/nll_loss: 10205.9199 (17183.8077, 10647.6426)  train/rec_loss: 0.0443 (0.0746, 0.0462)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0190)
2025-02-06 16:52:22,411 train INFO: [2160/46609/10000]  lr: 9.954524850873901e-05  eta: 0:16:37  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0195)  train/logits_fake: 0.0195 (0.0193, 0.0202)  train/total_loss: 9990.3320 (17114.8237, 11981.1396)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 74454.7969 (44387.1098, 82254.7188)  train/nll_loss: 9990.2471 (17114.7793, 11981.0576)  train/rec_loss: 0.0434 (0.0743, 0.0520)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0202)
2025-02-06 16:52:24,945 train INFO: [2180/46609/10000]  lr: 9.953679748594889e-05  eta: 0:16:35  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0191)  train/logits_fake: 0.0193 (0.0193, 0.0187)  train/total_loss: 9942.4824 (17053.7104, 7369.8081)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 74453.0547 (44669.7467, 78943.4062)  train/nll_loss: 9942.4092 (17053.6658, 7369.7290)  train/rec_loss: 0.0432 (0.0740, 0.0320)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0187)
2025-02-06 16:52:27,484 train INFO: [2200/46609/10000]  lr: 9.952826902736218e-05  eta: 0:16:32  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0201)  train/logits_fake: 0.0193 (0.0193, 0.0210)  train/total_loss: 9942.4824 (16992.7307, 11541.7988)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 74453.0547 (44948.7995, 65167.6562)  train/nll_loss: 9942.4092 (16992.6857, 11541.7334)  train/rec_loss: 0.0432 (0.0738, 0.0501)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0210)
2025-02-06 16:52:30,020 train INFO: [2220/46609/10000]  lr: 9.951966314644651e-05  eta: 0:16:30  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0230)  train/logits_fake: 0.0193 (0.0193, 0.0212)  train/total_loss: 9956.2217 (16940.8773, 10527.6270)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 74453.0547 (45240.5442, 70195.8906)  train/nll_loss: 9956.1387 (16940.8320, 10527.5566)  train/rec_loss: 0.0432 (0.0735, 0.0457)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0212)
2025-02-06 16:52:32,548 train INFO: [2240/46609/10000]  lr: 9.951097985679171e-05  eta: 0:16:27  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0194)  train/logits_fake: 0.0194 (0.0193, 0.0196)  train/total_loss: 10066.4141 (16885.3847, 8743.4336)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 75859.7812 (45546.9072, 73863.5469)  train/nll_loss: 10066.3340 (16885.3392, 8743.3594)  train/rec_loss: 0.0437 (0.0733, 0.0379)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0196)
2025-02-06 16:52:35,078 train INFO: [2260/46609/10000]  lr: 9.95022191721099e-05  eta: 0:16:25  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0188)  train/logits_fake: 0.0194 (0.0193, 0.0193)  train/total_loss: 10415.5127 (16828.7491, 9205.5049)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 76393.0938 (45825.5949, 81393.3906)  train/nll_loss: 10415.4355 (16828.7033, 9205.4238)  train/rec_loss: 0.0452 (0.0730, 0.0400)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0193)
2025-02-06 16:52:37,605 train INFO: [2280/46609/10000]  lr: 9.949338110623539e-05  eta: 0:16:22  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0197)  train/logits_fake: 0.0194 (0.0193, 0.0202)  train/total_loss: 10410.7734 (16771.5003, 13299.7998)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 76657.3281 (46107.6685, 78085.3672)  train/nll_loss: 10410.6895 (16771.4543, 13299.7217)  train/rec_loss: 0.0452 (0.0728, 0.0577)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0202)
2025-02-06 16:52:40,133 train INFO: [2300/46609/10000]  lr: 9.94844656731247e-05  eta: 0:16:19  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0196)  train/logits_fake: 0.0194 (0.0193, 0.0194)  train/total_loss: 10602.6611 (16732.2679, 10659.8848)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 77195.9453 (46374.4685, 46574.8672)  train/nll_loss: 10602.5938 (16732.2215, 10659.8379)  train/rec_loss: 0.0460 (0.0726, 0.0463)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0194)
2025-02-06 16:52:42,661 train INFO: [2320/46609/10000]  lr: 9.947547288685651e-05  eta: 0:16:17  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0189)  train/logits_fake: 0.0194 (0.0193, 0.0195)  train/total_loss: 10629.2100 (16683.2369, 7609.2539)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 77864.0938 (46672.2550, 69168.6562)  train/nll_loss: 10629.1387 (16683.1903, 7609.1846)  train/rec_loss: 0.0461 (0.0724, 0.0330)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0195)
2025-02-06 16:52:45,188 train INFO: [2340/46609/10000]  lr: 9.946640276163165e-05  eta: 0:16:14  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0229)  train/logits_fake: 0.0194 (0.0193, 0.0208)  train/total_loss: 10785.9082 (16640.2655, 19098.8008)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 78397.6875 (46940.7213, 79415.6562)  train/nll_loss: 10785.8359 (16640.2186, 19098.7207)  train/rec_loss: 0.0468 (0.0722, 0.0829)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0208)
2025-02-06 16:52:47,718 train INFO: [2360/46609/10000]  lr: 9.94572553117731e-05  eta: 0:16:11  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0210)  train/logits_fake: 0.0194 (0.0193, 0.0210)  train/total_loss: 11202.4463 (16605.5812, 11204.0742)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 78666.3672 (47193.7200, 62080.8828)  train/nll_loss: 11202.3574 (16605.5340, 11204.0117)  train/rec_loss: 0.0486 (0.0721, 0.0486)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0210)
2025-02-06 16:52:50,244 train INFO: [2380/46609/10000]  lr: 9.944803055172592e-05  eta: 0:16:09  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0174)  train/logits_fake: 0.0194 (0.0193, 0.0183)  train/total_loss: 11779.7100 (16568.9572, 11204.7285)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 80270.0625 (47519.8805, 96762.8047)  train/nll_loss: 11779.6387 (16568.9097, 11204.6318)  train/rec_loss: 0.0511 (0.0719, 0.0486)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0183)
2025-02-06 16:52:52,762 train INFO: [2400/46609/10000]  lr: 9.943872849605728e-05  eta: 0:16:06  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0192)  train/logits_fake: 0.0195 (0.0193, 0.0189)  train/total_loss: 11562.3311 (16525.1843, 7313.8833)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 80970.7109 (47801.9013, 64159.0234)  train/nll_loss: 11562.2451 (16525.1365, 7313.8193)  train/rec_loss: 0.0502 (0.0717, 0.0317)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0189)
2025-02-06 16:52:55,286 train INFO: [2420/46609/10000]  lr: 9.942934915945637e-05  eta: 0:16:04  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0209)  train/logits_fake: 0.0195 (0.0193, 0.0210)  train/total_loss: 11445.5674 (16475.6868, 10629.2520)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 80970.7109 (48059.8698, 75275.6719)  train/nll_loss: 11445.4795 (16475.6388, 10629.1768)  train/rec_loss: 0.0497 (0.0715, 0.0461)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0210)
2025-02-06 16:52:57,811 train INFO: [2440/46609/10000]  lr: 9.941989255673447e-05  eta: 0:16:01  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0197)  train/logits_fake: 0.0193 (0.0193, 0.0198)  train/total_loss: 11380.5557 (16428.1780, 10442.5918)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 81719.6875 (48293.4258, 81604.1953)  train/nll_loss: 11380.4873 (16428.1297, 10442.5098)  train/rec_loss: 0.0494 (0.0713, 0.0453)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0198)
2025-02-06 16:53:00,335 train INFO: [2460/46609/10000]  lr: 9.941035870282483e-05  eta: 0:15:58  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0195)  train/logits_fake: 0.0192 (0.0193, 0.0186)  train/total_loss: 11053.4160 (16370.4923, 8428.2197)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 81604.1953 (48551.4070, 80466.6094)  train/nll_loss: 11053.3535 (16370.4438, 8428.1396)  train/rec_loss: 0.0480 (0.0711, 0.0366)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0186)
2025-02-06 16:53:02,852 train INFO: [2480/46609/10000]  lr: 9.940074761278272e-05  eta: 0:15:56  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0204)  train/logits_fake: 0.0193 (0.0193, 0.0204)  train/total_loss: 10220.2246 (16317.6864, 10296.3193)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 80050.3906 (48821.8081, 65807.7500)  train/nll_loss: 10220.1387 (16317.6376, 10296.2539)  train/rec_loss: 0.0444 (0.0708, 0.0447)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0204)
2025-02-06 16:53:05,374 train INFO: [2500/46609/10000]  lr: 9.939105930178535e-05  eta: 0:15:53  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0190)  train/logits_fake: 0.0192 (0.0193, 0.0175)  train/total_loss: 9951.6562 (16272.6344, 11624.5518)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 80466.6094 (49107.1854, 106819.3125)  train/nll_loss: 9951.5703 (16272.5853, 11624.4453)  train/rec_loss: 0.0432 (0.0706, 0.0505)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0175)
2025-02-06 16:53:07,896 train INFO: [2520/46609/10000]  lr: 9.93812937851319e-05  eta: 0:15:51  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0185)  train/logits_fake: 0.0192 (0.0193, 0.0186)  train/total_loss: 9932.5127 (16225.7946, 9911.0801)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 81252.5469 (49369.9257, 87621.0781)  train/nll_loss: 9932.4219 (16225.7452, 9910.9922)  train/rec_loss: 0.0431 (0.0704, 0.0430)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0186)
2025-02-06 16:53:10,419 train INFO: [2540/46609/10000]  lr: 9.937145107824344e-05  eta: 0:15:48  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0199)  train/logits_fake: 0.0191 (0.0193, 0.0179)  train/total_loss: 9932.5127 (16187.3498, 11581.1221)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 82900.7500 (49657.9071, 76064.7422)  train/nll_loss: 9932.4219 (16187.3001, 11581.0459)  train/rec_loss: 0.0431 (0.0703, 0.0503)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0179)
2025-02-06 16:53:12,946 train INFO: [2560/46609/10000]  lr: 9.936153119666295e-05  eta: 0:15:45  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0178)  train/logits_fake: 0.0192 (0.0193, 0.0190)  train/total_loss: 10251.7227 (16144.1932, 11232.0762)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 83746.2812 (49936.7274, 93108.2734)  train/nll_loss: 10251.6426 (16144.1433, 11231.9834)  train/rec_loss: 0.0445 (0.0701, 0.0487)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0190)
2025-02-06 16:53:15,478 train INFO: [2580/46609/10000]  lr: 9.935153415605526e-05  eta: 0:15:43  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0197)  train/logits_fake: 0.0191 (0.0193, 0.0196)  train/total_loss: 10498.0596 (16100.8391, 8455.0986)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 83746.2812 (50208.3967, 83797.3125)  train/nll_loss: 10497.9697 (16100.7889, 8455.0146)  train/rec_loss: 0.0456 (0.0699, 0.0367)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0196)
2025-02-06 16:53:18,009 train INFO: [2600/46609/10000]  lr: 9.93414599722071e-05  eta: 0:15:40  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0183)  train/logits_fake: 0.0193 (0.0193, 0.0187)  train/total_loss: 10609.5908 (16061.9348, 11854.1631)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 83815.5625 (50487.2090, 93894.2109)  train/nll_loss: 10609.4854 (16061.8844, 11854.0693)  train/rec_loss: 0.0460 (0.0697, 0.0514)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0187)
2025-02-06 16:53:20,544 train INFO: [2620/46609/10000]  lr: 9.933130866102697e-05  eta: 0:15:38  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0197)  train/logits_fake: 0.0193 (0.0193, 0.0200)  train/total_loss: 10736.1660 (16018.0167, 8775.1963)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 84144.0000 (50727.9864, 74870.0078)  train/nll_loss: 10736.0879 (16017.9660, 8775.1211)  train/rec_loss: 0.0466 (0.0695, 0.0381)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0200)
2025-02-06 16:53:23,072 train INFO: [2640/46609/10000]  lr: 9.932108023854514e-05  eta: 0:15:35  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0197)  train/logits_fake: 0.0193 (0.0193, 0.0199)  train/total_loss: 10330.7744 (15968.3963, 7014.3882)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 83439.9844 (50963.3741, 76507.9844)  train/nll_loss: 10330.6660 (15968.3453, 7014.3115)  train/rec_loss: 0.0448 (0.0693, 0.0304)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0199)
2025-02-06 16:53:25,598 train INFO: [2660/46609/10000]  lr: 9.931077472091375e-05  eta: 0:15:33  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0194)  train/logits_fake: 0.0193 (0.0193, 0.0201)  train/total_loss: 10033.0420 (15923.2143, 8128.8540)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 82556.0156 (51194.9256, 87355.3750)  train/nll_loss: 10032.9668 (15923.1632, 8128.7666)  train/rec_loss: 0.0435 (0.0691, 0.0353)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0201)
2025-02-06 16:53:28,128 train INFO: [2680/46609/10000]  lr: 9.930039212440655e-05  eta: 0:15:30  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0195)  train/logits_fake: 0.0194 (0.0193, 0.0197)  train/total_loss: 10033.0420 (15879.8178, 10083.6230)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 84037.1719 (51463.3361, 89533.1094)  train/nll_loss: 10032.9668 (15879.7663, 10083.5332)  train/rec_loss: 0.0435 (0.0689, 0.0438)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0197)
2025-02-06 16:53:30,656 train INFO: [2700/46609/10000]  lr: 9.928993246541913e-05  eta: 0:15:27  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0178)  train/logits_fake: 0.0194 (0.0193, 0.0192)  train/total_loss: 9802.9531 (15839.4372, 12164.1572)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 84037.1719 (51728.3791, 94981.6406)  train/nll_loss: 9802.8623 (15839.3855, 12164.0625)  train/rec_loss: 0.0425 (0.0687, 0.0528)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0192)
2025-02-06 16:53:33,182 train INFO: [2720/46609/10000]  lr: 9.927939576046868e-05  eta: 0:15:25  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0186)  train/logits_fake: 0.0194 (0.0193, 0.0191)  train/total_loss: 9953.2891 (15802.2450, 10821.0684)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 84037.1719 (51952.7181, 89402.0625)  train/nll_loss: 9953.1895 (15802.1930, 10820.9785)  train/rec_loss: 0.0432 (0.0686, 0.0470)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0191)
2025-02-06 16:53:35,707 train INFO: [2740/46609/10000]  lr: 9.926878202619414e-05  eta: 0:15:22  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0202)  train/logits_fake: 0.0193 (0.0193, 0.0203)  train/total_loss: 10152.3799 (15759.9008, 9184.1650)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 84099.2500 (52167.7980, 74890.5469)  train/nll_loss: 10152.3008 (15759.8487, 9184.0898)  train/rec_loss: 0.0441 (0.0684, 0.0399)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0203)
2025-02-06 16:53:38,239 train INFO: [2760/46609/10000]  lr: 9.925809127935599e-05  eta: 0:15:20  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0184)  train/logits_fake: 0.0194 (0.0193, 0.0195)  train/total_loss: 10083.6230 (15717.2972, 9916.2725)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 83477.4062 (52397.7749, 81542.3125)  train/nll_loss: 10083.5332 (15717.2448, 9916.1914)  train/rec_loss: 0.0438 (0.0682, 0.0430)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0195)
2025-02-06 16:53:40,769 train INFO: [2780/46609/10000]  lr: 9.924732353683642e-05  eta: 0:15:17  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0197)  train/logits_fake: 0.0194 (0.0193, 0.0203)  train/total_loss: 9984.6328 (15668.6179, 7804.1436)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 82284.6562 (52616.3347, 74180.0469)  train/nll_loss: 9984.5547 (15668.5653, 7804.0693)  train/rec_loss: 0.0433 (0.0680, 0.0339)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0203)
2025-02-06 16:53:43,303 train INFO: [2800/46609/10000]  lr: 9.923647881563915e-05  eta: 0:15:15  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0195)  train/logits_fake: 0.0193 (0.0193, 0.0198)  train/total_loss: 9776.9424 (15624.7333, 9322.9648)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 82850.8594 (52875.0876, 83526.7266)  train/nll_loss: 9776.8613 (15624.6804, 9322.8809)  train/rec_loss: 0.0424 (0.0678, 0.0405)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0198)
2025-02-06 16:53:45,827 train INFO: [2820/46609/10000]  lr: 9.922555713288949e-05  eta: 0:15:12  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0175)  train/logits_fake: 0.0194 (0.0193, 0.0179)  train/total_loss: 9454.5889 (15583.0397, 7930.8271)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 83272.4844 (53135.1117, 95126.4375)  train/nll_loss: 9454.5059 (15582.9865, 7930.7319)  train/rec_loss: 0.0410 (0.0676, 0.0344)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0179)
2025-02-06 16:53:48,352 train INFO: [2840/46609/10000]  lr: 9.921455850583425e-05  eta: 0:15:09  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0183)  train/logits_fake: 0.0195 (0.0193, 0.0187)  train/total_loss: 9393.5400 (15537.4974, 9465.6191)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 84713.3047 (53344.4175, 99505.1641)  train/nll_loss: 9393.4590 (15537.4441, 9465.5195)  train/rec_loss: 0.0408 (0.0674, 0.0411)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0187)
2025-02-06 16:53:50,875 train INFO: [2860/46609/10000]  lr: 9.920348295184176e-05  eta: 0:15:07  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0192)  train/logits_fake: 0.0194 (0.0193, 0.0186)  train/total_loss: 9322.9648 (15493.8241, 9381.5088)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 86310.9375 (53593.4639, 87038.8203)  train/nll_loss: 9322.8809 (15493.7705, 9381.4219)  train/rec_loss: 0.0405 (0.0672, 0.0407)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0186)
2025-02-06 16:53:53,402 train INFO: [2880/46609/10000]  lr: 9.919233048840184e-05  eta: 0:15:04  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0206)  train/logits_fake: 0.0194 (0.0193, 0.0198)  train/total_loss: 9465.6191 (15462.0700, 9923.7842)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 85020.5703 (53793.4951, 77511.4844)  train/nll_loss: 9465.5195 (15462.0162, 9923.7070)  train/rec_loss: 0.0411 (0.0671, 0.0431)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0193, -0.0198)
2025-02-06 16:53:55,923 train INFO: [2900/46609/10000]  lr: 9.918110113312576e-05  eta: 0:15:02  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0198)  train/logits_fake: 0.0194 (0.0193, 0.0197)  train/total_loss: 9629.2070 (15424.2275, 8466.9707)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 84110.9766 (53994.4471, 65960.9844)  train/nll_loss: 9629.1270 (15424.1735, 8466.9043)  train/rec_loss: 0.0418 (0.0669, 0.0367)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0197)
2025-02-06 16:53:58,442 train INFO: [2920/46609/10000]  lr: 9.916979490374619e-05  eta: 0:14:59  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0183)  train/logits_fake: 0.0194 (0.0193, 0.0196)  train/total_loss: 9769.4062 (15389.2406, 10416.5918)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 83878.8984 (54248.2723, 104316.1875)  train/nll_loss: 9769.3174 (15389.1863, 10416.4873)  train/rec_loss: 0.0424 (0.0668, 0.0452)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0196)
2025-02-06 16:54:00,974 train INFO: [2940/46609/10000]  lr: 9.915841181811723e-05  eta: 0:14:56  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0174)  train/logits_fake: 0.0194 (0.0193, 0.0180)  train/total_loss: 9821.8145 (15345.6818, 8288.7764)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 84416.7969 (54470.6513, 88985.9062)  train/nll_loss: 9821.7129 (15345.6274, 8288.6875)  train/rec_loss: 0.0426 (0.0666, 0.0360)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0180)
2025-02-06 16:54:03,510 train INFO: [2960/46609/10000]  lr: 9.914695189421432e-05  eta: 0:14:54  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0196)  train/logits_fake: 0.0194 (0.0193, 0.0200)  train/total_loss: 9564.0771 (15301.4876, 7005.6904)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 85787.0469 (54717.1563, 84063.9688)  train/nll_loss: 9563.9980 (15301.4329, 7005.6064)  train/rec_loss: 0.0415 (0.0664, 0.0304)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0200)
2025-02-06 16:54:06,043 train INFO: [2980/46609/10000]  lr: 9.91354151501342e-05  eta: 0:14:51  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0193)  train/logits_fake: 0.0192 (0.0193, 0.0194)  train/total_loss: 9309.2227 (15259.4137, 6390.1934)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 86561.0234 (54944.6806, 84852.3125)  train/nll_loss: 9309.1406 (15259.3587, 6390.1084)  train/rec_loss: 0.0404 (0.0662, 0.0277)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0194)
2025-02-06 16:54:08,563 train INFO: [3000/46609/10000]  lr: 9.912380160409504e-05  eta: 0:14:49  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0207)  train/logits_fake: 0.0191 (0.0193, 0.0203)  train/total_loss: 9131.4912 (15218.0627, 7739.4888)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 87486.2969 (55178.3201, 91458.5156)  train/nll_loss: 9131.4102 (15218.0075, 7739.3975)  train/rec_loss: 0.0396 (0.0661, 0.0336)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0203)
2025-02-06 16:54:11,089 train INFO: [3020/46609/10000]  lr: 9.911211127443615e-05  eta: 0:14:46  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0194)  train/logits_fake: 0.0192 (0.0193, 0.0197)  train/total_loss: 9295.2314 (15199.0474, 11528.7334)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 87632.5938 (55438.4098, 97902.0938)  train/nll_loss: 9295.1396 (15198.9920, 11528.6357)  train/rec_loss: 0.0403 (0.0660, 0.0500)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0197)
2025-02-06 16:54:13,617 train INFO: [3040/46609/10000]  lr: 9.910034417961819e-05  eta: 0:14:44  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0203)  train/logits_fake: 0.0191 (0.0193, 0.0201)  train/total_loss: 9500.4609 (15162.7415, 6620.6538)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 87632.5938 (55665.0810, 73048.5859)  train/nll_loss: 9500.3760 (15162.6859, 6620.5806)  train/rec_loss: 0.0412 (0.0658, 0.0287)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0201)
2025-02-06 16:54:16,146 train INFO: [3060/46609/10000]  lr: 9.9088500338223e-05  eta: 0:14:41  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0190)  train/logits_fake: 0.0192 (0.0193, 0.0190)  train/total_loss: 9773.3535 (15127.9747, 9086.1250)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 87616.1406 (55876.1186, 95620.6172)  train/nll_loss: 9773.2676 (15127.9188, 9086.0293)  train/rec_loss: 0.0424 (0.0657, 0.0394)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0190)
2025-02-06 16:54:18,679 train INFO: [3080/46609/10000]  lr: 9.907657976895363e-05  eta: 0:14:38  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0174)  train/logits_fake: 0.0192 (0.0193, 0.0178)  train/total_loss: 9726.4834 (15089.1794, 7585.3848)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 90182.8281 (56097.5159, 78866.8203)  train/nll_loss: 9726.3965 (15089.1233, 7585.3057)  train/rec_loss: 0.0422 (0.0655, 0.0329)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0178)
2025-02-06 16:54:21,213 train INFO: [3100/46609/10000]  lr: 9.906458249063424e-05  eta: 0:14:36  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0185)  train/logits_fake: 0.0192 (0.0193, 0.0186)  train/total_loss: 9954.0049 (15058.5484, 9842.8359)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 89486.6094 (56301.9882, 86600.8984)  train/nll_loss: 9953.8965 (15058.4921, 9842.7490)  train/rec_loss: 0.0432 (0.0654, 0.0427)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0186)
2025-02-06 16:54:23,747 train INFO: [3120/46609/10000]  lr: 9.905250852221025e-05  eta: 0:14:33  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0182)  train/logits_fake: 0.0192 (0.0193, 0.0178)  train/total_loss: 9651.4170 (15021.7774, 8683.5156)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 89212.4844 (56538.1963, 99313.8984)  train/nll_loss: 9651.3203 (15021.7209, 8683.4160)  train/rec_loss: 0.0419 (0.0652, 0.0377)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0178)
2025-02-06 16:54:26,281 train INFO: [3140/46609/10000]  lr: 9.904035788274805e-05  eta: 0:14:31  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0188)  train/logits_fake: 0.0193 (0.0193, 0.0195)  train/total_loss: 9670.0537 (14988.9672, 11318.8428)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 88966.5469 (56722.1157, 83360.7500)  train/nll_loss: 9669.9775 (14988.9105, 11318.7598)  train/rec_loss: 0.0420 (0.0651, 0.0491)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0195)
2025-02-06 16:54:28,814 train INFO: [3160/46609/10000]  lr: 9.902813059143517e-05  eta: 0:14:28  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0203)  train/logits_fake: 0.0194 (0.0193, 0.0203)  train/total_loss: 9699.0674 (14959.0635, 11033.1475)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 88966.5469 (56929.9721, 100176.6562)  train/nll_loss: 9698.9766 (14959.0066, 11033.0469)  train/rec_loss: 0.0421 (0.0649, 0.0479)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0203)
2025-02-06 16:54:31,347 train INFO: [3180/46609/10000]  lr: 9.901582666758017e-05  eta: 0:14:26  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0195)  train/logits_fake: 0.0193 (0.0193, 0.0187)  train/total_loss: 9810.6572 (14929.7418, 12951.4629)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 89486.6094 (57162.4102, 91403.6562)  train/nll_loss: 9810.5508 (14929.6846, 12951.3711)  train/rec_loss: 0.0426 (0.0648, 0.0562)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0187)
2025-02-06 16:54:33,885 train INFO: [3200/46609/10000]  lr: 9.900344613061264e-05  eta: 0:14:23  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0184)  train/logits_fake: 0.0193 (0.0193, 0.0186)  train/total_loss: 9791.7510 (14901.7656, 8666.1035)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 91004.7188 (57375.9034, 102078.9766)  train/nll_loss: 9791.6797 (14901.7083, 8666.0010)  train/rec_loss: 0.0425 (0.0647, 0.0376)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0186)
2025-02-06 16:54:36,424 train INFO: [3220/46609/10000]  lr: 9.899098900008311e-05  eta: 0:14:21  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0183)  train/logits_fake: 0.0193 (0.0193, 0.0198)  train/total_loss: 9904.8604 (14870.8659, 9719.8965)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 90418.0781 (57573.3703, 65373.5391)  train/nll_loss: 9904.7607 (14870.8084, 9719.8311)  train/rec_loss: 0.0430 (0.0645, 0.0422)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0198)
2025-02-06 16:54:38,954 train INFO: [3240/46609/10000]  lr: 9.897845529566311e-05  eta: 0:14:18  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0190)  train/logits_fake: 0.0193 (0.0193, 0.0199)  train/total_loss: 10041.1260 (14840.4359, 8491.7881)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 91403.6562 (57773.2945, 89059.2969)  train/nll_loss: 10041.0283 (14840.3781, 8491.6992)  train/rec_loss: 0.0436 (0.0644, 0.0369)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0199)
2025-02-06 16:54:41,485 train INFO: [3260/46609/10000]  lr: 9.896584503714506e-05  eta: 0:14:15  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0168)  train/logits_fake: 0.0192 (0.0193, 0.0172)  train/total_loss: 9859.1533 (14809.1893, 9706.3193)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 91479.5000 (57987.1093, 90689.6719)  train/nll_loss: 9859.0664 (14809.1313, 9706.2285)  train/rec_loss: 0.0428 (0.0643, 0.0421)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0172)
2025-02-06 16:54:44,015 train INFO: [3280/46609/10000]  lr: 9.895315824444229e-05  eta: 0:14:13  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0180)  train/logits_fake: 0.0192 (0.0193, 0.0184)  train/total_loss: 9835.2676 (14781.0424, 8848.2441)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 90502.6641 (58202.4907, 85902.6719)  train/nll_loss: 9835.1396 (14780.9842, 8848.1582)  train/rec_loss: 0.0427 (0.0642, 0.0384)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0184)
2025-02-06 16:54:46,547 train INFO: [3300/46609/10000]  lr: 9.894039493758898e-05  eta: 0:14:10  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0188)  train/logits_fake: 0.0191 (0.0193, 0.0191)  train/total_loss: 9710.3516 (14745.5455, 7707.1499)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 90502.6641 (58402.2592, 90415.8672)  train/nll_loss: 9710.2383 (14745.4871, 7707.0596)  train/rec_loss: 0.0421 (0.0640, 0.0335)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0191)
2025-02-06 16:54:49,084 train INFO: [3320/46609/10000]  lr: 9.892755513674011e-05  eta: 0:14:08  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0191)  train/logits_fake: 0.0192 (0.0193, 0.0206)  train/total_loss: 9432.9531 (14708.7171, 7549.2075)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 91143.5625 (58613.7007, 86567.8594)  train/nll_loss: 9432.8516 (14708.6585, 7549.1211)  train/rec_loss: 0.0409 (0.0638, 0.0328)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0206)
2025-02-06 16:54:51,623 train INFO: [3340/46609/10000]  lr: 9.891463886217151e-05  eta: 0:14:05  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0203)  train/logits_fake: 0.0191 (0.0193, 0.0208)  train/total_loss: 8999.0908 (14679.7842, 10660.7031)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 92371.4844 (58844.6254, 109724.5391)  train/nll_loss: 8998.9961 (14679.7254, 10660.5938)  train/rec_loss: 0.0391 (0.0637, 0.0463)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0208)
2025-02-06 16:54:54,151 train INFO: [3360/46609/10000]  lr: 9.89016461342797e-05  eta: 0:14:03  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0171)  train/logits_fake: 0.0191 (0.0193, 0.0182)  train/total_loss: 8969.5898 (14648.2556, 8925.9170)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 92438.3984 (59032.8902, 102573.2656)  train/nll_loss: 8969.5020 (14648.1965, 8925.8145)  train/rec_loss: 0.0389 (0.0636, 0.0387)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0182)
2025-02-06 16:54:56,681 train INFO: [3380/46609/10000]  lr: 9.888857697358202e-05  eta: 0:14:00  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0185)  train/logits_fake: 0.0192 (0.0193, 0.0188)  train/total_loss: 9362.4102 (14619.0148, 9058.0166)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 91935.4375 (59209.2165, 80758.3594)  train/nll_loss: 9362.3281 (14618.9556, 9057.9355)  train/rec_loss: 0.0406 (0.0635, 0.0393)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0188)
2025-02-06 16:54:59,215 train INFO: [3400/46609/10000]  lr: 9.887543140071642e-05  eta: 0:13:58  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0211)  train/logits_fake: 0.0193 (0.0193, 0.0212)  train/total_loss: 9452.1084 (14590.1841, 9085.9697)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 91680.4688 (59384.5238, 110850.7812)  train/nll_loss: 9452.0117 (14590.1248, 9085.8584)  train/rec_loss: 0.0410 (0.0633, 0.0394)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0212)
2025-02-06 16:55:01,743 train INFO: [3420/46609/10000]  lr: 9.886220943644157e-05  eta: 0:13:55  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0189)  train/logits_fake: 0.0193 (0.0193, 0.0179)  train/total_loss: 9670.0596 (14562.8621, 9998.1816)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 92127.2500 (59594.2729, 92181.6250)  train/nll_loss: 9669.9746 (14562.8025, 9998.0898)  train/rec_loss: 0.0420 (0.0632, 0.0434)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0179)
2025-02-06 16:55:04,282 train INFO: [3440/46609/10000]  lr: 9.884891110163676e-05  eta: 0:13:52  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0199)  train/logits_fake: 0.0193 (0.0193, 0.0205)  train/total_loss: 9669.2559 (14533.4872, 8185.0400)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 91680.4688 (59798.6144, 79319.2422)  train/nll_loss: 9669.1660 (14533.4274, 8184.9609)  train/rec_loss: 0.0420 (0.0631, 0.0355)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0205)
2025-02-06 16:55:06,817 train INFO: [3460/46609/10000]  lr: 9.883553641730187e-05  eta: 0:13:50  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0177)  train/logits_fake: 0.0193 (0.0193, 0.0171)  train/total_loss: 9663.7197 (14501.0912, 8527.2666)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 92177.6094 (60017.5073, 113749.8125)  train/nll_loss: 9663.6523 (14501.0312, 8527.1533)  train/rec_loss: 0.0419 (0.0629, 0.0370)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0171)
2025-02-06 16:55:09,355 train INFO: [3480/46609/10000]  lr: 9.882208540455734e-05  eta: 0:13:47  iter_time: 0.127  data: 0.001  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0204)  train/logits_fake: 0.0193 (0.0193, 0.0199)  train/total_loss: 9451.6533 (14472.1770, 9451.6533)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 92677.3438 (60189.1164, 83803.9766)  train/nll_loss: 9451.5693 (14472.1168, 9451.5693)  train/rec_loss: 0.0410 (0.0628, 0.0410)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0199)
2025-02-06 16:55:11,884 train INFO: [3500/46609/10000]  lr: 9.880855808464419e-05  eta: 0:13:45  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0195)  train/logits_fake: 0.0193 (0.0193, 0.0192)  train/total_loss: 9240.4951 (14441.9182, 6789.2021)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 93158.8203 (60364.5306, 75391.4062)  train/nll_loss: 9240.3906 (14441.8578, 6789.1270)  train/rec_loss: 0.0401 (0.0627, 0.0295)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0192)
2025-02-06 16:55:14,418 train INFO: [3520/46609/10000]  lr: 9.879495447892385e-05  eta: 0:13:42  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0187)  train/logits_fake: 0.0194 (0.0193, 0.0192)  train/total_loss: 9275.4238 (14415.4528, 8740.2363)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 93032.2969 (60551.7914, 99127.3438)  train/nll_loss: 9275.3271 (14415.3923, 8740.1367)  train/rec_loss: 0.0403 (0.0626, 0.0379)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0193, -0.0192)
2025-02-06 16:55:16,951 train INFO: [3540/46609/10000]  lr: 9.878127460887831e-05  eta: 0:13:40  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0223)  train/logits_fake: 0.0192 (0.0193, 0.0220)  train/total_loss: 9118.1465 (14386.8994, 8848.4727)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 92795.2031 (60737.1614, 95121.2734)  train/nll_loss: 9118.0547 (14386.8387, 8848.3779)  train/rec_loss: 0.0396 (0.0624, 0.0384)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0220)
2025-02-06 16:55:19,479 train INFO: [3560/46609/10000]  lr: 9.876751849610996e-05  eta: 0:13:37  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0213)  train/logits_fake: 0.0192 (0.0193, 0.0202)  train/total_loss: 9118.1465 (14356.8382, 7046.0786)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 92396.5312 (60932.3189, 91565.1484)  train/nll_loss: 9118.0547 (14356.7773, 7045.9868)  train/rec_loss: 0.0396 (0.0623, 0.0306)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0202)
2025-02-06 16:55:22,008 train INFO: [3580/46609/10000]  lr: 9.875368616234155e-05  eta: 0:13:35  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0202)  train/logits_fake: 0.0192 (0.0193, 0.0204)  train/total_loss: 8742.9521 (14321.1528, 9280.1787)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 92795.2031 (61119.4524, 85062.7656)  train/nll_loss: 8742.8496 (14321.0917, 9280.0938)  train/rec_loss: 0.0379 (0.0622, 0.0403)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0204)
2025-02-06 16:55:24,537 train INFO: [3600/46609/10000]  lr: 9.873977762941625e-05  eta: 0:13:32  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0187)  train/logits_fake: 0.0192 (0.0193, 0.0188)  train/total_loss: 8398.9473 (14288.5057, 7718.4712)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 93032.2969 (61311.1966, 120826.7031)  train/nll_loss: 8398.8496 (14288.4444, 7718.3506)  train/rec_loss: 0.0365 (0.0620, 0.0335)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0188)
2025-02-06 16:55:27,068 train INFO: [3620/46609/10000]  lr: 9.872579291929751e-05  eta: 0:13:30  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0194)  train/logits_fake: 0.0191 (0.0193, 0.0196)  train/total_loss: 8432.2432 (14263.5935, 8432.2432)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 93007.7422 (61493.9624, 104126.2188)  train/nll_loss: 8432.1387 (14263.5320, 8432.1387)  train/rec_loss: 0.0366 (0.0619, 0.0366)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0196)
2025-02-06 16:55:29,606 train INFO: [3640/46609/10000]  lr: 9.87117320540691e-05  eta: 0:13:27  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0186)  train/logits_fake: 0.0192 (0.0193, 0.0187)  train/total_loss: 8404.5605 (14237.1148, 7319.7344)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 94477.0781 (61715.8313, 84929.9922)  train/nll_loss: 8404.4648 (14237.0531, 7319.6494)  train/rec_loss: 0.0365 (0.0618, 0.0318)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0187)
2025-02-06 16:55:32,129 train INFO: [3660/46609/10000]  lr: 9.869759505593506e-05  eta: 0:13:24  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0182)  train/logits_fake: 0.0192 (0.0193, 0.0185)  train/total_loss: 8506.9189 (14212.2320, 8506.9189)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 94477.0781 (61900.5230, 94074.5000)  train/nll_loss: 8506.8252 (14212.1701, 8506.8252)  train/rec_loss: 0.0369 (0.0617, 0.0369)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0185)
2025-02-06 16:55:34,662 train INFO: [3680/46609/10000]  lr: 9.868338194721962e-05  eta: 0:13:22  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0187)  train/logits_fake: 0.0192 (0.0193, 0.0187)  train/total_loss: 8891.2510 (14189.7919, 8269.1699)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 94098.2188 (62064.8942, 87856.6953)  train/nll_loss: 8891.1602 (14189.7299, 8269.0820)  train/rec_loss: 0.0386 (0.0616, 0.0359)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0187)
2025-02-06 16:55:37,196 train INFO: [3700/46609/10000]  lr: 9.866909275036726e-05  eta: 0:13:19  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0178)  train/logits_fake: 0.0192 (0.0193, 0.0179)  train/total_loss: 9158.5430 (14162.6193, 9519.9805)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 93882.9688 (62231.9802, 88076.2891)  train/nll_loss: 9158.4277 (14162.5570, 9519.8926)  train/rec_loss: 0.0398 (0.0615, 0.0413)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0179)
2025-02-06 16:55:39,729 train INFO: [3720/46609/10000]  lr: 9.86547274879425e-05  eta: 0:13:17  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0181)  train/logits_fake: 0.0192 (0.0193, 0.0170)  train/total_loss: 9080.7061 (14134.0513, 9580.0645)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 94555.1406 (62410.4512, 95488.4766)  train/nll_loss: 9080.6191 (14133.9889, 9579.9688)  train/rec_loss: 0.0394 (0.0613, 0.0416)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0170)
2025-02-06 16:55:42,262 train INFO: [3740/46609/10000]  lr: 9.86402861826301e-05  eta: 0:13:14  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0173)  train/logits_fake: 0.0192 (0.0193, 0.0185)  train/total_loss: 9043.0049 (14106.9391, 10187.9551)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 93023.5391 (62587.5169, 115206.5312)  train/nll_loss: 9042.9102 (14106.8765, 10187.8398)  train/rec_loss: 0.0392 (0.0612, 0.0442)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0185)
2025-02-06 16:55:44,802 train INFO: [3760/46609/10000]  lr: 9.862576885723485e-05  eta: 0:13:12  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0200)  train/logits_fake: 0.0192 (0.0193, 0.0200)  train/total_loss: 9080.7061 (14081.1646, 8572.1758)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 93167.1328 (62774.4149, 91994.4297)  train/nll_loss: 9080.6191 (14081.1018, 8572.0840)  train/rec_loss: 0.0394 (0.0611, 0.0372)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0200)
2025-02-06 16:55:47,342 train INFO: [3780/46609/10000]  lr: 9.861117553468158e-05  eta: 0:13:09  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0207)  train/logits_fake: 0.0192 (0.0193, 0.0202)  train/total_loss: 8666.1211 (14052.2129, 7153.9448)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 95315.6875 (62957.9019, 102743.8672)  train/nll_loss: 8666.0381 (14052.1499, 7153.8423)  train/rec_loss: 0.0376 (0.0610, 0.0310)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0202)
2025-02-06 16:55:49,877 train INFO: [3800/46609/10000]  lr: 9.859650623801515e-05  eta: 0:13:07  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0178)  train/logits_fake: 0.0192 (0.0193, 0.0178)  train/total_loss: 8650.5693 (14026.1448, 8329.2207)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 95488.4766 (63138.1049, 114950.7969)  train/nll_loss: 8650.4795 (14026.0816, 8329.1055)  train/rec_loss: 0.0375 (0.0609, 0.0362)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0178)
2025-02-06 16:55:52,413 train INFO: [3820/46609/10000]  lr: 9.858176099040036e-05  eta: 0:13:04  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0198)  train/logits_fake: 0.0192 (0.0193, 0.0197)  train/total_loss: 8666.1211 (14000.6520, 10518.7852)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 97228.5469 (63322.6877, 87617.1562)  train/nll_loss: 8666.0381 (14000.5887, 10518.6973)  train/rec_loss: 0.0376 (0.0608, 0.0457)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0197)
2025-02-06 16:55:54,948 train INFO: [3840/46609/10000]  lr: 9.856693981512198e-05  eta: 0:13:01  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0192)  train/logits_fake: 0.0191 (0.0193, 0.0198)  train/total_loss: 8879.7832 (13978.3266, 10189.4111)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 97670.1719 (63500.3854, 91255.7891)  train/nll_loss: 8879.6836 (13978.2631, 10189.3203)  train/rec_loss: 0.0385 (0.0607, 0.0442)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0198)
2025-02-06 16:55:57,485 train INFO: [3860/46609/10000]  lr: 9.855204273558467e-05  eta: 0:12:59  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0180)  train/logits_fake: 0.0190 (0.0193, 0.0183)  train/total_loss: 8866.1885 (13951.9864, 9525.9424)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 96797.1016 (63663.8290, 79608.8828)  train/nll_loss: 8866.0986 (13951.9227, 9525.8623)  train/rec_loss: 0.0385 (0.0606, 0.0413)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0183)
2025-02-06 16:56:00,018 train INFO: [3880/46609/10000]  lr: 9.853706977531296e-05  eta: 0:12:56  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0177)  train/logits_fake: 0.0190 (0.0193, 0.0191)  train/total_loss: 8866.1885 (13926.4721, 10393.2930)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 96797.1016 (63839.8174, 114978.9531)  train/nll_loss: 8866.0986 (13926.4083, 10393.1777)  train/rec_loss: 0.0385 (0.0604, 0.0451)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0191)
2025-02-06 16:56:02,550 train INFO: [3900/46609/10000]  lr: 9.852202095795118e-05  eta: 0:12:54  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0186)  train/logits_fake: 0.0190 (0.0193, 0.0192)  train/total_loss: 8421.2090 (13895.9587, 9691.5596)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 97687.1094 (64027.9180, 98653.2969)  train/nll_loss: 8421.1201 (13895.8947, 9691.4609)  train/rec_loss: 0.0366 (0.0603, 0.0421)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0193, -0.0192)
2025-02-06 16:56:05,087 train INFO: [3920/46609/10000]  lr: 9.85068963072635e-05  eta: 0:12:51  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0202)  train/logits_fake: 0.0190 (0.0193, 0.0207)  train/total_loss: 8583.1973 (13870.7476, 8538.5684)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 97670.1719 (64200.3249, 97303.8984)  train/nll_loss: 8583.0859 (13870.6834, 8538.4707)  train/rec_loss: 0.0373 (0.0602, 0.0371)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0193, -0.0207)
2025-02-06 16:56:07,624 train INFO: [3940/46609/10000]  lr: 9.849169584713375e-05  eta: 0:12:49  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0179)  train/logits_fake: 0.0190 (0.0193, 0.0180)  train/total_loss: 8284.9678 (13844.4898, 8284.9678)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 97303.8984 (64366.6222, 98159.1719)  train/nll_loss: 8284.8691 (13844.4254, 8284.8691)  train/rec_loss: 0.0360 (0.0601, 0.0360)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0180)
2025-02-06 16:56:10,156 train INFO: [3960/46609/10000]  lr: 9.847641960156558e-05  eta: 0:12:46  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0203)  train/logits_fake: 0.0191 (0.0193, 0.0213)  train/total_loss: 8421.2090 (13821.1084, 10677.2529)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 98653.2969 (64550.6726, 108961.0234)  train/nll_loss: 8421.1201 (13821.0438, 10677.1436)  train/rec_loss: 0.0366 (0.0600, 0.0463)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0213)
2025-02-06 16:56:12,689 train INFO: [3980/46609/10000]  lr: 9.846106759468224e-05  eta: 0:12:44  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0174)  train/logits_fake: 0.0191 (0.0193, 0.0169)  train/total_loss: 8538.5684 (13798.5453, 8520.3516)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 99537.2344 (64747.9157, 115655.3906)  train/nll_loss: 8538.4707 (13798.4806, 8520.2363)  train/rec_loss: 0.0371 (0.0599, 0.0370)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0169)
2025-02-06 16:56:15,225 train INFO: [4000/46609/10000]  lr: 9.844563985072668e-05  eta: 0:12:41  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0183)  train/logits_fake: 0.0191 (0.0193, 0.0191)  train/total_loss: 8538.5684 (13772.3771, 9423.0000)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 98845.6562 (64911.3679, 123243.6094)  train/nll_loss: 8538.4707 (13772.3122, 9422.8770)  train/rec_loss: 0.0371 (0.0598, 0.0409)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0193, -0.0191)
2025-02-06 16:56:17,761 train INFO: [4020/46609/10000]  lr: 9.843013639406139e-05  eta: 0:12:39  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0209)  train/logits_fake: 0.0191 (0.0193, 0.0208)  train/total_loss: 8520.3516 (13748.2679, 9482.5723)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 100767.0000 (65087.5287, 96765.9219)  train/nll_loss: 8520.2363 (13748.2029, 9482.4756)  train/rec_loss: 0.0370 (0.0597, 0.0412)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0208)
2025-02-06 16:56:20,297 train INFO: [4040/46609/10000]  lr: 9.841455724916842e-05  eta: 0:12:36  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0192)  train/logits_fake: 0.0192 (0.0193, 0.0187)  train/total_loss: 8719.0039 (13725.9581, 6515.4937)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 102246.0625 (65292.6770, 118515.0625)  train/nll_loss: 8718.9121 (13725.8928, 6515.3750)  train/rec_loss: 0.0378 (0.0596, 0.0283)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0187)
2025-02-06 16:56:22,836 train INFO: [4060/46609/10000]  lr: 9.839890244064939e-05  eta: 0:12:34  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0188)  train/logits_fake: 0.0192 (0.0193, 0.0189)  train/total_loss: 8522.7607 (13697.6840, 8522.7607)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 102246.0625 (65470.0451, 108527.4688)  train/nll_loss: 8522.6523 (13697.6186, 8522.6523)  train/rec_loss: 0.0370 (0.0595, 0.0370)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0189)
2025-02-06 16:56:25,373 train INFO: [4080/46609/10000]  lr: 9.838317199322539e-05  eta: 0:12:31  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0208)  train/logits_fake: 0.0192 (0.0193, 0.0208)  train/total_loss: 8225.5596 (13668.3427, 7581.5508)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 100893.4609 (65619.2715, 84002.4062)  train/nll_loss: 8225.4463 (13668.2771, 7581.4668)  train/rec_loss: 0.0357 (0.0593, 0.0329)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0208)
2025-02-06 16:56:27,906 train INFO: [4100/46609/10000]  lr: 9.836736593173694e-05  eta: 0:12:28  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0188)  train/logits_fake: 0.0193 (0.0193, 0.0192)  train/total_loss: 8378.9375 (13642.0343, 7881.9634)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 100392.0078 (65764.2655, 115623.2344)  train/nll_loss: 8378.8301 (13641.9685, 7881.8477)  train/rec_loss: 0.0364 (0.0592, 0.0342)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0192)
2025-02-06 16:56:30,444 train INFO: [4120/46609/10000]  lr: 9.835148428114396e-05  eta: 0:12:26  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0191)  train/logits_fake: 0.0192 (0.0193, 0.0181)  train/total_loss: 8093.0522 (13616.8430, 8526.2832)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 99678.0469 (65932.4729, 111825.8047)  train/nll_loss: 8092.9531 (13616.7770, 8526.1709)  train/rec_loss: 0.0351 (0.0591, 0.0370)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0181)
2025-02-06 16:56:32,981 train INFO: [4140/46609/10000]  lr: 9.833552706652576e-05  eta: 0:12:23  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0172)  train/logits_fake: 0.0192 (0.0193, 0.0181)  train/total_loss: 8088.4424 (13593.3517, 8574.5107)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 99446.1406 (66128.7916, 92285.7891)  train/nll_loss: 8088.3467 (13593.2855, 8574.4180)  train/rec_loss: 0.0351 (0.0590, 0.0372)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0181)
2025-02-06 16:56:35,515 train INFO: [4160/46609/10000]  lr: 9.831949431308091e-05  eta: 0:12:21  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0185)  train/logits_fake: 0.0192 (0.0193, 0.0190)  train/total_loss: 8220.0410 (13566.8671, 6977.6143)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 98991.9922 (66279.0656, 119365.9297)  train/nll_loss: 8219.9326 (13566.8008, 6977.4951)  train/rec_loss: 0.0357 (0.0589, 0.0303)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0190)
2025-02-06 16:56:38,048 train INFO: [4180/46609/10000]  lr: 9.830338604612738e-05  eta: 0:12:18  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0199)  train/logits_fake: 0.0192 (0.0193, 0.0201)  train/total_loss: 8243.5820 (13545.1760, 6093.6494)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 97945.3984 (66426.8042, 87132.2500)  train/nll_loss: 8243.4990 (13545.1096, 6093.5625)  train/rec_loss: 0.0358 (0.0588, 0.0264)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0201)
2025-02-06 16:56:40,576 train INFO: [4200/46609/10000]  lr: 9.828720229110229e-05  eta: 0:12:16  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0191)  train/logits_fake: 0.0192 (0.0193, 0.0195)  train/total_loss: 8236.9971 (13521.4351, 6373.6572)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 98905.2969 (66576.9364, 99640.3672)  train/nll_loss: 8236.8906 (13521.3685, 6373.5576)  train/rec_loss: 0.0358 (0.0587, 0.0277)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0195)
2025-02-06 16:56:43,104 train INFO: [4220/46609/10000]  lr: 9.8270943073562e-05  eta: 0:12:13  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0185)  train/logits_fake: 0.0193 (0.0193, 0.0186)  train/total_loss: 8243.5820 (13497.1628, 9340.8340)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 97834.4531 (66739.5119, 114143.5312)  train/nll_loss: 8243.4990 (13497.0960, 9340.7197)  train/rec_loss: 0.0358 (0.0586, 0.0405)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0193, -0.0186)
2025-02-06 16:56:45,629 train INFO: [4240/46609/10000]  lr: 9.825460841918203e-05  eta: 0:12:11  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0201)  train/logits_fake: 0.0192 (0.0193, 0.0200)  train/total_loss: 8077.0259 (13472.0997, 8929.8711)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 97676.2109 (66886.1285, 97720.6094)  train/nll_loss: 8076.9194 (13472.0329, 8929.7734)  train/rec_loss: 0.0351 (0.0585, 0.0388)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0200)
2025-02-06 16:56:48,151 train INFO: [4260/46609/10000]  lr: 9.823819835375703e-05  eta: 0:12:08  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0180)  train/logits_fake: 0.0192 (0.0193, 0.0188)  train/total_loss: 7966.7471 (13445.0181, 9707.8789)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 97676.2109 (67040.3307, 97814.3281)  train/nll_loss: 7966.6597 (13444.9510, 9707.7812)  train/rec_loss: 0.0346 (0.0584, 0.0421)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0188)
2025-02-06 16:56:50,683 train INFO: [4280/46609/10000]  lr: 9.822171290320077e-05  eta: 0:12:05  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0190)  train/logits_fake: 0.0191 (0.0192, 0.0185)  train/total_loss: 7926.0322 (13423.9018, 8469.4004)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 97834.4531 (67193.9996, 95787.6719)  train/nll_loss: 7925.9092 (13423.8346, 8469.3047)  train/rec_loss: 0.0344 (0.0583, 0.0368)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0185)
2025-02-06 16:56:53,208 train INFO: [4300/46609/10000]  lr: 9.820515209354598e-05  eta: 0:12:03  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0195)  train/logits_fake: 0.0192 (0.0193, 0.0202)  train/total_loss: 8086.3042 (13402.6472, 15447.3174)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 98770.6562 (67362.6372, 96968.4219)  train/nll_loss: 8086.1758 (13402.5798, 15447.2207)  train/rec_loss: 0.0351 (0.0582, 0.0670)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0193, -0.0202)
2025-02-06 16:56:55,726 train INFO: [4320/46609/10000]  lr: 9.818851595094445e-05  eta: 0:12:00  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0194)  train/logits_fake: 0.0189 (0.0192, 0.0188)  train/total_loss: 8173.0293 (13384.6878, 7516.3726)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 98969.1094 (67535.3157, 95408.3906)  train/nll_loss: 8172.9307 (13384.6203, 7516.2773)  train/rec_loss: 0.0355 (0.0581, 0.0326)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0192, -0.0188)
2025-02-06 16:56:58,249 train INFO: [4340/46609/10000]  lr: 9.817180450166691e-05  eta: 0:11:58  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0197)  train/logits_fake: 0.0191 (0.0192, 0.0199)  train/total_loss: 8365.3027 (13363.9016, 5810.9277)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 100944.9062 (67703.5757, 99720.1406)  train/nll_loss: 8365.1963 (13363.8339, 5810.8281)  train/rec_loss: 0.0363 (0.0580, 0.0252)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0199)
2025-02-06 16:57:00,778 train INFO: [4360/46609/10000]  lr: 9.815501777210306e-05  eta: 0:11:55  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0177)  train/logits_fake: 0.0192 (0.0192, 0.0182)  train/total_loss: 8657.2979 (13344.2322, 9605.2520)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 102192.8281 (67857.8508, 114993.0312)  train/nll_loss: 8657.1992 (13344.1644, 9605.1367)  train/rec_loss: 0.0376 (0.0579, 0.0417)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0182)
2025-02-06 16:57:03,314 train INFO: [4380/46609/10000]  lr: 9.81381557887614e-05  eta: 0:11:53  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0196)  train/logits_fake: 0.0192 (0.0192, 0.0197)  train/total_loss: 8699.9004 (13322.6347, 6741.5894)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 102192.8281 (68013.9449, 79512.0312)  train/nll_loss: 8699.8057 (13322.5667, 6741.5098)  train/rec_loss: 0.0378 (0.0578, 0.0293)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0197)
2025-02-06 16:57:05,848 train INFO: [4400/46609/10000]  lr: 9.812121857826931e-05  eta: 0:11:50  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0189)  train/logits_fake: 0.0192 (0.0192, 0.0192)  train/total_loss: 8980.8623 (13304.7062, 8231.5166)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 103278.5469 (68180.4501, 116482.1094)  train/nll_loss: 8980.7549 (13304.6380, 8231.4004)  train/rec_loss: 0.0390 (0.0577, 0.0357)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0192)
2025-02-06 16:57:08,379 train INFO: [4420/46609/10000]  lr: 9.810420616737296e-05  eta: 0:11:48  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0172)  train/logits_fake: 0.0192 (0.0192, 0.0174)  train/total_loss: 9047.4336 (13286.2627, 9495.8096)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 103345.5781 (68343.1677, 122168.4531)  train/nll_loss: 9047.3262 (13286.1943, 9495.6875)  train/rec_loss: 0.0393 (0.0577, 0.0412)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0174)
2025-02-06 16:57:10,913 train INFO: [4440/46609/10000]  lr: 9.808711858293728e-05  eta: 0:11:45  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0180)  train/logits_fake: 0.0192 (0.0192, 0.0181)  train/total_loss: 8990.5498 (13266.3588, 9618.4541)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 103350.9219 (68493.3480, 106923.7969)  train/nll_loss: 8990.4443 (13266.2904, 9618.3477)  train/rec_loss: 0.0390 (0.0576, 0.0417)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0181)
2025-02-06 16:57:13,456 train INFO: [4460/46609/10000]  lr: 9.806995585194588e-05  eta: 0:11:43  iter_time: 0.128  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0168)  train/logits_fake: 0.0192 (0.0192, 0.0176)  train/total_loss: 9294.8545 (13255.8242, 11650.9512)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 103729.6172 (68646.6882, 109100.7344)  train/nll_loss: 9294.7744 (13255.7556, 11650.8418)  train/rec_loss: 0.0403 (0.0575, 0.0506)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0176)
2025-02-06 16:57:15,993 train INFO: [4480/46609/10000]  lr: 9.805271800150107e-05  eta: 0:11:40  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0177)  train/logits_fake: 0.0191 (0.0192, 0.0170)  train/total_loss: 9530.2324 (13242.0429, 7940.5103)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 103971.3594 (68805.5784, 114038.3516)  train/nll_loss: 9530.1406 (13241.9741, 7940.3960)  train/rec_loss: 0.0414 (0.0575, 0.0345)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0170)
2025-02-06 16:57:18,524 train INFO: [4500/46609/10000]  lr: 9.803540505882376e-05  eta: 0:11:37  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0190)  train/logits_fake: 0.0192 (0.0192, 0.0191)  train/total_loss: 9722.7461 (13228.4487, 9290.0625)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 105113.1328 (68988.7821, 103867.0938)  train/nll_loss: 9722.6348 (13228.3797, 9289.9590)  train/rec_loss: 0.0422 (0.0574, 0.0403)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0191)
2025-02-06 16:57:21,058 train INFO: [4520/46609/10000]  lr: 9.801801705125344e-05  eta: 0:11:35  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0153)  train/logits_fake: 0.0193 (0.0192, 0.0164)  train/total_loss: 9742.5498 (13212.8882, 13585.2598)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 106586.7812 (69162.0768, 103400.9688)  train/nll_loss: 9742.4199 (13212.8190, 13585.1562)  train/rec_loss: 0.0423 (0.0573, 0.0590)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0164)
2025-02-06 16:57:23,598 train INFO: [4540/46609/10000]  lr: 9.800055400624818e-05  eta: 0:11:32  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0222)  train/logits_fake: 0.0192 (0.0192, 0.0213)  train/total_loss: 9742.5498 (13194.4202, 18045.6406)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 106289.5391 (69316.2922, 97710.1094)  train/nll_loss: 9742.4199 (13194.3509, 18045.5430)  train/rec_loss: 0.0423 (0.0573, 0.0783)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0213)
2025-02-06 16:57:26,144 train INFO: [4560/46609/10000]  lr: 9.798301595138447e-05  eta: 0:11:30  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0199)  train/logits_fake: 0.0192 (0.0192, 0.0213)  train/total_loss: 9339.6406 (13178.1321, 8831.7031)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 106850.0469 (69486.4130, 108317.3203)  train/nll_loss: 9339.5352 (13178.0626, 8831.5947)  train/rec_loss: 0.0405 (0.0572, 0.0383)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0213)
2025-02-06 16:57:28,678 train INFO: [4580/46609/10000]  lr: 9.796540291435734e-05  eta: 0:11:27  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0189)  train/logits_fake: 0.0192 (0.0192, 0.0194)  train/total_loss: 9290.0625 (13160.9541, 9473.4658)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 107917.0391 (69654.4030, 125458.6719)  train/nll_loss: 9289.9590 (13160.8845, 9473.3408)  train/rec_loss: 0.0403 (0.0571, 0.0411)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0194)
2025-02-06 16:57:31,200 train INFO: [4600/46609/10000]  lr: 9.794771492298013e-05  eta: 0:11:25  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0185)  train/logits_fake: 0.0192 (0.0192, 0.0182)  train/total_loss: 8904.4873 (13141.8874, 9475.2480)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 107786.9766 (69822.7598, 140437.0625)  train/nll_loss: 8904.3867 (13141.8176, 9475.1074)  train/rec_loss: 0.0386 (0.0570, 0.0411)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0182)
2025-02-06 16:57:33,723 train INFO: [4620/46609/10000]  lr: 9.792995200518464e-05  eta: 0:11:22  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0166)  train/logits_fake: 0.0192 (0.0192, 0.0175)  train/total_loss: 8707.8438 (13121.8877, 11006.8145)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 105924.0547 (69984.0713, 104534.7500)  train/nll_loss: 8707.7510 (13121.8177, 11006.7100)  train/rec_loss: 0.0378 (0.0570, 0.0478)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0175)
2025-02-06 16:57:36,245 train INFO: [4640/46609/10000]  lr: 9.791211418902089e-05  eta: 0:11:20  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0177)  train/logits_fake: 0.0192 (0.0192, 0.0182)  train/total_loss: 8792.6582 (13103.3693, 6753.0029)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 105924.0547 (70123.2423, 103372.3672)  train/nll_loss: 8792.5352 (13103.2992, 6752.8994)  train/rec_loss: 0.0382 (0.0569, 0.0293)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0182)
2025-02-06 16:57:38,787 train INFO: [4660/46609/10000]  lr: 9.789420150265727e-05  eta: 0:11:17  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0194)  train/logits_fake: 0.0192 (0.0192, 0.0178)  train/total_loss: 8740.3838 (13087.3130, 10263.9590)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 105924.0547 (70288.0211, 118132.9844)  train/nll_loss: 8740.2695 (13087.2427, 10263.8408)  train/rec_loss: 0.0379 (0.0568, 0.0445)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0178)
2025-02-06 16:57:41,316 train INFO: [4680/46609/10000]  lr: 9.787621397438034e-05  eta: 0:11:15  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0179)  train/logits_fake: 0.0192 (0.0192, 0.0177)  train/total_loss: 9185.7324 (13079.9157, 7692.7700)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 107809.5234 (70460.2947, 112584.2188)  train/nll_loss: 9185.6641 (13079.8453, 7692.6572)  train/rec_loss: 0.0399 (0.0568, 0.0334)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0177)
2025-02-06 16:57:43,845 train INFO: [4700/46609/10000]  lr: 9.785815163259485e-05  eta: 0:11:12  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0192)  train/logits_fake: 0.0191 (0.0192, 0.0210)  train/total_loss: 9474.2900 (13066.4386, 12024.0732)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 107768.7031 (70618.0893, 114088.6328)  train/nll_loss: 9474.1582 (13066.3680, 12023.9590)  train/rec_loss: 0.0411 (0.0567, 0.0522)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0210)
2025-02-06 16:57:46,378 train INFO: [4720/46609/10000]  lr: 9.784001450582375e-05  eta: 0:11:09  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0175)  train/logits_fake: 0.0191 (0.0192, 0.0189)  train/total_loss: 9571.4375 (13049.2792, 7930.3115)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 108747.9688 (70788.6152, 132772.3594)  train/nll_loss: 9571.3115 (13049.2084, 7930.1787)  train/rec_loss: 0.0415 (0.0566, 0.0344)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0189)
2025-02-06 16:57:48,919 train INFO: [4740/46609/10000]  lr: 9.782180262270797e-05  eta: 0:11:07  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0179)  train/logits_fake: 0.0190 (0.0192, 0.0178)  train/total_loss: 9308.2979 (13028.9968, 7955.6558)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 108959.5156 (70926.8793, 124205.6328)  train/nll_loss: 9308.1934 (13028.9258, 7955.5317)  train/rec_loss: 0.0404 (0.0565, 0.0345)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0192, -0.0178)
2025-02-06 16:57:51,459 train INFO: [4760/46609/10000]  lr: 9.78035160120066e-05  eta: 0:11:04  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0193)  train/logits_fake: 0.0189 (0.0192, 0.0198)  train/total_loss: 9011.7588 (13010.1480, 9546.4033)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 108946.7344 (71086.2511, 110348.9609)  train/nll_loss: 9011.6641 (13010.0769, 9546.2930)  train/rec_loss: 0.0391 (0.0565, 0.0414)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0192, -0.0198)
2025-02-06 16:57:53,995 train INFO: [4780/46609/10000]  lr: 9.77851547025967e-05  eta: 0:11:02  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0200)  train/logits_fake: 0.0189 (0.0192, 0.0184)  train/total_loss: 8719.5029 (12995.4414, 9782.8193)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 105924.5234 (71245.8278, 110818.3594)  train/nll_loss: 8719.3906 (12995.3702, 9782.7090)  train/rec_loss: 0.0378 (0.0564, 0.0425)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0192, -0.0184)
2025-02-06 16:57:56,529 train INFO: [4800/46609/10000]  lr: 9.776671872347327e-05  eta: 0:10:59  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0189)  train/logits_fake: 0.0190 (0.0192, 0.0192)  train/total_loss: 8411.0820 (12974.6803, 5429.3335)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 107289.7266 (71389.6232, 85141.7656)  train/nll_loss: 8410.9961 (12974.6089, 5429.2485)  train/rec_loss: 0.0365 (0.0563, 0.0236)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0192, -0.0192)
2025-02-06 16:57:59,060 train INFO: [4820/46609/10000]  lr: 9.774820810374925e-05  eta: 0:10:57  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0160)  train/logits_fake: 0.0191 (0.0192, 0.0166)  train/total_loss: 8319.8252 (12953.1049, 9194.4277)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 105924.5234 (71536.3079, 127191.1641)  train/nll_loss: 8319.7246 (12953.0334, 9194.3008)  train/rec_loss: 0.0361 (0.0562, 0.0399)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0166)
2025-02-06 16:58:01,588 train INFO: [4840/46609/10000]  lr: 9.77296228726554e-05  eta: 0:10:54  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0197)  train/logits_fake: 0.0191 (0.0192, 0.0197)  train/total_loss: 8324.9355 (12931.1788, 7718.3096)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 105720.0625 (71675.0081, 99678.2422)  train/nll_loss: 8324.8262 (12931.1071, 7718.2100)  train/rec_loss: 0.0361 (0.0561, 0.0335)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0197)
2025-02-06 16:58:04,114 train INFO: [4860/46609/10000]  lr: 9.771096305954038e-05  eta: 0:10:52  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0180)  train/logits_fake: 0.0191 (0.0192, 0.0181)  train/total_loss: 8227.8770 (12911.3727, 5922.5776)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 105720.0625 (71813.4702, 89797.3828)  train/nll_loss: 8227.7734 (12911.3009, 5922.4878)  train/rec_loss: 0.0357 (0.0560, 0.0257)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0181)
2025-02-06 16:58:06,639 train INFO: [4880/46609/10000]  lr: 9.769222869387056e-05  eta: 0:10:49  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0204)  train/logits_fake: 0.0192 (0.0192, 0.0208)  train/total_loss: 7981.9673 (12892.3287, 6207.7251)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 108037.5469 (71992.5100, 86810.4688)  train/nll_loss: 7981.8750 (12892.2568, 6207.6382)  train/rec_loss: 0.0346 (0.0560, 0.0269)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0208)
2025-02-06 16:58:09,164 train INFO: [4900/46609/10000]  lr: 9.767341980523007e-05  eta: 0:10:47  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0200)  train/logits_fake: 0.0193 (0.0192, 0.0208)  train/total_loss: 8256.4570 (12876.2976, 11653.4502)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 106905.3125 (72117.8173, 116219.5938)  train/nll_loss: 8256.3281 (12876.2255, 11653.3340)  train/rec_loss: 0.0358 (0.0559, 0.0506)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0208)
2025-02-06 16:58:11,690 train INFO: [4920/46609/10000]  lr: 9.765453642332069e-05  eta: 0:10:44  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0183)  train/logits_fake: 0.0193 (0.0192, 0.0180)  train/total_loss: 8311.3750 (12861.3809, 8295.1514)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 108800.8828 (72277.8827, 99002.9766)  train/nll_loss: 8311.3076 (12861.3086, 8295.0527)  train/rec_loss: 0.0361 (0.0558, 0.0360)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0180)
2025-02-06 16:58:14,219 train INFO: [4940/46609/10000]  lr: 9.763557857796189e-05  eta: 0:10:41  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0183)  train/logits_fake: 0.0193 (0.0192, 0.0193)  train/total_loss: 8379.4033 (12842.9736, 9237.4746)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 109881.0156 (72423.3583, 86043.7969)  train/nll_loss: 8379.2998 (12842.9012, 9237.3887)  train/rec_loss: 0.0364 (0.0557, 0.0401)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0193)
2025-02-06 16:58:16,748 train INFO: [4960/46609/10000]  lr: 9.761654629909068e-05  eta: 0:10:39  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0194)  train/logits_fake: 0.0193 (0.0192, 0.0202)  train/total_loss: 8478.9033 (12826.9267, 7708.3979)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 111069.8125 (72585.7155, 84659.6328)  train/nll_loss: 8478.7773 (12826.8542, 7708.3135)  train/rec_loss: 0.0368 (0.0557, 0.0335)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0202)
2025-02-06 16:58:19,274 train INFO: [4980/46609/10000]  lr: 9.759743961676163e-05  eta: 0:10:36  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0180)  train/logits_fake: 0.0193 (0.0192, 0.0185)  train/total_loss: 8342.6289 (12806.9490, 9930.3447)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 109232.7422 (72714.6768, 107602.6406)  train/nll_loss: 8342.5020 (12806.8763, 9930.2373)  train/rec_loss: 0.0362 (0.0556, 0.0431)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0185)
2025-02-06 16:58:21,813 train INFO: [5000/46609/10000]  lr: 9.757825856114678e-05  eta: 0:10:34  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0203)  train/logits_fake: 0.0193 (0.0192, 0.0201)  train/total_loss: 8351.0254 (12790.1340, 6391.8789)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 109881.0156 (72856.3219, 87062.1875)  train/nll_loss: 8350.9131 (12790.0611, 6391.7920)  train/rec_loss: 0.0362 (0.0555, 0.0277)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0201)
2025-02-06 16:58:24,342 train INFO: [5020/46609/10000]  lr: 9.755900316253567e-05  eta: 0:10:31  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0191)  train/logits_fake: 0.0192 (0.0192, 0.0175)  train/total_loss: 8212.4238 (12772.0049, 10882.1758)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 108095.6172 (73001.8192, 117134.1875)  train/nll_loss: 8212.3262 (12771.9319, 10882.0586)  train/rec_loss: 0.0356 (0.0554, 0.0472)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0175)
2025-02-06 16:58:26,872 train INFO: [5040/46609/10000]  lr: 9.753967345133516e-05  eta: 0:10:29  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0200)  train/logits_fake: 0.0193 (0.0192, 0.0186)  train/total_loss: 8217.8184 (12754.7494, 9584.1973)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 109161.6719 (73159.4279, 127108.4609)  train/nll_loss: 8217.6973 (12754.6762, 9584.0703)  train/rec_loss: 0.0357 (0.0554, 0.0416)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0186)
2025-02-06 16:58:29,397 train INFO: [5060/46609/10000]  lr: 9.752026945806955e-05  eta: 0:10:26  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0174)  train/logits_fake: 0.0192 (0.0192, 0.0198)  train/total_loss: 8033.5679 (12736.2406, 15035.8945)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 107602.6406 (73283.8099, 88993.9062)  train/nll_loss: 8033.4531 (12736.1674, 15035.8057)  train/rec_loss: 0.0349 (0.0553, 0.0653)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0198)
2025-02-06 16:58:31,929 train INFO: [5080/46609/10000]  lr: 9.750079121338035e-05  eta: 0:10:24  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0205)  train/logits_fake: 0.0193 (0.0192, 0.0204)  train/total_loss: 8225.7305 (12719.6615, 7252.2681)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 109055.6406 (73420.2592, 94981.1406)  train/nll_loss: 8225.6113 (12719.5881, 7252.1729)  train/rec_loss: 0.0357 (0.0552, 0.0315)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0204)
2025-02-06 16:58:34,461 train INFO: [5100/46609/10000]  lr: 9.748123874802639e-05  eta: 0:10:21  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0207)  train/logits_fake: 0.0193 (0.0192, 0.0202)  train/total_loss: 8033.5679 (12701.4083, 8625.8496)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 111934.7969 (73589.2666, 109451.4375)  train/nll_loss: 8033.4531 (12701.3347, 8625.7402)  train/rec_loss: 0.0349 (0.0551, 0.0374)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0202)
2025-02-06 16:58:36,988 train INFO: [5120/46609/10000]  lr: 9.746161209288368e-05  eta: 0:10:19  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0190)  train/logits_fake: 0.0193 (0.0192, 0.0194)  train/total_loss: 8041.8286 (12682.9008, 6956.2563)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 112607.9453 (73745.1365, 102687.3672)  train/nll_loss: 8041.7051 (12682.8271, 6956.1538)  train/rec_loss: 0.0349 (0.0550, 0.0302)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0194)
2025-02-06 16:58:39,513 train INFO: [5140/46609/10000]  lr: 9.74419112789454e-05  eta: 0:10:16  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0182)  train/logits_fake: 0.0193 (0.0192, 0.0177)  train/total_loss: 7953.5322 (12667.0058, 12808.7031)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 109451.4375 (73880.5704, 105373.2344)  train/nll_loss: 7953.4019 (12666.9319, 12808.5977)  train/rec_loss: 0.0345 (0.0550, 0.0556)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0177)
2025-02-06 16:58:42,043 train INFO: [5160/46609/10000]  lr: 9.742213633732179e-05  eta: 0:10:13  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0184)  train/logits_fake: 0.0194 (0.0192, 0.0199)  train/total_loss: 8191.6128 (12650.1878, 10623.8711)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 111150.4844 (74025.4517, 88060.1875)  train/nll_loss: 8191.4697 (12650.1137, 10623.7832)  train/rec_loss: 0.0356 (0.0549, 0.0461)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0199)
2025-02-06 16:58:44,579 train INFO: [5180/46609/10000]  lr: 9.740228729924023e-05  eta: 0:10:11  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0200)  train/logits_fake: 0.0192 (0.0192, 0.0201)  train/total_loss: 7955.5264 (12633.9288, 10862.8662)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 110662.4219 (74152.3798, 125313.1406)  train/nll_loss: 7955.4375 (12633.8547, 10862.7412)  train/rec_loss: 0.0345 (0.0548, 0.0471)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0201)
2025-02-06 16:58:47,117 train INFO: [5200/46609/10000]  lr: 9.7382364196045e-05  eta: 0:10:08  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0189)  train/logits_fake: 0.0192 (0.0192, 0.0188)  train/total_loss: 8041.8286 (12615.8815, 8490.7764)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 108596.8750 (74293.6577, 131203.3594)  train/nll_loss: 8041.7051 (12615.8072, 8490.6455)  train/rec_loss: 0.0349 (0.0548, 0.0369)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0188)
2025-02-06 16:58:49,652 train INFO: [5220/46609/10000]  lr: 9.736236705919744e-05  eta: 0:10:06  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0211)  train/logits_fake: 0.0192 (0.0192, 0.0217)  train/total_loss: 8081.5215 (12599.8471, 8356.4688)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 107793.3281 (74429.3451, 81073.2500)  train/nll_loss: 8081.4009 (12599.7727, 8356.3877)  train/rec_loss: 0.0351 (0.0547, 0.0363)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0217)
2025-02-06 16:58:52,179 train INFO: [5240/46609/10000]  lr: 9.734229592027576e-05  eta: 0:10:03  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0189)  train/logits_fake: 0.0193 (0.0192, 0.0193)  train/total_loss: 8105.4136 (12584.9194, 7549.9023)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 108596.8750 (74557.5112, 106678.0312)  train/nll_loss: 8105.3276 (12584.8448, 7549.7959)  train/rec_loss: 0.0352 (0.0546, 0.0328)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0193)
2025-02-06 16:58:54,708 train INFO: [5260/46609/10000]  lr: 9.732215081097501e-05  eta: 0:10:01  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0210)  train/logits_fake: 0.0194 (0.0192, 0.0206)  train/total_loss: 7955.5264 (12567.0870, 7704.8354)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 107638.8438 (74688.6475, 106849.2188)  train/nll_loss: 7955.4375 (12567.0123, 7704.7285)  train/rec_loss: 0.0345 (0.0545, 0.0334)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0206)
2025-02-06 16:58:57,241 train INFO: [5280/46609/10000]  lr: 9.73019317631071e-05  eta: 0:09:58  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0194 (0.0191, 0.0190)  train/logits_fake: 0.0194 (0.0192, 0.0192)  train/total_loss: 7888.1470 (12548.3086, 6430.9629)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 107638.8438 (74814.1920, 88996.3594)  train/nll_loss: 7888.0352 (12548.2338, 6430.8740)  train/rec_loss: 0.0342 (0.0545, 0.0279)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0192)
2025-02-06 16:58:59,775 train INFO: [5300/46609/10000]  lr: 9.728163880860061e-05  eta: 0:09:56  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0195 (0.0191, 0.0173)  train/logits_fake: 0.0195 (0.0192, 0.0186)  train/total_loss: 7777.1416 (12529.6148, 10096.9658)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 108897.0391 (74958.1753, 104836.3125)  train/nll_loss: 7777.0239 (12529.5398, 10096.8613)  train/rec_loss: 0.0338 (0.0544, 0.0438)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0186)
2025-02-06 16:59:02,309 train INFO: [5320/46609/10000]  lr: 9.726127197950094e-05  eta: 0:09:53  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0194 (0.0191, 0.0178)  train/logits_fake: 0.0195 (0.0192, 0.0181)  train/total_loss: 7746.2241 (12513.4487, 6750.3066)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 109880.9453 (75100.6192, 115078.8594)  train/nll_loss: 7746.1279 (12513.3736, 6750.1914)  train/rec_loss: 0.0336 (0.0543, 0.0293)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0181)
2025-02-06 16:59:04,848 train INFO: [5340/46609/10000]  lr: 9.724083130797005e-05  eta: 0:09:51  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0192)  train/logits_fake: 0.0195 (0.0192, 0.0183)  train/total_loss: 7592.4424 (12495.3730, 8202.6123)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 109880.9453 (75220.8914, 120525.7188)  train/nll_loss: 7592.3218 (12495.2978, 8202.4922)  train/rec_loss: 0.0330 (0.0542, 0.0356)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0183)
2025-02-06 16:59:07,384 train INFO: [5360/46609/10000]  lr: 9.722031682628658e-05  eta: 0:09:48  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0187)  train/logits_fake: 0.0194 (0.0192, 0.0179)  train/total_loss: 7740.1875 (12478.3544, 6768.9658)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 110321.3594 (75367.1845, 136697.8906)  train/nll_loss: 7740.0684 (12478.2790, 6768.8291)  train/rec_loss: 0.0336 (0.0542, 0.0294)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0179)
2025-02-06 16:59:09,916 train INFO: [5380/46609/10000]  lr: 9.71997285668457e-05  eta: 0:09:46  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0185)  train/logits_fake: 0.0194 (0.0192, 0.0195)  train/total_loss: 7805.9648 (12463.3069, 9791.9424)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 110070.8828 (75497.0322, 107953.3594)  train/nll_loss: 7805.8359 (12463.2314, 9791.8340)  train/rec_loss: 0.0339 (0.0541, 0.0425)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0195)
2025-02-06 16:59:12,449 train INFO: [5400/46609/10000]  lr: 9.717906656215905e-05  eta: 0:09:43  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0209)  train/logits_fake: 0.0193 (0.0192, 0.0206)  train/total_loss: 7820.7559 (12447.2983, 7222.2168)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 110282.8516 (75641.4665, 93581.1250)  train/nll_loss: 7820.6387 (12447.2226, 7222.1230)  train/rec_loss: 0.0339 (0.0540, 0.0313)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0206)
2025-02-06 16:59:14,977 train INFO: [5420/46609/10000]  lr: 9.715833084485479e-05  eta: 0:09:40  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0201)  train/logits_fake: 0.0193 (0.0192, 0.0205)  train/total_loss: 7752.4658 (12430.4256, 5594.6597)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 110703.7656 (75784.6812, 83417.6562)  train/nll_loss: 7752.3569 (12430.3499, 5594.5762)  train/rec_loss: 0.0336 (0.0540, 0.0243)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0205)
2025-02-06 16:59:17,506 train INFO: [5440/46609/10000]  lr: 9.713752144767742e-05  eta: 0:09:38  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0213)  train/logits_fake: 0.0191 (0.0192, 0.0205)  train/total_loss: 7846.8901 (12414.1874, 7478.5459)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 113388.4766 (75928.5793, 107529.6719)  train/nll_loss: 7846.7954 (12414.1115, 7478.4385)  train/rec_loss: 0.0341 (0.0539, 0.0325)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0205)
2025-02-06 16:59:20,035 train INFO: [5460/46609/10000]  lr: 9.711663840348785e-05  eta: 0:09:35  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0192)  train/logits_fake: 0.0192 (0.0192, 0.0192)  train/total_loss: 7820.7559 (12396.5941, 6637.4170)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 110826.5703 (76040.9771, 82462.8125)  train/nll_loss: 7820.6387 (12396.5181, 6637.3345)  train/rec_loss: 0.0339 (0.0538, 0.0288)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0192)
2025-02-06 16:59:22,564 train INFO: [5480/46609/10000]  lr: 9.709568174526323e-05  eta: 0:09:33  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0205)  train/logits_fake: 0.0194 (0.0192, 0.0208)  train/total_loss: 7752.4658 (12379.8797, 8833.2910)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 110851.7188 (76164.8386, 115801.5781)  train/nll_loss: 7752.3569 (12379.8035, 8833.1748)  train/rec_loss: 0.0336 (0.0537, 0.0383)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0208)
2025-02-06 16:59:25,092 train INFO: [5500/46609/10000]  lr: 9.7074651506097e-05  eta: 0:09:30  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0196)  train/logits_fake: 0.0192 (0.0192, 0.0200)  train/total_loss: 7846.8901 (12363.4740, 5282.3633)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 110851.7188 (76298.1847, 83921.5547)  train/nll_loss: 7846.7954 (12363.3977, 5282.2793)  train/rec_loss: 0.0341 (0.0537, 0.0229)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0200)
2025-02-06 16:59:27,621 train INFO: [5520/46609/10000]  lr: 9.705354771919877e-05  eta: 0:09:28  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0185)  train/logits_fake: 0.0192 (0.0192, 0.0185)  train/total_loss: 7832.2256 (12347.6698, 6494.6665)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 111649.3125 (76452.0604, 125575.1875)  train/nll_loss: 7832.1289 (12347.5933, 6494.5410)  train/rec_loss: 0.0340 (0.0536, 0.0282)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0185)
2025-02-06 16:59:30,157 train INFO: [5540/46609/10000]  lr: 9.703237041789428e-05  eta: 0:09:25  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0183)  train/logits_fake: 0.0192 (0.0192, 0.0185)  train/total_loss: 7686.2563 (12331.9000, 7975.2612)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 110928.5859 (76580.1482, 109916.0625)  train/nll_loss: 7686.1162 (12331.8234, 7975.1514)  train/rec_loss: 0.0334 (0.0535, 0.0346)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0185)
2025-02-06 16:59:32,692 train INFO: [5560/46609/10000]  lr: 9.701111963562542e-05  eta: 0:09:23  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0198)  train/logits_fake: 0.0191 (0.0192, 0.0197)  train/total_loss: 7876.2798 (12315.8260, 9213.5527)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 112149.2734 (76706.4907, 102607.1250)  train/nll_loss: 7876.1782 (12315.7493, 9213.4502)  train/rec_loss: 0.0342 (0.0535, 0.0400)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0197)
2025-02-06 16:59:35,221 train INFO: [5580/46609/10000]  lr: 9.698979540595005e-05  eta: 0:09:20  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0188 (0.0191, 0.0192)  train/logits_fake: 0.0192 (0.0192, 0.0195)  train/total_loss: 7706.0146 (12300.4455, 10374.9072)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 113152.3984 (76832.0162, 101568.7109)  train/nll_loss: 7705.8989 (12300.3687, 10374.8057)  train/rec_loss: 0.0334 (0.0534, 0.0450)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0195)
2025-02-06 16:59:37,749 train INFO: [5600/46609/10000]  lr: 9.696839776254204e-05  eta: 0:09:18  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0189)  train/logits_fake: 0.0192 (0.0192, 0.0202)  train/total_loss: 7900.1885 (12288.3270, 10491.7588)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 110928.5859 (76953.5629, 126228.0781)  train/nll_loss: 7900.0947 (12288.2500, 10491.6328)  train/rec_loss: 0.0343 (0.0533, 0.0455)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0202)
2025-02-06 16:59:40,279 train INFO: [5620/46609/10000]  lr: 9.694692673919121e-05  eta: 0:09:15  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0199)  train/logits_fake: 0.0192 (0.0192, 0.0217)  train/total_loss: 7975.2612 (12274.8206, 9011.2842)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 110286.7734 (77084.8021, 127515.4531)  train/nll_loss: 7975.1514 (12274.7435, 9011.1562)  train/rec_loss: 0.0346 (0.0533, 0.0391)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0217)
2025-02-06 16:59:42,810 train INFO: [5640/46609/10000]  lr: 9.69253823698032e-05  eta: 0:09:12  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0197)  train/logits_fake: 0.0192 (0.0192, 0.0206)  train/total_loss: 8099.2500 (12261.5543, 8099.2500)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 110336.9219 (77215.6170, 104682.8672)  train/nll_loss: 8099.1455 (12261.4771, 8099.1455)  train/rec_loss: 0.0352 (0.0532, 0.0352)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0206)
2025-02-06 16:59:45,340 train INFO: [5660/46609/10000]  lr: 9.690376468839956e-05  eta: 0:09:10  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0210)  train/logits_fake: 0.0193 (0.0192, 0.0214)  train/total_loss: 8025.6719 (12247.0804, 6057.8525)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 110286.7734 (77336.3500, 117640.3281)  train/nll_loss: 8025.5635 (12247.0030, 6057.7349)  train/rec_loss: 0.0348 (0.0532, 0.0263)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0214)
2025-02-06 16:59:47,865 train INFO: [5680/46609/10000]  lr: 9.688207372911751e-05  eta: 0:09:07  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0201)  train/logits_fake: 0.0192 (0.0192, 0.0186)  train/total_loss: 8212.1035 (12233.1339, 9308.4336)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 110816.5781 (77482.8645, 116906.4219)  train/nll_loss: 8211.9590 (12233.0564, 9308.3164)  train/rec_loss: 0.0356 (0.0531, 0.0404)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0186)
2025-02-06 16:59:50,397 train INFO: [5700/46609/10000]  lr: 9.686030952621007e-05  eta: 0:09:05  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0201)  train/logits_fake: 0.0191 (0.0192, 0.0205)  train/total_loss: 7938.2217 (12216.9316, 7326.2578)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 114769.2734 (77628.1569, 106181.2422)  train/nll_loss: 7938.0981 (12216.8540, 7326.1519)  train/rec_loss: 0.0345 (0.0530, 0.0318)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0205)
2025-02-06 16:59:52,935 train INFO: [5720/46609/10000]  lr: 9.683847211404587e-05  eta: 0:09:02  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0187)  train/logits_fake: 0.0190 (0.0192, 0.0172)  train/total_loss: 7938.2217 (12203.5934, 9607.1777)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 116505.9062 (77760.0809, 115110.9844)  train/nll_loss: 7938.0981 (12203.5156, 9607.0625)  train/rec_loss: 0.0345 (0.0530, 0.0417)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0192, -0.0172)
2025-02-06 16:59:55,470 train INFO: [5740/46609/10000]  lr: 9.681656152710917e-05  eta: 0:09:00  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0184)  train/logits_fake: 0.0190 (0.0192, 0.0179)  train/total_loss: 7838.0635 (12187.7130, 5953.6475)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 115110.9844 (77886.1865, 110473.7500)  train/nll_loss: 7837.9209 (12187.6351, 5953.5371)  train/rec_loss: 0.0340 (0.0529, 0.0258)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0179)
2025-02-06 16:59:58,006 train INFO: [5760/46609/10000]  lr: 9.679457779999978e-05  eta: 0:08:57  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0197)  train/logits_fake: 0.0190 (0.0192, 0.0193)  train/total_loss: 7918.1172 (12172.7117, 5421.6445)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 115991.2500 (78029.3415, 112403.5703)  train/nll_loss: 7918.0254 (12172.6337, 5421.5322)  train/rec_loss: 0.0344 (0.0528, 0.0235)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0192, -0.0193)
2025-02-06 17:00:00,543 train INFO: [5780/46609/10000]  lr: 9.677252096743299e-05  eta: 0:08:55  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0199)  train/logits_fake: 0.0190 (0.0192, 0.0193)  train/total_loss: 7643.3252 (12155.2931, 5843.7871)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 112403.5703 (78136.0277, 106541.3125)  train/nll_loss: 7643.2305 (12155.2150, 5843.6807)  train/rec_loss: 0.0332 (0.0528, 0.0254)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0193)
2025-02-06 17:00:03,070 train INFO: [5800/46609/10000]  lr: 9.675039106423956e-05  eta: 0:08:52  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0180)  train/logits_fake: 0.0192 (0.0192, 0.0184)  train/total_loss: 7593.0503 (12140.4405, 6631.6147)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 111309.5859 (78271.6522, 116701.1406)  train/nll_loss: 7592.9473 (12140.3623, 6631.4980)  train/rec_loss: 0.0330 (0.0527, 0.0288)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0184)
2025-02-06 17:00:05,595 train INFO: [5820/46609/10000]  lr: 9.672818812536565e-05  eta: 0:08:50  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0204)  train/logits_fake: 0.0193 (0.0192, 0.0205)  train/total_loss: 7643.3252 (12129.1871, 10417.8838)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 110939.5547 (78390.2654, 116468.0312)  train/nll_loss: 7643.2305 (12129.1087, 10417.7676)  train/rec_loss: 0.0332 (0.0526, 0.0452)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0205)
2025-02-06 17:00:08,120 train INFO: [5840/46609/10000]  lr: 9.670591218587268e-05  eta: 0:08:47  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0180)  train/logits_fake: 0.0192 (0.0192, 0.0187)  train/total_loss: 7736.9058 (12116.0610, 11883.5186)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 110939.5547 (78512.8131, 112629.0469)  train/nll_loss: 7736.7832 (12115.9824, 11883.4062)  train/rec_loss: 0.0336 (0.0526, 0.0516)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0187)
2025-02-06 17:00:10,646 train INFO: [5860/46609/10000]  lr: 9.668356328093746e-05  eta: 0:08:45  iter_time: 0.126  data: 0.001  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0196)  train/logits_fake: 0.0192 (0.0192, 0.0187)  train/total_loss: 7650.5381 (12102.2457, 8140.7031)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 111448.7656 (78659.0256, 108510.6875)  train/nll_loss: 7650.4219 (12102.1671, 8140.5947)  train/rec_loss: 0.0332 (0.0525, 0.0353)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0187)
2025-02-06 17:00:13,175 train INFO: [5880/46609/10000]  lr: 9.666114144585191e-05  eta: 0:08:42  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0192)  train/logits_fake: 0.0192 (0.0192, 0.0187)  train/total_loss: 8048.6650 (12089.5401, 8663.6025)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 116198.7266 (78800.8386, 118576.1406)  train/nll_loss: 8048.5176 (12089.4613, 8663.4844)  train/rec_loss: 0.0349 (0.0525, 0.0376)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0187)
2025-02-06 17:00:15,701 train INFO: [5900/46609/10000]  lr: 9.663864671602321e-05  eta: 0:08:39  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0193)  train/logits_fake: 0.0192 (0.0192, 0.0190)  train/total_loss: 8145.2358 (12076.4598, 5806.0435)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 115824.1094 (78927.5063, 115824.1094)  train/nll_loss: 8145.1069 (12076.3809, 5805.9277)  train/rec_loss: 0.0354 (0.0524, 0.0252)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0190)
2025-02-06 17:00:18,226 train INFO: [5920/46609/10000]  lr: 9.661607912697357e-05  eta: 0:08:37  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0178)  train/logits_fake: 0.0191 (0.0192, 0.0168)  train/total_loss: 7998.0786 (12062.2626, 8762.5527)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 116446.6562 (79063.1094, 129392.7891)  train/nll_loss: 7997.9697 (12062.1836, 8762.4238)  train/rec_loss: 0.0347 (0.0524, 0.0380)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0168)
2025-02-06 17:00:20,761 train INFO: [5940/46609/10000]  lr: 9.65934387143403e-05  eta: 0:08:34  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0173)  train/logits_fake: 0.0191 (0.0192, 0.0186)  train/total_loss: 8045.9375 (12051.7213, 7881.4512)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 118464.1562 (79195.9024, 146058.4375)  train/nll_loss: 8045.8164 (12051.6421, 7881.3052)  train/rec_loss: 0.0349 (0.0523, 0.0342)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0186)
2025-02-06 17:00:23,295 train INFO: [5960/46609/10000]  lr: 9.657072551387573e-05  eta: 0:08:32  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0214)  train/logits_fake: 0.0192 (0.0192, 0.0216)  train/total_loss: 7962.7808 (12037.2085, 10750.7842)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 117348.2891 (79315.2236, 112770.4062)  train/nll_loss: 7962.6812 (12037.1291, 10750.6719)  train/rec_loss: 0.0346 (0.0522, 0.0467)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0216)
2025-02-06 17:00:25,814 train INFO: [5980/46609/10000]  lr: 9.65479395614471e-05  eta: 0:08:29  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0192)  train/logits_fake: 0.0192 (0.0192, 0.0194)  train/total_loss: 7914.5317 (12025.1543, 7656.0054)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 118285.8984 (79464.4649, 134098.4531)  train/nll_loss: 7914.4131 (12025.0748, 7655.8711)  train/rec_loss: 0.0344 (0.0522, 0.0332)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0194)
2025-02-06 17:00:28,335 train INFO: [6000/46609/10000]  lr: 9.65250808930365e-05  eta: 0:08:27  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0186)  train/logits_fake: 0.0192 (0.0192, 0.0189)  train/total_loss: 7748.0513 (12010.4943, 7160.1221)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 117140.7344 (79577.6231, 107873.4062)  train/nll_loss: 7747.9409 (12010.4148, 7160.0142)  train/rec_loss: 0.0336 (0.0521, 0.0311)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0189)
2025-02-06 17:00:30,866 train INFO: [6020/46609/10000]  lr: 9.650214954474094e-05  eta: 0:08:24  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0186)  train/logits_fake: 0.0194 (0.0192, 0.0195)  train/total_loss: 7580.2236 (11995.9286, 10532.4346)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 116352.6562 (79694.5261, 116674.6250)  train/nll_loss: 7580.1270 (11995.8489, 10532.3184)  train/rec_loss: 0.0329 (0.0521, 0.0457)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0195)
2025-02-06 17:00:33,398 train INFO: [6040/46609/10000]  lr: 9.647914555277209e-05  eta: 0:08:22  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0182)  train/logits_fake: 0.0194 (0.0192, 0.0191)  train/total_loss: 7687.5767 (11986.4410, 11099.9492)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 116674.6250 (79832.7680, 121156.1094)  train/nll_loss: 7687.4531 (11986.3612, 11099.8281)  train/rec_loss: 0.0334 (0.0520, 0.0482)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0191)
2025-02-06 17:00:35,927 train INFO: [6060/46609/10000]  lr: 9.645606895345646e-05  eta: 0:08:19  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0201)  train/logits_fake: 0.0193 (0.0192, 0.0197)  train/total_loss: 7656.0054 (11972.5944, 6891.2949)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 119481.6875 (79973.6582, 119930.5156)  train/nll_loss: 7655.8711 (11972.5144, 6891.1748)  train/rec_loss: 0.0332 (0.0520, 0.0299)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0197)
2025-02-06 17:00:38,455 train INFO: [6080/46609/10000]  lr: 9.643291978323509e-05  eta: 0:08:17  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0212)  train/logits_fake: 0.0193 (0.0192, 0.0206)  train/total_loss: 7815.7388 (11963.0509, 7798.6650)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 119216.8906 (80104.5548, 106382.4375)  train/nll_loss: 7815.6284 (11962.9708, 7798.5586)  train/rec_loss: 0.0339 (0.0519, 0.0338)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0206)
2025-02-06 17:00:40,982 train INFO: [6100/46609/10000]  lr: 9.64096980786637e-05  eta: 0:08:14  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0194)  train/logits_fake: 0.0193 (0.0192, 0.0198)  train/total_loss: 7911.7217 (11950.6925, 10442.4033)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 119930.5156 (80234.7713, 98327.8359)  train/nll_loss: 7911.6069 (11950.6123, 10442.3047)  train/rec_loss: 0.0343 (0.0519, 0.0453)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0198)
2025-02-06 17:00:43,507 train INFO: [6120/46609/10000]  lr: 9.638640387641256e-05  eta: 0:08:11  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0184)  train/logits_fake: 0.0193 (0.0192, 0.0182)  train/total_loss: 7949.8955 (11937.8434, 6713.7349)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 122020.8906 (80375.7257, 144245.9062)  train/nll_loss: 7949.7920 (11937.7630, 6713.5908)  train/rec_loss: 0.0345 (0.0518, 0.0291)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0182)
2025-02-06 17:00:46,033 train INFO: [6140/46609/10000]  lr: 9.636303721326636e-05  eta: 0:08:09  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0209)  train/logits_fake: 0.0191 (0.0192, 0.0213)  train/total_loss: 7949.8955 (11925.4073, 10371.2285)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 121045.2734 (80500.3050, 118391.8828)  train/nll_loss: 7949.7920 (11925.3268, 10371.1104)  train/rec_loss: 0.0345 (0.0518, 0.0450)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0213)
2025-02-06 17:00:48,561 train INFO: [6160/46609/10000]  lr: 9.633959812612427e-05  eta: 0:08:06  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0189)  train/logits_fake: 0.0191 (0.0192, 0.0189)  train/total_loss: 8162.6299 (11915.6793, 8708.7314)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 120335.0938 (80633.8744, 105852.2891)  train/nll_loss: 8162.5005 (11915.5987, 8708.6260)  train/rec_loss: 0.0354 (0.0517, 0.0378)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0189)
2025-02-06 17:00:51,083 train INFO: [6180/46609/10000]  lr: 9.631608665199979e-05  eta: 0:08:04  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0193)  train/logits_fake: 0.0192 (0.0192, 0.0194)  train/total_loss: 8146.9946 (11904.2184, 5801.2695)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 121762.7188 (80771.5111, 116066.9297)  train/nll_loss: 8146.8564 (11904.1377, 5801.1533)  train/rec_loss: 0.0354 (0.0517, 0.0252)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0194)
2025-02-06 17:00:53,607 train INFO: [6200/46609/10000]  lr: 9.629250282802076e-05  eta: 0:08:01  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0156)  train/logits_fake: 0.0192 (0.0192, 0.0164)  train/total_loss: 8162.6299 (11890.9326, 8518.8018)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 121762.7188 (80889.1247, 139815.4688)  train/nll_loss: 8162.5005 (11890.8517, 8518.6621)  train/rec_loss: 0.0354 (0.0516, 0.0370)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0164)
2025-02-06 17:00:56,139 train INFO: [6220/46609/10000]  lr: 9.626884669142927e-05  eta: 0:07:59  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0181)  train/logits_fake: 0.0192 (0.0192, 0.0180)  train/total_loss: 8221.7734 (11878.9559, 9186.4551)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 119794.0000 (81024.8166, 138388.2656)  train/nll_loss: 8221.6709 (11878.8749, 9186.3164)  train/rec_loss: 0.0357 (0.0516, 0.0399)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0180)
2025-02-06 17:00:58,668 train INFO: [6240/46609/10000]  lr: 9.624511827958155e-05  eta: 0:07:56  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0187)  train/logits_fake: 0.0193 (0.0192, 0.0187)  train/total_loss: 8388.4512 (11869.1796, 8639.8555)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 118763.1406 (81137.9278, 101786.8281)  train/nll_loss: 8388.3281 (11869.0984, 8639.7539)  train/rec_loss: 0.0364 (0.0515, 0.0375)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0187)
2025-02-06 17:01:01,203 train INFO: [6260/46609/10000]  lr: 9.622131762994803e-05  eta: 0:07:54  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0167)  train/logits_fake: 0.0194 (0.0192, 0.0173)  train/total_loss: 8347.1182 (11857.3503, 7199.6431)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 118975.9922 (81252.0001, 138980.6094)  train/nll_loss: 8346.9922 (11857.2691, 7199.5039)  train/rec_loss: 0.0362 (0.0515, 0.0312)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0173)
2025-02-06 17:01:03,744 train INFO: [6280/46609/10000]  lr: 9.619744478011319e-05  eta: 0:07:51  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0193)  train/logits_fake: 0.0192 (0.0192, 0.0194)  train/total_loss: 7906.1387 (11844.2732, 13651.8506)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 118975.9922 (81368.2431, 127506.9297)  train/nll_loss: 7906.0400 (11844.1918, 13651.7227)  train/rec_loss: 0.0343 (0.0514, 0.0593)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0194)
2025-02-06 17:01:06,282 train INFO: [6300/46609/10000]  lr: 9.617349976777549e-05  eta: 0:07:49  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0215)  train/logits_fake: 0.0192 (0.0192, 0.0209)  train/total_loss: 7851.9399 (11833.0429, 7428.8066)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 121418.8672 (81510.0909, 129111.9688)  train/nll_loss: 7851.8184 (11832.9614, 7428.6777)  train/rec_loss: 0.0341 (0.0514, 0.0322)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0209)
2025-02-06 17:01:08,820 train INFO: [6320/46609/10000]  lr: 9.61494826307474e-05  eta: 0:07:46  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0185)  train/logits_fake: 0.0192 (0.0192, 0.0200)  train/total_loss: 7923.1714 (11824.2219, 9216.0117)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 120926.7969 (81628.7738, 104447.8438)  train/nll_loss: 7923.0552 (11824.1403, 9215.9072)  train/rec_loss: 0.0344 (0.0513, 0.0400)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0200)
2025-02-06 17:01:11,361 train INFO: [6340/46609/10000]  lr: 9.612539340695525e-05  eta: 0:07:44  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0195)  train/logits_fake: 0.0192 (0.0192, 0.0196)  train/total_loss: 7609.5264 (11811.2906, 8107.1650)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 120808.1875 (81734.2071, 122039.7969)  train/nll_loss: 7609.4062 (11811.2088, 8107.0430)  train/rec_loss: 0.0330 (0.0513, 0.0352)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0196)
2025-02-06 17:01:13,892 train INFO: [6360/46609/10000]  lr: 9.61012321344392e-05  eta: 0:07:41  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0207)  train/logits_fake: 0.0191 (0.0192, 0.0195)  train/total_loss: 7634.8667 (11800.3377, 11716.2578)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 120820.7188 (81870.5269, 132947.8750)  train/nll_loss: 7634.7461 (11800.2558, 11716.1250)  train/rec_loss: 0.0331 (0.0512, 0.0509)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0195)
2025-02-06 17:01:16,425 train INFO: [6380/46609/10000]  lr: 9.607699885135321e-05  eta: 0:07:38  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0187)  train/logits_fake: 0.0192 (0.0192, 0.0195)  train/total_loss: 7609.5264 (11788.5261, 6780.4238)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 118491.2188 (81973.2552, 104416.4844)  train/nll_loss: 7609.4062 (11788.4441, 6780.3193)  train/rec_loss: 0.0330 (0.0512, 0.0294)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0195)
2025-02-06 17:01:18,955 train INFO: [6400/46609/10000]  lr: 9.605269359596496e-05  eta: 0:07:36  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0187)  train/logits_fake: 0.0192 (0.0192, 0.0196)  train/total_loss: 7609.5264 (11775.9141, 9427.2246)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 117243.8750 (82101.2943, 112933.6641)  train/nll_loss: 7609.4062 (11775.8320, 9427.1113)  train/rec_loss: 0.0330 (0.0511, 0.0409)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0196)
2025-02-06 17:01:21,485 train INFO: [6420/46609/10000]  lr: 9.602831640665573e-05  eta: 0:07:33  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0185)  train/logits_fake: 0.0193 (0.0192, 0.0180)  train/total_loss: 7605.3521 (11766.4839, 9905.6533)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 118823.8594 (82223.7958, 126328.7891)  train/nll_loss: 7605.2168 (11766.4017, 9905.5273)  train/rec_loss: 0.0330 (0.0511, 0.0430)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0180)
2025-02-06 17:01:24,031 train INFO: [6440/46609/10000]  lr: 9.600386732192043e-05  eta: 0:07:31  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0218)  train/logits_fake: 0.0192 (0.0192, 0.0206)  train/total_loss: 7858.0747 (11755.7231, 8962.8955)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 120345.5938 (82344.6394, 135535.2500)  train/nll_loss: 7857.9873 (11755.6408, 8962.7598)  train/rec_loss: 0.0341 (0.0510, 0.0389)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0206)
2025-02-06 17:01:26,567 train INFO: [6460/46609/10000]  lr: 9.597934638036753e-05  eta: 0:07:28  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0186)  train/logits_fake: 0.0193 (0.0192, 0.0183)  train/total_loss: 7822.5488 (11742.8186, 8437.9990)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 120345.5938 (82471.5631, 123885.4688)  train/nll_loss: 7822.3760 (11742.7362, 8437.8750)  train/rec_loss: 0.0340 (0.0510, 0.0366)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0183)
2025-02-06 17:01:29,098 train INFO: [6480/46609/10000]  lr: 9.595475362071893e-05  eta: 0:07:26  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0187)  train/logits_fake: 0.0193 (0.0192, 0.0183)  train/total_loss: 7953.3975 (11731.5508, 11160.4893)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 121686.3672 (82618.3402, 131660.6562)  train/nll_loss: 7953.2471 (11731.4682, 11160.3574)  train/rec_loss: 0.0345 (0.0509, 0.0484)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0183)
2025-02-06 17:01:31,632 train INFO: [6500/46609/10000]  lr: 9.593008908180993e-05  eta: 0:07:23  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0196)  train/logits_fake: 0.0193 (0.0192, 0.0194)  train/total_loss: 7879.4902 (11719.6573, 7319.5693)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 120991.4922 (82727.2795, 134166.7188)  train/nll_loss: 7879.3906 (11719.5746, 7319.4351)  train/rec_loss: 0.0342 (0.0509, 0.0318)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0194)
2025-02-06 17:01:34,169 train INFO: [6520/46609/10000]  lr: 9.590535280258926e-05  eta: 0:07:21  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0184)  train/logits_fake: 0.0191 (0.0192, 0.0191)  train/total_loss: 7665.0156 (11705.7875, 7660.5229)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 121686.3672 (82857.2705, 133096.7188)  train/nll_loss: 7664.9072 (11705.7047, 7660.3896)  train/rec_loss: 0.0333 (0.0508, 0.0332)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0191)
2025-02-06 17:01:36,705 train INFO: [6540/46609/10000]  lr: 9.588054482211884e-05  eta: 0:07:18  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0195)  train/logits_fake: 0.0191 (0.0192, 0.0196)  train/total_loss: 7660.5229 (11695.4823, 10450.0615)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 123885.4688 (82991.9871, 132713.2031)  train/nll_loss: 7660.3896 (11695.3994, 10449.9287)  train/rec_loss: 0.0332 (0.0508, 0.0454)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0196)
2025-02-06 17:01:39,239 train INFO: [6560/46609/10000]  lr: 9.585566517957387e-05  eta: 0:07:16  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0199)  train/logits_fake: 0.0192 (0.0192, 0.0210)  train/total_loss: 7660.5229 (11685.1299, 9945.5527)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 122684.6094 (83101.4985, 130658.6016)  train/nll_loss: 7660.3896 (11685.0468, 9945.4219)  train/rec_loss: 0.0332 (0.0507, 0.0432)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0210)
2025-02-06 17:01:41,773 train INFO: [6580/46609/10000]  lr: 9.583071391424269e-05  eta: 0:07:13  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0197)  train/logits_fake: 0.0192 (0.0192, 0.0197)  train/total_loss: 7509.3257 (11672.8485, 6066.4448)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 120483.8125 (83213.9738, 93715.7344)  train/nll_loss: 7509.1948 (11672.7653, 6066.3511)  train/rec_loss: 0.0326 (0.0507, 0.0263)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0197)
2025-02-06 17:01:44,304 train INFO: [6600/46609/10000]  lr: 9.580569106552677e-05  eta: 0:07:11  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0191)  train/logits_fake: 0.0192 (0.0192, 0.0192)  train/total_loss: 7565.9639 (11660.9798, 4957.0635)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 121221.1641 (83324.9259, 104951.9688)  train/nll_loss: 7565.8652 (11660.8965, 4956.9585)  train/rec_loss: 0.0328 (0.0506, 0.0215)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0192)
2025-02-06 17:01:46,838 train INFO: [6620/46609/10000]  lr: 9.578059667294058e-05  eta: 0:07:08  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0204)  train/logits_fake: 0.0193 (0.0192, 0.0195)  train/total_loss: 7728.1099 (11650.6356, 8500.9277)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 121248.7500 (83443.7227, 117392.1250)  train/nll_loss: 7727.9902 (11650.5522, 8500.8105)  train/rec_loss: 0.0335 (0.0506, 0.0369)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0195)
2025-02-06 17:01:49,380 train INFO: [6640/46609/10000]  lr: 9.575543077611162e-05  eta: 0:07:06  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0182)  train/logits_fake: 0.0193 (0.0192, 0.0184)  train/total_loss: 7642.9688 (11642.4511, 7642.9688)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 122764.0781 (83584.5537, 136731.0625)  train/nll_loss: 7642.8320 (11642.3675, 7642.8320)  train/rec_loss: 0.0332 (0.0505, 0.0332)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0184)
2025-02-06 17:01:51,918 train INFO: [6660/46609/10000]  lr: 9.573019341478025e-05  eta: 0:07:03  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0196)  train/logits_fake: 0.0194 (0.0192, 0.0200)  train/total_loss: 7757.6631 (11632.3383, 4960.9590)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 123508.4844 (83706.2629, 106364.4844)  train/nll_loss: 7757.5410 (11632.2546, 4960.8525)  train/rec_loss: 0.0337 (0.0505, 0.0215)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0200)
2025-02-06 17:01:54,454 train INFO: [6680/46609/10000]  lr: 9.570488462879973e-05  eta: 0:07:00  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0184)  train/logits_fake: 0.0193 (0.0192, 0.0180)  train/total_loss: 7901.8550 (11621.5712, 9285.5869)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 122207.0781 (83807.0310, 135301.3750)  train/nll_loss: 7901.7104 (11621.4874, 9285.4512)  train/rec_loss: 0.0343 (0.0504, 0.0403)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0180)
2025-02-06 17:01:56,986 train INFO: [6700/46609/10000]  lr: 9.567950445813609e-05  eta: 0:06:58  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0194)  train/logits_fake: 0.0193 (0.0192, 0.0199)  train/total_loss: 7723.1436 (11608.5491, 8102.2104)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 121716.6875 (83916.9141, 139001.0312)  train/nll_loss: 7723.0479 (11608.4652, 8102.0713)  train/rec_loss: 0.0335 (0.0504, 0.0352)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0199)
2025-02-06 17:01:59,517 train INFO: [6720/46609/10000]  lr: 9.565405294286806e-05  eta: 0:06:55  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0185)  train/logits_fake: 0.0193 (0.0192, 0.0190)  train/total_loss: 7688.4771 (11598.2835, 5875.2778)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 121375.3984 (84042.5729, 142242.5938)  train/nll_loss: 7688.3564 (11598.1995, 5875.1357)  train/rec_loss: 0.0334 (0.0503, 0.0255)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0190)
2025-02-06 17:02:02,054 train INFO: [6740/46609/10000]  lr: 9.562853012318705e-05  eta: 0:06:53  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0182)  train/logits_fake: 0.0192 (0.0192, 0.0196)  train/total_loss: 7688.4771 (11588.7145, 9182.5811)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 121057.0156 (84162.2349, 126795.1406)  train/nll_loss: 7688.3564 (11588.6303, 9182.4541)  train/rec_loss: 0.0334 (0.0503, 0.0399)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0196)
2025-02-06 17:02:04,587 train INFO: [6760/46609/10000]  lr: 9.560293603939711e-05  eta: 0:06:50  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0180)  train/logits_fake: 0.0191 (0.0192, 0.0186)  train/total_loss: 7448.5537 (11575.6469, 6430.3403)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 120505.4609 (84272.0275, 136291.9062)  train/nll_loss: 7448.4458 (11575.5626, 6430.2041)  train/rec_loss: 0.0323 (0.0502, 0.0279)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0186)
2025-02-06 17:02:07,126 train INFO: [6780/46609/10000]  lr: 9.557727073191479e-05  eta: 0:06:48  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0191)  train/logits_fake: 0.0192 (0.0192, 0.0210)  train/total_loss: 7347.6069 (11565.7164, 13721.5312)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 121768.1250 (84392.6956, 139374.7656)  train/nll_loss: 7347.4482 (11565.6320, 13721.3916)  train/rec_loss: 0.0319 (0.0502, 0.0596)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0210)
2025-02-06 17:02:09,656 train INFO: [6800/46609/10000]  lr: 9.555153424126908e-05  eta: 0:06:45  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0196)  train/logits_fake: 0.0192 (0.0192, 0.0187)  train/total_loss: 7330.1592 (11552.4253, 8690.1387)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 122400.8203 (84493.1366, 118056.3828)  train/nll_loss: 7330.0425 (11552.3408, 8690.0205)  train/rec_loss: 0.0318 (0.0501, 0.0377)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0187)
2025-02-06 17:02:12,186 train INFO: [6820/46609/10000]  lr: 9.552572660810145e-05  eta: 0:06:43  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0180)  train/logits_fake: 0.0193 (0.0192, 0.0184)  train/total_loss: 7182.2100 (11539.1648, 8607.6367)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 123246.2500 (84612.2590, 113051.9297)  train/nll_loss: 7182.1045 (11539.0802, 8607.5234)  train/rec_loss: 0.0312 (0.0501, 0.0374)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0184)
2025-02-06 17:02:14,719 train INFO: [6840/46609/10000]  lr: 9.549984787316565e-05  eta: 0:06:40  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0194 (0.0191, 0.0192)  train/logits_fake: 0.0193 (0.0192, 0.0197)  train/total_loss: 7062.8276 (11528.4594, 7780.2915)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 123246.2500 (84737.4397, 122334.8672)  train/nll_loss: 7062.7134 (11528.3746, 7780.1689)  train/rec_loss: 0.0307 (0.0500, 0.0338)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0197)
2025-02-06 17:02:17,257 train INFO: [6860/46609/10000]  lr: 9.547389807732774e-05  eta: 0:06:38  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0194 (0.0191, 0.0190)  train/logits_fake: 0.0193 (0.0192, 0.0196)  train/total_loss: 7089.2427 (11515.5877, 6994.5161)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 122297.7500 (84837.3261, 114549.6562)  train/nll_loss: 7089.1016 (11515.5029, 6994.4014)  train/rec_loss: 0.0308 (0.0500, 0.0304)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0196)
2025-02-06 17:02:19,792 train INFO: [6880/46609/10000]  lr: 9.5447877261566e-05  eta: 0:06:35  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0194 (0.0191, 0.0165)  train/logits_fake: 0.0193 (0.0192, 0.0170)  train/total_loss: 7330.1592 (11506.8350, 13016.6865)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 121987.4062 (84950.8844, 108495.6953)  train/nll_loss: 7330.0425 (11506.7501, 13016.5781)  train/rec_loss: 0.0318 (0.0499, 0.0565)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0170)
2025-02-06 17:02:22,332 train INFO: [6900/46609/10000]  lr: 9.542178546697084e-05  eta: 0:06:33  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0194 (0.0191, 0.0185)  train/logits_fake: 0.0194 (0.0192, 0.0189)  train/total_loss: 7491.3657 (11496.2367, 9890.5283)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 124655.2891 (85066.4186, 134498.1094)  train/nll_loss: 7491.2661 (11496.1516, 9890.3936)  train/rec_loss: 0.0325 (0.0499, 0.0429)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0189)
2025-02-06 17:02:24,869 train INFO: [6920/46609/10000]  lr: 9.539562273474476e-05  eta: 0:06:30  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0188)  train/logits_fake: 0.0193 (0.0192, 0.0187)  train/total_loss: 7729.2163 (11485.8673, 7078.4609)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 123053.8750 (85184.3425, 93199.5156)  train/nll_loss: 7729.0840 (11485.7821, 7078.3677)  train/rec_loss: 0.0335 (0.0499, 0.0307)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0187)
2025-02-06 17:02:27,405 train INFO: [6940/46609/10000]  lr: 9.53693891062023e-05  eta: 0:06:27  iter_time: 0.127  data: 0.001  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0200)  train/logits_fake: 0.0192 (0.0192, 0.0195)  train/total_loss: 7528.4614 (11471.9427, 6388.8174)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 122573.7031 (85283.6249, 136003.0156)  train/nll_loss: 7528.3291 (11471.8574, 6388.6812)  train/rec_loss: 0.0327 (0.0498, 0.0277)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0195)
2025-02-06 17:02:29,936 train INFO: [6960/46609/10000]  lr: 9.534308462276993e-05  eta: 0:06:25  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0189)  train/logits_fake: 0.0193 (0.0192, 0.0182)  train/total_loss: 7671.1470 (11460.7111, 5710.1011)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 125097.6562 (85390.7431, 124426.6094)  train/nll_loss: 7671.0576 (11460.6258, 5709.9766)  train/rec_loss: 0.0333 (0.0497, 0.0248)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0182)
2025-02-06 17:02:32,474 train INFO: [6980/46609/10000]  lr: 9.531670932598602e-05  eta: 0:06:22  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0186)  train/logits_fake: 0.0194 (0.0192, 0.0184)  train/total_loss: 7447.0078 (11448.5376, 7849.4629)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 126304.0000 (85525.7285, 163453.2969)  train/nll_loss: 7446.8823 (11448.4521, 7849.2993)  train/rec_loss: 0.0323 (0.0497, 0.0341)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0184)
2025-02-06 17:02:35,017 train INFO: [7000/46609/10000]  lr: 9.529026325750076e-05  eta: 0:06:20  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0187)  train/logits_fake: 0.0193 (0.0192, 0.0193)  train/total_loss: 7141.2085 (11436.5973, 6101.6328)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 125375.1094 (85630.0586, 120770.6875)  train/nll_loss: 7141.0684 (11436.5117, 6101.5122)  train/rec_loss: 0.0310 (0.0496, 0.0265)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0193)
2025-02-06 17:02:37,551 train INFO: [7020/46609/10000]  lr: 9.526374645907612e-05  eta: 0:06:17  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0199)  train/logits_fake: 0.0195 (0.0192, 0.0198)  train/total_loss: 7065.2935 (11425.2742, 8962.8691)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 126304.0000 (85773.7970, 124205.1094)  train/nll_loss: 7065.1875 (11425.1885, 8962.7451)  train/rec_loss: 0.0307 (0.0496, 0.0389)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0198)
2025-02-06 17:02:40,081 train INFO: [7040/46609/10000]  lr: 9.523715897258573e-05  eta: 0:06:15  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0194 (0.0191, 0.0208)  train/logits_fake: 0.0195 (0.0192, 0.0207)  train/total_loss: 7102.3872 (11413.6895, 5719.6831)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 127748.7812 (85905.4756, 123986.9844)  train/nll_loss: 7102.2539 (11413.6036, 5719.5591)  train/rec_loss: 0.0308 (0.0495, 0.0248)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0207)
2025-02-06 17:02:42,614 train INFO: [7060/46609/10000]  lr: 9.521050084001487e-05  eta: 0:06:12  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0181)  train/logits_fake: 0.0194 (0.0192, 0.0183)  train/total_loss: 6986.7783 (11401.9675, 7299.3442)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 131471.6719 (86028.3814, 134458.6250)  train/nll_loss: 6986.6523 (11401.8815, 7299.2100)  train/rec_loss: 0.0303 (0.0495, 0.0317)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0183)
2025-02-06 17:02:45,143 train INFO: [7080/46609/10000]  lr: 9.518377210346035e-05  eta: 0:06:10  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0183)  train/logits_fake: 0.0193 (0.0192, 0.0188)  train/total_loss: 6876.3379 (11388.8660, 5397.3750)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 130430.9375 (86144.6735, 160030.0781)  train/nll_loss: 6876.2236 (11388.7799, 5397.2148)  train/rec_loss: 0.0298 (0.0494, 0.0234)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0188)
2025-02-06 17:02:47,677 train INFO: [7100/46609/10000]  lr: 9.51569728051305e-05  eta: 0:06:07  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0194)  train/logits_fake: 0.0192 (0.0192, 0.0202)  train/total_loss: 6952.8809 (11377.9139, 8283.2764)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 132747.5469 (86272.8881, 124245.9609)  train/nll_loss: 6952.7637 (11377.8276, 8283.1523)  train/rec_loss: 0.0302 (0.0494, 0.0360)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0202)
2025-02-06 17:02:50,213 train INFO: [7120/46609/10000]  lr: 9.513010298734508e-05  eta: 0:06:05  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0187)  train/logits_fake: 0.0192 (0.0192, 0.0186)  train/total_loss: 6952.8809 (11367.3482, 8622.8506)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 131765.9375 (86383.0787, 135450.6562)  train/nll_loss: 6952.7637 (11367.2619, 8622.7148)  train/rec_loss: 0.0302 (0.0493, 0.0374)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0186)
2025-02-06 17:02:52,753 train INFO: [7140/46609/10000]  lr: 9.51031626925352e-05  eta: 0:06:02  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0200)  train/logits_fake: 0.0191 (0.0192, 0.0192)  train/total_loss: 7199.9609 (11359.4636, 10436.3867)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 129214.8672 (86498.6043, 128434.4844)  train/nll_loss: 7199.8311 (11359.3771, 10436.2578)  train/rec_loss: 0.0312 (0.0493, 0.0453)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0192)
2025-02-06 17:02:55,292 train INFO: [7160/46609/10000]  lr: 9.507615196324327e-05  eta: 0:06:00  iter_time: 0.127  data: 0.001  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0181)  train/logits_fake: 0.0190 (0.0192, 0.0187)  train/total_loss: 7363.8560 (11349.5328, 5410.9536)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 128570.5469 (86619.0557, 137090.7500)  train/nll_loss: 7363.7129 (11349.4462, 5410.8164)  train/rec_loss: 0.0320 (0.0493, 0.0235)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0187)
2025-02-06 17:02:57,835 train INFO: [7180/46609/10000]  lr: 9.50490708421229e-05  eta: 0:05:57  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0171)  train/logits_fake: 0.0190 (0.0192, 0.0176)  train/total_loss: 7394.9717 (11338.3039, 10037.6240)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 128570.5469 (86738.5151, 160979.2812)  train/nll_loss: 7394.8418 (11338.2171, 10037.4629)  train/rec_loss: 0.0321 (0.0492, 0.0436)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0192, -0.0176)
2025-02-06 17:03:00,370 train INFO: [7200/46609/10000]  lr: 9.502191937193887e-05  eta: 0:05:55  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0196)  train/logits_fake: 0.0192 (0.0192, 0.0197)  train/total_loss: 7761.2881 (11329.3092, 6651.9766)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 129180.8281 (86874.5793, 105929.4844)  train/nll_loss: 7761.1431 (11329.2223, 6651.8706)  train/rec_loss: 0.0337 (0.0492, 0.0289)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0197)
2025-02-06 17:03:02,907 train INFO: [7220/46609/10000]  lr: 9.499469759556709e-05  eta: 0:05:52  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0203)  train/logits_fake: 0.0192 (0.0192, 0.0194)  train/total_loss: 7492.3315 (11317.2206, 8986.2109)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 128434.4844 (86974.9883, 121452.7422)  train/nll_loss: 7492.2065 (11317.1337, 8986.0898)  train/rec_loss: 0.0325 (0.0491, 0.0390)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0194)
2025-02-06 17:03:05,440 train INFO: [7240/46609/10000]  lr: 9.496740555599444e-05  eta: 0:05:49  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0190)  train/logits_fake: 0.0193 (0.0192, 0.0190)  train/total_loss: 7195.3462 (11304.6927, 5428.3521)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 127818.8281 (87080.7923, 116380.9219)  train/nll_loss: 7195.1934 (11304.6057, 5428.2358)  train/rec_loss: 0.0312 (0.0491, 0.0236)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0190)
2025-02-06 17:03:07,973 train INFO: [7260/46609/10000]  lr: 9.494004329631877e-05  eta: 0:05:47  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0190)  train/logits_fake: 0.0195 (0.0192, 0.0184)  train/total_loss: 7027.9990 (11292.4817, 6209.6074)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 127818.8281 (87198.1988, 129672.8750)  train/nll_loss: 7027.8862 (11292.3945, 6209.4775)  train/rec_loss: 0.0305 (0.0490, 0.0270)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0184)
2025-02-06 17:03:10,501 train INFO: [7280/46609/10000]  lr: 9.491261085974884e-05  eta: 0:05:44  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0185)  train/logits_fake: 0.0194 (0.0192, 0.0192)  train/total_loss: 6899.6777 (11281.2554, 9477.5381)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 127511.5391 (87310.0852, 117483.2109)  train/nll_loss: 6899.5337 (11281.1681, 9477.4209)  train/rec_loss: 0.0299 (0.0490, 0.0411)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0192)
2025-02-06 17:03:13,028 train INFO: [7300/46609/10000]  lr: 9.488510828960418e-05  eta: 0:05:42  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0184)  train/logits_fake: 0.0192 (0.0192, 0.0187)  train/total_loss: 6759.5688 (11270.0673, 7207.3506)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 126927.5625 (87428.9058, 146919.4375)  train/nll_loss: 6759.4429 (11269.9799, 7207.2036)  train/rec_loss: 0.0293 (0.0489, 0.0313)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0187)
2025-02-06 17:03:15,560 train INFO: [7320/46609/10000]  lr: 9.485753562931516e-05  eta: 0:05:39  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0171)  train/logits_fake: 0.0193 (0.0192, 0.0184)  train/total_loss: 6758.3286 (11259.2331, 9871.6523)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 127745.1953 (87545.6776, 137683.6875)  train/nll_loss: 6758.2041 (11259.1456, 9871.5146)  train/rec_loss: 0.0293 (0.0489, 0.0428)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0184)
2025-02-06 17:03:18,094 train INFO: [7340/46609/10000]  lr: 9.48298929224227e-05  eta: 0:05:37  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0196)  train/logits_fake: 0.0193 (0.0192, 0.0198)  train/total_loss: 6899.6777 (11249.6630, 5656.9624)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 128701.4062 (87664.5120, 125168.0703)  train/nll_loss: 6899.5337 (11249.5754, 5656.8374)  train/rec_loss: 0.0299 (0.0488, 0.0246)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0198)
2025-02-06 17:03:20,631 train INFO: [7360/46609/10000]  lr: 9.480218021257847e-05  eta: 0:05:34  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0194)  train/logits_fake: 0.0192 (0.0192, 0.0194)  train/total_loss: 6798.9204 (11236.5336, 7452.4746)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 128701.4062 (87773.8906, 157777.0625)  train/nll_loss: 6798.7900 (11236.4458, 7452.3169)  train/rec_loss: 0.0295 (0.0488, 0.0323)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0194)
2025-02-06 17:03:23,168 train INFO: [7380/46609/10000]  lr: 9.477439754354459e-05  eta: 0:05:32  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0194)  train/logits_fake: 0.0193 (0.0192, 0.0192)  train/total_loss: 7064.9341 (11228.5157, 8495.4980)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 128606.9688 (87883.0264, 135400.0156)  train/nll_loss: 7064.7930 (11228.4278, 8495.3623)  train/rec_loss: 0.0307 (0.0487, 0.0369)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0192)
2025-02-06 17:03:25,703 train INFO: [7400/46609/10000]  lr: 9.47465449591937e-05  eta: 0:05:29  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0192)  train/logits_fake: 0.0193 (0.0192, 0.0194)  train/total_loss: 7389.2915 (11219.5023, 7555.4351)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 128663.0000 (88011.2387, 153669.8125)  train/nll_loss: 7389.1846 (11219.4143, 7555.2812)  train/rec_loss: 0.0321 (0.0487, 0.0328)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0194)
2025-02-06 17:03:28,236 train INFO: [7420/46609/10000]  lr: 9.471862250350882e-05  eta: 0:05:27  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0199)  train/logits_fake: 0.0192 (0.0192, 0.0204)  train/total_loss: 7682.1113 (11212.6837, 8400.9795)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 132408.5781 (88152.6013, 153274.0000)  train/nll_loss: 7681.9819 (11212.5956, 8400.8262)  train/rec_loss: 0.0333 (0.0487, 0.0365)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0204)
2025-02-06 17:03:30,774 train INFO: [7440/46609/10000]  lr: 9.469063022058334e-05  eta: 0:05:24  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0178)  train/logits_fake: 0.0192 (0.0192, 0.0188)  train/total_loss: 7356.0513 (11200.8922, 8392.1680)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 133028.9688 (88288.8247, 156493.7656)  train/nll_loss: 7355.8975 (11200.8039, 8392.0117)  train/rec_loss: 0.0319 (0.0486, 0.0364)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0188)
2025-02-06 17:03:33,305 train INFO: [7460/46609/10000]  lr: 9.466256815462087e-05  eta: 0:05:22  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0193)  train/logits_fake: 0.0192 (0.0192, 0.0205)  train/total_loss: 7555.4351 (11192.1439, 13077.9775)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 133940.0938 (88422.2908, 136151.3281)  train/nll_loss: 7555.2812 (11192.0555, 13077.8418)  train/rec_loss: 0.0328 (0.0486, 0.0568)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0205)
2025-02-06 17:03:35,846 train INFO: [7480/46609/10000]  lr: 9.463443634993526e-05  eta: 0:05:19  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0191)  train/logits_fake: 0.0191 (0.0192, 0.0192)  train/total_loss: 7446.3232 (11182.7952, 6526.4336)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 135428.6406 (88535.1055, 118945.5000)  train/nll_loss: 7446.1685 (11182.7067, 6526.3145)  train/rec_loss: 0.0323 (0.0485, 0.0283)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0192)
2025-02-06 17:03:38,388 train INFO: [7500/46609/10000]  lr: 9.460623485095045e-05  eta: 0:05:16  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0173)  train/logits_fake: 0.0191 (0.0192, 0.0174)  train/total_loss: 7272.2979 (11171.1176, 7130.3145)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 135256.7344 (88656.0341, 153306.2500)  train/nll_loss: 7272.1689 (11171.0290, 7130.1611)  train/rec_loss: 0.0316 (0.0485, 0.0309)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0174)
2025-02-06 17:03:40,928 train INFO: [7520/46609/10000]  lr: 9.457796370220048e-05  eta: 0:05:14  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0176)  train/logits_fake: 0.0189 (0.0192, 0.0168)  train/total_loss: 6856.6763 (11159.6003, 5996.9536)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 134990.0000 (88780.1425, 137565.2188)  train/nll_loss: 6856.5654 (11159.5116, 5996.8159)  train/rec_loss: 0.0298 (0.0484, 0.0260)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0192, -0.0168)
2025-02-06 17:03:43,461 train INFO: [7540/46609/10000]  lr: 9.454962294832933e-05  eta: 0:05:11  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0191)  train/logits_fake: 0.0189 (0.0192, 0.0191)  train/total_loss: 7050.7729 (11149.4514, 5224.6719)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 133559.3750 (88877.0687, 111513.9609)  train/nll_loss: 7050.6406 (11149.3626, 5224.5605)  train/rec_loss: 0.0306 (0.0484, 0.0227)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0192, -0.0191)
2025-02-06 17:03:45,998 train INFO: [7560/46609/10000]  lr: 9.452121263409094e-05  eta: 0:05:09  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0196)  train/logits_fake: 0.0191 (0.0192, 0.0194)  train/total_loss: 7169.9199 (11140.5697, 7351.8022)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 134990.0000 (89017.9488, 140171.2188)  train/nll_loss: 7169.7812 (11140.4807, 7351.6621)  train/rec_loss: 0.0311 (0.0484, 0.0319)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0194)
2025-02-06 17:03:48,535 train INFO: [7580/46609/10000]  lr: 9.449273280434908e-05  eta: 0:05:06  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0186)  train/logits_fake: 0.0190 (0.0192, 0.0188)  train/total_loss: 7169.9199 (11132.4314, 10854.9746)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 135308.6562 (89140.2480, 175852.3750)  train/nll_loss: 7169.7812 (11132.3423, 10854.7988)  train/rec_loss: 0.0311 (0.0483, 0.0471)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0192, -0.0188)
2025-02-06 17:03:51,064 train INFO: [7600/46609/10000]  lr: 9.446418350407724e-05  eta: 0:05:04  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0177)  train/logits_fake: 0.0189 (0.0192, 0.0173)  train/total_loss: 7235.9536 (11122.4023, 6551.5400)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 136956.6250 (89265.3257, 105074.8750)  train/nll_loss: 7235.8081 (11122.3130, 6551.4351)  train/rec_loss: 0.0314 (0.0483, 0.0284)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0192, -0.0173)
2025-02-06 17:03:53,594 train INFO: [7620/46609/10000]  lr: 9.443556477835872e-05  eta: 0:05:01  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0189)  train/logits_fake: 0.0191 (0.0192, 0.0190)  train/total_loss: 7351.8022 (11113.0987, 7491.8384)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 136956.6250 (89395.2000, 117553.6562)  train/nll_loss: 7351.6621 (11113.0093, 7491.7207)  train/rec_loss: 0.0319 (0.0482, 0.0325)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0190)
2025-02-06 17:03:56,125 train INFO: [7640/46609/10000]  lr: 9.440687667238635e-05  eta: 0:04:59  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0187)  train/logits_fake: 0.0193 (0.0192, 0.0188)  train/total_loss: 7293.8882 (11102.8028, 5600.9185)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 136911.0156 (89502.8742, 105397.7812)  train/nll_loss: 7293.7515 (11102.7133, 5600.8130)  train/rec_loss: 0.0317 (0.0482, 0.0243)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0188)
2025-02-06 17:03:58,660 train INFO: [7660/46609/10000]  lr: 9.437811923146262e-05  eta: 0:04:56  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0194)  train/logits_fake: 0.0192 (0.0192, 0.0200)  train/total_loss: 7210.8506 (11093.0672, 5803.1265)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 134511.0469 (89608.6207, 113721.8203)  train/nll_loss: 7210.7129 (11092.9776, 5803.0127)  train/rec_loss: 0.0313 (0.0481, 0.0252)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0200)
2025-02-06 17:04:01,196 train INFO: [7680/46609/10000]  lr: 9.434929250099939e-05  eta: 0:04:54  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0179)  train/logits_fake: 0.0193 (0.0192, 0.0183)  train/total_loss: 6874.3638 (11079.4025, 5489.6987)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 134511.0469 (89724.3511, 136254.0156)  train/nll_loss: 6874.2373 (11079.3127, 5489.5625)  train/rec_loss: 0.0298 (0.0481, 0.0238)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0183)
2025-02-06 17:04:03,734 train INFO: [7700/46609/10000]  lr: 9.432039652651805e-05  eta: 0:04:51  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0209)  train/logits_fake: 0.0194 (0.0192, 0.0210)  train/total_loss: 6816.6016 (11069.4318, 9078.1729)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 133829.5469 (89832.2073, 132685.0000)  train/nll_loss: 6816.4678 (11069.3420, 9078.0400)  train/rec_loss: 0.0296 (0.0480, 0.0394)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0210)
2025-02-06 17:04:06,270 train INFO: [7720/46609/10000]  lr: 9.429143135364926e-05  eta: 0:04:49  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0180)  train/logits_fake: 0.0194 (0.0192, 0.0188)  train/total_loss: 6716.8477 (11059.4566, 7756.3330)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 133829.5469 (89959.9200, 149004.5625)  train/nll_loss: 6716.7026 (11059.3667, 7756.1841)  train/rec_loss: 0.0292 (0.0480, 0.0337)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0188)
2025-02-06 17:04:08,806 train INFO: [7740/46609/10000]  lr: 9.426239702813299e-05  eta: 0:04:46  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0194)  train/logits_fake: 0.0194 (0.0192, 0.0195)  train/total_loss: 6773.6655 (11049.7125, 7081.7915)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 133829.5469 (90069.1551, 137407.5156)  train/nll_loss: 6773.5200 (11049.6224, 7081.6543)  train/rec_loss: 0.0294 (0.0480, 0.0307)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0195)
2025-02-06 17:04:11,349 train INFO: [7760/46609/10000]  lr: 9.42332935958184e-05  eta: 0:04:44  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0182)  train/logits_fake: 0.0193 (0.0192, 0.0183)  train/total_loss: 6817.5654 (11040.0528, 9935.6523)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 135588.0938 (90204.8112, 147443.4375)  train/nll_loss: 6817.4180 (11039.9626, 9935.5049)  train/rec_loss: 0.0296 (0.0479, 0.0431)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0183)
2025-02-06 17:04:13,889 train INFO: [7780/46609/10000]  lr: 9.42041211026638e-05  eta: 0:04:41  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0185)  train/logits_fake: 0.0193 (0.0192, 0.0180)  train/total_loss: 6926.5874 (11028.5089, 8005.8579)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 135884.7188 (90318.2039, 137503.9219)  train/nll_loss: 6926.4336 (11028.4186, 8005.7202)  train/rec_loss: 0.0301 (0.0479, 0.0347)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0180)
2025-02-06 17:04:16,427 train INFO: [7800/46609/10000]  lr: 9.417487959473651e-05  eta: 0:04:38  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0165)  train/logits_fake: 0.0191 (0.0192, 0.0167)  train/total_loss: 6992.5410 (11017.7643, 5219.3818)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 137350.0938 (90453.9346, 144518.0312)  train/nll_loss: 6992.3916 (11017.6739, 5219.2373)  train/rec_loss: 0.0303 (0.0478, 0.0227)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0167)
2025-02-06 17:04:18,965 train INFO: [7820/46609/10000]  lr: 9.41455691182129e-05  eta: 0:04:36  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0197)  train/logits_fake: 0.0192 (0.0192, 0.0200)  train/total_loss: 6916.6807 (11007.0780, 12230.0703)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 135649.8125 (90549.9062, 144315.2812)  train/nll_loss: 6916.5381 (11006.9875, 12229.9258)  train/rec_loss: 0.0300 (0.0478, 0.0531)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0200)
2025-02-06 17:04:21,507 train INFO: [7840/46609/10000]  lr: 9.411618971937817e-05  eta: 0:04:33  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0195)  train/logits_fake: 0.0191 (0.0192, 0.0191)  train/total_loss: 6555.8999 (10995.9836, 5938.8398)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 135745.9062 (90653.3200, 133180.3750)  train/nll_loss: 6555.7705 (10995.8930, 5938.7065)  train/rec_loss: 0.0285 (0.0477, 0.0258)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0191)
2025-02-06 17:04:24,044 train INFO: [7860/46609/10000]  lr: 9.408674144462642e-05  eta: 0:04:31  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0173)  train/logits_fake: 0.0192 (0.0192, 0.0175)  train/total_loss: 6555.8999 (10985.5229, 7730.3818)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 135474.5312 (90761.1250, 168189.2500)  train/nll_loss: 6555.7705 (10985.4321, 7730.2139)  train/rec_loss: 0.0285 (0.0477, 0.0336)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0175)
2025-02-06 17:04:26,582 train INFO: [7880/46609/10000]  lr: 9.405722434046051e-05  eta: 0:04:28  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0205)  train/logits_fake: 0.0192 (0.0192, 0.0210)  train/total_loss: 6449.0146 (10973.1938, 5871.9033)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 133702.9844 (90867.2076, 148856.1094)  train/nll_loss: 6448.8857 (10973.1030, 5871.7544)  train/rec_loss: 0.0280 (0.0476, 0.0255)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0210)
2025-02-06 17:04:29,123 train INFO: [7900/46609/10000]  lr: 9.402763845349195e-05  eta: 0:04:26  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0191)  train/logits_fake: 0.0193 (0.0192, 0.0198)  train/total_loss: 6336.9976 (10961.7439, 6187.2397)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 133702.9844 (90984.0189, 132290.9531)  train/nll_loss: 6336.8945 (10961.6529, 6187.1074)  train/rec_loss: 0.0275 (0.0476, 0.0269)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0198)
2025-02-06 17:04:31,662 train INFO: [7920/46609/10000]  lr: 9.399798383044092e-05  eta: 0:04:23  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0187)  train/logits_fake: 0.0192 (0.0192, 0.0186)  train/total_loss: 6248.3154 (10950.6116, 7414.6626)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 135474.5312 (91100.6052, 151951.7812)  train/nll_loss: 6248.1992 (10950.5205, 7414.5107)  train/rec_loss: 0.0271 (0.0475, 0.0322)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0186)
2025-02-06 17:04:34,198 train INFO: [7940/46609/10000]  lr: 9.396826051813611e-05  eta: 0:04:21  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0197)  train/logits_fake: 0.0193 (0.0192, 0.0190)  train/total_loss: 6245.4487 (10938.6337, 6053.5767)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 135508.1094 (91213.3073, 131179.4375)  train/nll_loss: 6245.3115 (10938.5424, 6053.4453)  train/rec_loss: 0.0271 (0.0475, 0.0263)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0190)
2025-02-06 17:04:36,738 train INFO: [7960/46609/10000]  lr: 9.393846856351466e-05  eta: 0:04:18  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0194)  train/logits_fake: 0.0193 (0.0192, 0.0194)  train/total_loss: 6162.3159 (10927.5771, 5962.0752)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 135977.8125 (91318.9386, 129739.4141)  train/nll_loss: 6162.1729 (10927.4857, 5961.9453)  train/rec_loss: 0.0267 (0.0474, 0.0259)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0194)
2025-02-06 17:04:39,282 train INFO: [7980/46609/10000]  lr: 9.390860801362217e-05  eta: 0:04:16  iter_time: 0.127  data: 0.001  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0184)  train/logits_fake: 0.0194 (0.0192, 0.0189)  train/total_loss: 6113.7876 (10915.4870, 6940.1113)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 136563.0312 (91430.4445, 151549.2500)  train/nll_loss: 6113.6582 (10915.3956, 6939.9600)  train/rec_loss: 0.0265 (0.0474, 0.0301)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0189)
2025-02-06 17:04:41,822 train INFO: [8000/46609/10000]  lr: 9.38786789156125e-05  eta: 0:04:13  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0185)  train/logits_fake: 0.0194 (0.0192, 0.0190)  train/total_loss: 6245.4487 (10905.2683, 7052.7505)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 137677.9219 (91549.3435, 144021.5156)  train/nll_loss: 6245.3115 (10905.1768, 7052.6064)  train/rec_loss: 0.0271 (0.0473, 0.0306)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0190)
2025-02-06 17:04:44,351 train INFO: [8020/46609/10000]  lr: 9.384868131674781e-05  eta: 0:04:11  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0170)  train/logits_fake: 0.0194 (0.0192, 0.0171)  train/total_loss: 6266.6387 (10894.3696, 8275.3193)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 137346.5156 (91667.4796, 117644.4688)  train/nll_loss: 6266.5073 (10894.2780, 8275.2021)  train/rec_loss: 0.0272 (0.0473, 0.0359)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0171)
2025-02-06 17:04:46,882 train INFO: [8040/46609/10000]  lr: 9.381861526439836e-05  eta: 0:04:08  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0201)  train/logits_fake: 0.0194 (0.0192, 0.0201)  train/total_loss: 6531.0659 (10884.0861, 6964.7349)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 138336.9375 (91787.1254, 152036.4062)  train/nll_loss: 6530.9453 (10883.9943, 6964.5830)  train/rec_loss: 0.0283 (0.0472, 0.0302)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0201)
2025-02-06 17:04:49,418 train INFO: [8060/46609/10000]  lr: 9.37884808060426e-05  eta: 0:04:05  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0187)  train/logits_fake: 0.0193 (0.0192, 0.0188)  train/total_loss: 6613.6602 (10874.3292, 6899.5801)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 139961.7969 (91921.7511, 151527.9844)  train/nll_loss: 6613.5059 (10874.2373, 6899.4287)  train/rec_loss: 0.0287 (0.0472, 0.0299)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0188)
2025-02-06 17:04:51,955 train INFO: [8080/46609/10000]  lr: 9.375827798926689e-05  eta: 0:04:03  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0193)  train/logits_fake: 0.0193 (0.0192, 0.0195)  train/total_loss: 6759.9058 (10864.5124, 8319.0664)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 140616.7656 (92029.8398, 132594.4062)  train/nll_loss: 6759.7305 (10864.4204, 8318.9336)  train/rec_loss: 0.0293 (0.0472, 0.0361)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0195)
2025-02-06 17:04:54,486 train INFO: [8100/46609/10000]  lr: 9.372800686176567e-05  eta: 0:04:00  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0190)  train/logits_fake: 0.0192 (0.0192, 0.0195)  train/total_loss: 6899.3589 (10856.0346, 9287.3291)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 138557.8750 (92132.4156, 134468.3438)  train/nll_loss: 6899.2061 (10855.9424, 9287.1943)  train/rec_loss: 0.0299 (0.0471, 0.0403)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0195)
2025-02-06 17:04:57,028 train INFO: [8120/46609/10000]  lr: 9.369766747134113e-05  eta: 0:03:58  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0189)  train/logits_fake: 0.0193 (0.0192, 0.0182)  train/total_loss: 6772.1704 (10845.0600, 6643.2266)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 138557.8750 (92249.0935, 170122.1875)  train/nll_loss: 6772.0190 (10844.9677, 6643.0566)  train/rec_loss: 0.0294 (0.0471, 0.0288)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0182)
2025-02-06 17:04:59,555 train INFO: [8140/46609/10000]  lr: 9.366725986590334e-05  eta: 0:03:55  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0197)  train/logits_fake: 0.0192 (0.0192, 0.0192)  train/total_loss: 6759.9058 (10835.0593, 4718.6348)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 138208.2344 (92362.6877, 129392.2734)  train/nll_loss: 6759.7305 (10834.9670, 4718.5054)  train/rec_loss: 0.0293 (0.0470, 0.0205)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0192)
2025-02-06 17:05:02,077 train INFO: [8160/46609/10000]  lr: 9.363678409347004e-05  eta: 0:03:53  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0185)  train/logits_fake: 0.0192 (0.0192, 0.0186)  train/total_loss: 6650.2021 (10823.9471, 7111.7471)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 137081.6094 (92469.2401, 148466.0625)  train/nll_loss: 6650.0557 (10823.8546, 7111.5986)  train/rec_loss: 0.0289 (0.0470, 0.0309)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0186)
2025-02-06 17:05:04,602 train INFO: [8180/46609/10000]  lr: 9.360624020216665e-05  eta: 0:03:50  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0196)  train/logits_fake: 0.0192 (0.0192, 0.0195)  train/total_loss: 6340.2207 (10812.1926, 5866.8970)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 138432.0938 (92593.1142, 135178.7031)  train/nll_loss: 6340.0825 (10812.1000, 5866.7617)  train/rec_loss: 0.0275 (0.0469, 0.0255)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0195)
2025-02-06 17:05:07,130 train INFO: [8200/46609/10000]  lr: 9.357562824022613e-05  eta: 0:03:48  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0194)  train/logits_fake: 0.0192 (0.0192, 0.0193)  train/total_loss: 6281.5400 (10802.4207, 6632.1274)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 138189.6406 (92709.6512, 175637.6562)  train/nll_loss: 6281.4043 (10802.3280, 6631.9517)  train/rec_loss: 0.0273 (0.0469, 0.0288)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0193)
2025-02-06 17:05:09,661 train INFO: [8220/46609/10000]  lr: 9.354494825598895e-05  eta: 0:03:45  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0179)  train/logits_fake: 0.0192 (0.0192, 0.0179)  train/total_loss: 6340.2207 (10792.2190, 6540.4155)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 136982.3438 (92817.8599, 143543.2344)  train/nll_loss: 6340.0825 (10792.1262, 6540.2720)  train/rec_loss: 0.0275 (0.0468, 0.0284)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0179)
2025-02-06 17:05:12,195 train INFO: [8240/46609/10000]  lr: 9.351420029790299e-05  eta: 0:03:43  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0205)  train/logits_fake: 0.0192 (0.0192, 0.0201)  train/total_loss: 6180.2441 (10780.1510, 5732.1948)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 136650.2656 (92926.7452, 114943.4141)  train/nll_loss: 6180.1021 (10780.0581, 5732.0801)  train/rec_loss: 0.0268 (0.0468, 0.0249)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0201)
2025-02-06 17:05:14,731 train INFO: [8260/46609/10000]  lr: 9.348338441452349e-05  eta: 0:03:40  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0197)  train/logits_fake: 0.0192 (0.0192, 0.0199)  train/total_loss: 6171.0215 (10769.6273, 6053.6484)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 137341.8750 (93045.5372, 124915.5469)  train/nll_loss: 6170.8633 (10769.5343, 6053.5234)  train/rec_loss: 0.0268 (0.0467, 0.0263)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0199)
2025-02-06 17:05:17,266 train INFO: [8280/46609/10000]  lr: 9.345250065451291e-05  eta: 0:03:38  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0189)  train/logits_fake: 0.0192 (0.0192, 0.0189)  train/total_loss: 6277.9019 (10758.3473, 6668.2065)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 136589.2500 (93148.8195, 145244.5781)  train/nll_loss: 6277.7402 (10758.2541, 6668.0615)  train/rec_loss: 0.0272 (0.0467, 0.0289)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0189)
2025-02-06 17:05:19,795 train INFO: [8300/46609/10000]  lr: 9.342154906664095e-05  eta: 0:03:35  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0198)  train/logits_fake: 0.0191 (0.0192, 0.0199)  train/total_loss: 6299.2788 (10749.1861, 6693.1724)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 137609.8281 (93261.4200, 136277.5156)  train/nll_loss: 6299.1523 (10749.0929, 6693.0361)  train/rec_loss: 0.0273 (0.0467, 0.0290)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0199)
2025-02-06 17:05:22,333 train INFO: [8320/46609/10000]  lr: 9.339052969978439e-05  eta: 0:03:32  iter_time: 0.127  data: 0.001  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0186)  train/logits_fake: 0.0192 (0.0192, 0.0183)  train/total_loss: 6293.3354 (10739.6999, 6123.4780)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 140244.8438 (93373.5431, 159499.5938)  train/nll_loss: 6293.1943 (10739.6066, 6123.3184)  train/rec_loss: 0.0273 (0.0466, 0.0266)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0183)
2025-02-06 17:05:24,875 train INFO: [8340/46609/10000]  lr: 9.335944260292699e-05  eta: 0:03:30  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0189)  train/logits_fake: 0.0192 (0.0192, 0.0185)  train/total_loss: 6362.8540 (10729.5401, 7437.2041)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 139756.2969 (93463.9519, 137898.2500)  train/nll_loss: 6362.7227 (10729.4467, 7437.0664)  train/rec_loss: 0.0276 (0.0466, 0.0323)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0185)
2025-02-06 17:05:27,409 train INFO: [8360/46609/10000]  lr: 9.332828782515959e-05  eta: 0:03:27  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0190)  train/logits_fake: 0.0192 (0.0192, 0.0192)  train/total_loss: 6293.3354 (10717.5970, 5685.6523)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 137147.6875 (93550.3928, 145315.8125)  train/nll_loss: 6293.1943 (10717.5035, 5685.5068)  train/rec_loss: 0.0273 (0.0465, 0.0247)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0192)
2025-02-06 17:05:29,946 train INFO: [8380/46609/10000]  lr: 9.329706541567982e-05  eta: 0:03:25  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0171)  train/logits_fake: 0.0192 (0.0192, 0.0173)  train/total_loss: 6365.6787 (10708.9780, 7741.2866)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 135086.8906 (93644.0819, 160262.2500)  train/nll_loss: 6365.5430 (10708.8843, 7741.1265)  train/rec_loss: 0.0276 (0.0465, 0.0336)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0173)
2025-02-06 17:05:32,478 train INFO: [8400/46609/10000]  lr: 9.326577542379208e-05  eta: 0:03:22  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0177)  train/logits_fake: 0.0192 (0.0192, 0.0176)  train/total_loss: 6344.9517 (10698.6309, 5838.5269)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 134175.0312 (93762.4821, 147195.4375)  train/nll_loss: 6344.8086 (10698.5371, 5838.3799)  train/rec_loss: 0.0275 (0.0464, 0.0253)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0176)
2025-02-06 17:05:35,010 train INFO: [8420/46609/10000]  lr: 9.32344178989076e-05  eta: 0:03:20  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0176)  train/logits_fake: 0.0191 (0.0192, 0.0176)  train/total_loss: 6426.8628 (10689.5933, 6897.2036)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 134175.0312 (93877.0632, 153314.9688)  train/nll_loss: 6426.7207 (10689.4994, 6897.0503)  train/rec_loss: 0.0279 (0.0464, 0.0299)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0176)
2025-02-06 17:05:37,541 train INFO: [8440/46609/10000]  lr: 9.320299289054416e-05  eta: 0:03:17  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0199)  train/logits_fake: 0.0192 (0.0192, 0.0200)  train/total_loss: 6537.6406 (10679.8341, 4897.9287)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 137127.4062 (93985.1022, 116817.4375)  train/nll_loss: 6537.4785 (10679.7401, 4897.8120)  train/rec_loss: 0.0284 (0.0464, 0.0213)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0200)
2025-02-06 17:05:40,070 train INFO: [8460/46609/10000]  lr: 9.317150044832614e-05  eta: 0:03:15  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0190)  train/logits_fake: 0.0192 (0.0192, 0.0188)  train/total_loss: 6641.5347 (10669.4272, 6351.5234)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 139089.4844 (94104.6274, 126964.2266)  train/nll_loss: 6641.3818 (10669.3331, 6351.3965)  train/rec_loss: 0.0288 (0.0463, 0.0276)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0188)
2025-02-06 17:05:42,601 train INFO: [8480/46609/10000]  lr: 9.313994062198441e-05  eta: 0:03:12  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0185)  train/logits_fake: 0.0192 (0.0192, 0.0185)  train/total_loss: 6603.2178 (10660.2529, 9146.0576)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 141269.1562 (94209.7536, 117520.0938)  train/nll_loss: 6603.0752 (10660.1587, 9145.9404)  train/rec_loss: 0.0287 (0.0463, 0.0397)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0185)
2025-02-06 17:05:45,137 train INFO: [8500/46609/10000]  lr: 9.310831346135623e-05  eta: 0:03:10  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0201)  train/logits_fake: 0.0194 (0.0192, 0.0198)  train/total_loss: 6611.0815 (10650.1154, 5422.5957)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 139156.7031 (94301.8909, 114271.3047)  train/nll_loss: 6610.9316 (10650.0211, 5422.4814)  train/rec_loss: 0.0287 (0.0462, 0.0235)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0198)
2025-02-06 17:05:47,673 train INFO: [8520/46609/10000]  lr: 9.307661901638523e-05  eta: 0:03:07  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0194 (0.0191, 0.0196)  train/logits_fake: 0.0195 (0.0192, 0.0198)  train/total_loss: 6540.3145 (10640.2575, 7518.6724)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 139156.7031 (94411.2021, 145788.2656)  train/nll_loss: 6540.1919 (10640.1630, 7518.5264)  train/rec_loss: 0.0284 (0.0462, 0.0326)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0198)
2025-02-06 17:05:50,212 train INFO: [8540/46609/10000]  lr: 9.304485733712123e-05  eta: 0:03:05  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0189)  train/logits_fake: 0.0194 (0.0192, 0.0194)  train/total_loss: 6453.0615 (10631.0297, 8439.1123)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 139391.1250 (94539.0050, 175044.2969)  train/nll_loss: 6452.9189 (10630.9351, 8438.9375)  train/rec_loss: 0.0280 (0.0461, 0.0366)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0194)
2025-02-06 17:05:52,751 train INFO: [8560/46609/10000]  lr: 9.30130284737203e-05  eta: 0:03:02  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0195)  train/logits_fake: 0.0192 (0.0192, 0.0189)  train/total_loss: 6527.8164 (10621.6663, 10098.6162)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 141618.9688 (94656.7805, 141838.7969)  train/nll_loss: 6527.6685 (10621.5717, 10098.4746)  train/rec_loss: 0.0283 (0.0461, 0.0438)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0189)
2025-02-06 17:05:55,292 train INFO: [8580/46609/10000]  lr: 9.298113247644452e-05  eta: 0:03:00  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0205)  train/logits_fake: 0.0194 (0.0192, 0.0210)  train/total_loss: 6527.8164 (10611.9579, 6964.7671)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 141013.3281 (94761.5128, 130564.5469)  train/nll_loss: 6527.6685 (10611.8631, 6964.6367)  train/rec_loss: 0.0283 (0.0461, 0.0302)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0210)
2025-02-06 17:05:57,831 train INFO: [8600/46609/10000]  lr: 9.294916939566204e-05  eta: 0:02:57  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0193)  train/logits_fake: 0.0191 (0.0192, 0.0191)  train/total_loss: 6597.1895 (10603.5485, 5171.4917)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 141838.7969 (94864.2181, 138352.9375)  train/nll_loss: 6597.0356 (10603.4536, 5171.3535)  train/rec_loss: 0.0286 (0.0460, 0.0224)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0191)
2025-02-06 17:06:00,370 train INFO: [8620/46609/10000]  lr: 9.291713928184693e-05  eta: 0:02:54  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0183)  train/logits_fake: 0.0191 (0.0192, 0.0179)  train/total_loss: 6525.1021 (10593.7560, 4847.3188)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 142200.7031 (94982.1945, 174575.9062)  train/nll_loss: 6524.9565 (10593.6610, 4847.1440)  train/rec_loss: 0.0283 (0.0460, 0.0210)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0179)
2025-02-06 17:06:02,930 train INFO: [8640/46609/10000]  lr: 9.28850421855791e-05  eta: 0:02:52  iter_time: 0.128  data: 0.001  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0175)  train/logits_fake: 0.0191 (0.0192, 0.0173)  train/total_loss: 6352.2632 (10583.7217, 4432.8979)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 141967.8594 (95090.1068, 147339.2656)  train/nll_loss: 6352.1094 (10583.6266, 4432.7505)  train/rec_loss: 0.0276 (0.0459, 0.0192)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0173)
2025-02-06 17:06:05,471 train INFO: [8660/46609/10000]  lr: 9.285287815754427e-05  eta: 0:02:49  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0194)  train/logits_fake: 0.0191 (0.0192, 0.0190)  train/total_loss: 6308.6421 (10574.7490, 6378.1641)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 141671.7344 (95200.8154, 142317.9531)  train/nll_loss: 6308.4932 (10574.6538, 6378.0220)  train/rec_loss: 0.0274 (0.0459, 0.0277)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0190)
2025-02-06 17:06:08,006 train INFO: [8680/46609/10000]  lr: 9.28206472485338e-05  eta: 0:02:47  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0184)  train/logits_fake: 0.0191 (0.0192, 0.0180)  train/total_loss: 6308.6421 (10565.3067, 5653.6396)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 143209.0625 (95324.1339, 160166.3438)  train/nll_loss: 6308.4932 (10565.2114, 5653.4795)  train/rec_loss: 0.0274 (0.0459, 0.0245)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0180)
2025-02-06 17:06:10,543 train INFO: [8700/46609/10000]  lr: 9.278834950944472e-05  eta: 0:02:44  iter_time: 0.127  data: 0.001  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0207)  train/logits_fake: 0.0191 (0.0192, 0.0210)  train/total_loss: 6204.5425 (10556.1880, 5646.9707)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 144611.3438 (95438.4931, 134042.5000)  train/nll_loss: 6204.3975 (10556.0925, 5646.8364)  train/rec_loss: 0.0269 (0.0458, 0.0245)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0210)
2025-02-06 17:06:13,071 train INFO: [8720/46609/10000]  lr: 9.275598499127956e-05  eta: 0:02:42  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0187)  train/logits_fake: 0.0191 (0.0192, 0.0191)  train/total_loss: 6126.8774 (10545.3835, 4069.0747)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 144357.6250 (95541.5872, 167098.8125)  train/nll_loss: 6126.7178 (10545.2879, 4068.9077)  train/rec_loss: 0.0266 (0.0458, 0.0177)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0191)
2025-02-06 17:06:15,611 train INFO: [8740/46609/10000]  lr: 9.272355374514631e-05  eta: 0:02:39  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0190)  train/logits_fake: 0.0191 (0.0192, 0.0186)  train/total_loss: 6201.4702 (10534.8424, 6089.4478)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 144169.5000 (95643.7973, 146338.3438)  train/nll_loss: 6201.3428 (10534.7468, 6089.3013)  train/rec_loss: 0.0269 (0.0457, 0.0264)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0186)
2025-02-06 17:06:18,146 train INFO: [8760/46609/10000]  lr: 9.269105582225833e-05  eta: 0:02:37  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0175)  train/logits_fake: 0.0191 (0.0192, 0.0177)  train/total_loss: 6126.8774 (10524.5237, 7443.2544)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 144173.4688 (95759.0927, 163287.3438)  train/nll_loss: 6126.7178 (10524.4280, 7443.0913)  train/rec_loss: 0.0266 (0.0457, 0.0323)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0177)
2025-02-06 17:06:20,682 train INFO: [8780/46609/10000]  lr: 9.265849127393429e-05  eta: 0:02:34  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0183)  train/logits_fake: 0.0192 (0.0192, 0.0187)  train/total_loss: 6089.4478 (10514.9052, 7780.0864)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 143461.1875 (95868.6873, 140222.4375)  train/nll_loss: 6089.3013 (10514.8093, 7779.9463)  train/rec_loss: 0.0264 (0.0456, 0.0338)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0187)
2025-02-06 17:06:23,224 train INFO: [8800/46609/10000]  lr: 9.262586015159802e-05  eta: 0:02:32  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0160)  train/logits_fake: 0.0193 (0.0192, 0.0164)  train/total_loss: 6130.4399 (10505.8871, 8976.7803)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 141197.7500 (95965.7734, 154513.1250)  train/nll_loss: 6130.2949 (10505.7911, 8976.6260)  train/rec_loss: 0.0266 (0.0456, 0.0390)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0164)
2025-02-06 17:06:25,742 train INFO: [8820/46609/10000]  lr: 9.259316250677857e-05  eta: 0:02:29  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0179)  train/logits_fake: 0.0194 (0.0192, 0.0183)  train/total_loss: 6203.2812 (10497.0731, 6033.2871)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 141746.7812 (96073.9222, 143547.1875)  train/nll_loss: 6203.1152 (10496.9771, 6033.1436)  train/rec_loss: 0.0269 (0.0456, 0.0262)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0183)
2025-02-06 17:06:28,265 train INFO: [8840/46609/10000]  lr: 9.256039839110996e-05  eta: 0:02:27  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0220)  train/logits_fake: 0.0193 (0.0192, 0.0218)  train/total_loss: 6355.4512 (10489.2899, 7639.7256)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 143461.1875 (96194.7028, 134852.2812)  train/nll_loss: 6355.3008 (10489.1937, 7639.5908)  train/rec_loss: 0.0276 (0.0455, 0.0332)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0218)
2025-02-06 17:06:30,793 train INFO: [8860/46609/10000]  lr: 9.252756785633119e-05  eta: 0:02:24  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0185)  train/logits_fake: 0.0194 (0.0192, 0.0194)  train/total_loss: 6741.9551 (10482.2368, 9742.5518)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 143461.1875 (96309.2002, 155310.2812)  train/nll_loss: 6741.7861 (10482.1405, 9742.3965)  train/rec_loss: 0.0293 (0.0455, 0.0423)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0194)
2025-02-06 17:06:33,330 train INFO: [8880/46609/10000]  lr: 9.249467095428616e-05  eta: 0:02:21  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0185)  train/logits_fake: 0.0194 (0.0192, 0.0189)  train/total_loss: 6879.7422 (10476.2365, 6798.9434)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 143778.3125 (96419.1106, 108245.0859)  train/nll_loss: 6879.6182 (10476.1401, 6798.8350)  train/rec_loss: 0.0299 (0.0455, 0.0295)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0189)
2025-02-06 17:06:35,874 train INFO: [8900/46609/10000]  lr: 9.246170773692357e-05  eta: 0:02:19  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0188)  train/logits_fake: 0.0191 (0.0192, 0.0192)  train/total_loss: 6870.7026 (10467.7115, 6087.3857)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 143778.3125 (96520.5984, 161150.6875)  train/nll_loss: 6870.5552 (10467.6150, 6087.2246)  train/rec_loss: 0.0298 (0.0454, 0.0264)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0192)
2025-02-06 17:06:38,417 train INFO: [8920/46609/10000]  lr: 9.242867825629686e-05  eta: 0:02:16  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0198)  train/logits_fake: 0.0191 (0.0192, 0.0199)  train/total_loss: 6800.4058 (10459.3614, 5466.2812)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 145051.5625 (96626.9521, 121228.5312)  train/nll_loss: 6800.2764 (10459.2647, 5466.1602)  train/rec_loss: 0.0295 (0.0454, 0.0237)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0199)
2025-02-06 17:06:40,954 train INFO: [8940/46609/10000]  lr: 9.239558256456405e-05  eta: 0:02:14  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0190)  train/logits_fake: 0.0191 (0.0192, 0.0186)  train/total_loss: 6599.9263 (10450.2506, 5200.4561)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 147061.1562 (96746.9281, 121959.1875)  train/nll_loss: 6599.7510 (10450.1538, 5200.3340)  train/rec_loss: 0.0286 (0.0454, 0.0226)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0186)
2025-02-06 17:06:43,491 train INFO: [8960/46609/10000]  lr: 9.23624207139878e-05  eta: 0:02:11  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0195)  train/logits_fake: 0.0191 (0.0192, 0.0199)  train/total_loss: 6306.4199 (10440.5138, 5922.2876)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 145051.5625 (96857.2143, 126316.3281)  train/nll_loss: 6306.2446 (10440.4169, 5922.1611)  train/rec_loss: 0.0274 (0.0453, 0.0257)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0199)
2025-02-06 17:06:46,029 train INFO: [8980/46609/10000]  lr: 9.232919275693516e-05  eta: 0:02:09  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0177)  train/logits_fake: 0.0190 (0.0192, 0.0183)  train/total_loss: 6188.5146 (10431.6848, 6494.5474)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 145897.8281 (96981.0552, 137160.6250)  train/nll_loss: 6188.3687 (10431.5878, 6494.4102)  train/rec_loss: 0.0269 (0.0453, 0.0282)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0183)
2025-02-06 17:06:48,560 train INFO: [9000/46609/10000]  lr: 9.229589874587763e-05  eta: 0:02:06  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0200)  train/logits_fake: 0.0188 (0.0192, 0.0199)  train/total_loss: 6185.1348 (10422.2982, 7866.4253)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 147061.1562 (97091.2936, 141300.8281)  train/nll_loss: 6184.9966 (10422.2011, 7866.2842)  train/rec_loss: 0.0268 (0.0452, 0.0341)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0192, -0.0199)
2025-02-06 17:06:51,101 train INFO: [9020/46609/10000]  lr: 9.226253873339098e-05  eta: 0:02:04  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0197)  train/logits_fake: 0.0191 (0.0192, 0.0198)  train/total_loss: 6212.0420 (10413.7109, 5811.7085)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 147061.1562 (97199.7538, 124296.5156)  train/nll_loss: 6211.8862 (10413.6137, 5811.5840)  train/rec_loss: 0.0270 (0.0452, 0.0252)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0198)
2025-02-06 17:06:53,642 train INFO: [9040/46609/10000]  lr: 9.222911277215525e-05  eta: 0:02:01  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0202)  train/logits_fake: 0.0192 (0.0192, 0.0203)  train/total_loss: 6208.7520 (10404.7154, 4886.9517)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 145126.4375 (97297.1045, 145126.4375)  train/nll_loss: 6208.6387 (10404.6181, 4886.8066)  train/rec_loss: 0.0269 (0.0452, 0.0212)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0203)
2025-02-06 17:06:56,178 train INFO: [9060/46609/10000]  lr: 9.219562091495456e-05  eta: 0:01:59  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0222)  train/logits_fake: 0.0192 (0.0192, 0.0220)  train/total_loss: 6180.5449 (10394.6113, 4994.3242)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 145475.3125 (97398.9383, 139732.9062)  train/nll_loss: 6180.3555 (10394.5139, 4994.1846)  train/rec_loss: 0.0268 (0.0451, 0.0217)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0220)
2025-02-06 17:06:58,712 train INFO: [9080/46609/10000]  lr: 9.216206321467716e-05  eta: 0:01:56  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0183)  train/logits_fake: 0.0192 (0.0192, 0.0179)  train/total_loss: 5949.9458 (10384.6794, 6420.6768)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 143106.1719 (97491.2689, 146681.8281)  train/nll_loss: 5949.8315 (10384.5819, 6420.5303)  train/rec_loss: 0.0258 (0.0451, 0.0279)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0179)
2025-02-06 17:07:01,242 train INFO: [9100/46609/10000]  lr: 9.212843972431522e-05  eta: 0:01:54  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0208)  train/logits_fake: 0.0194 (0.0192, 0.0206)  train/total_loss: 6014.6870 (10376.3516, 4472.4351)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 143106.1719 (97588.0565, 146808.2188)  train/nll_loss: 6014.5356 (10376.2540, 4472.2881)  train/rec_loss: 0.0261 (0.0450, 0.0194)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0206)
2025-02-06 17:07:03,781 train INFO: [9120/46609/10000]  lr: 9.209475049696483e-05  eta: 0:01:51  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0191)  train/logits_fake: 0.0193 (0.0192, 0.0187)  train/total_loss: 5976.6743 (10366.7863, 6179.4287)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 143507.5312 (97694.1126, 139874.6562)  train/nll_loss: 5976.5312 (10366.6886, 6179.2891)  train/rec_loss: 0.0259 (0.0450, 0.0268)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0187)
2025-02-06 17:07:06,317 train INFO: [9140/46609/10000]  lr: 9.206099558582587e-05  eta: 0:01:49  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0175)  train/logits_fake: 0.0191 (0.0192, 0.0176)  train/total_loss: 5975.8315 (10357.9585, 5086.7197)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 142595.0469 (97789.0384, 139842.6250)  train/nll_loss: 5975.7217 (10357.8607, 5086.5801)  train/rec_loss: 0.0259 (0.0450, 0.0221)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0176)
2025-02-06 17:07:08,851 train INFO: [9160/46609/10000]  lr: 9.202717504420194e-05  eta: 0:01:46  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0197)  train/logits_fake: 0.0192 (0.0192, 0.0194)  train/total_loss: 6014.6870 (10347.8945, 7489.9004)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 140318.5938 (97876.7296, 105606.0781)  train/nll_loss: 6014.5356 (10347.7966, 7489.7949)  train/rec_loss: 0.0261 (0.0449, 0.0325)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0194)
2025-02-06 17:07:11,382 train INFO: [9180/46609/10000]  lr: 9.199328892550032e-05  eta: 0:01:43  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0186)  train/logits_fake: 0.0192 (0.0192, 0.0191)  train/total_loss: 6080.4824 (10340.4824, 7389.9790)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 140346.5625 (97973.2376, 124206.5000)  train/nll_loss: 6080.3594 (10340.3844, 7389.8550)  train/rec_loss: 0.0264 (0.0449, 0.0321)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0191)
2025-02-06 17:07:13,921 train INFO: [9200/46609/10000]  lr: 9.195933728323181e-05  eta: 0:01:41  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0196)  train/logits_fake: 0.0191 (0.0192, 0.0193)  train/total_loss: 6149.6938 (10333.0818, 5958.6021)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 142018.1094 (98079.6495, 147771.2656)  train/nll_loss: 6149.5371 (10332.9837, 5958.4541)  train/rec_loss: 0.0267 (0.0448, 0.0259)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0193)
2025-02-06 17:07:16,462 train INFO: [9220/46609/10000]  lr: 9.192532017101067e-05  eta: 0:01:38  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0186)  train/logits_fake: 0.0192 (0.0192, 0.0187)  train/total_loss: 6195.3970 (10325.6579, 7961.9521)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 142295.5625 (98194.6497, 122108.1719)  train/nll_loss: 6195.2588 (10325.5597, 7961.8301)  train/rec_loss: 0.0269 (0.0448, 0.0346)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0187)
2025-02-06 17:07:18,994 train INFO: [9240/46609/10000]  lr: 9.189123764255458e-05  eta: 0:01:36  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0187)  train/logits_fake: 0.0194 (0.0192, 0.0188)  train/total_loss: 6129.7344 (10316.1552, 7841.7314)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 142295.5625 (98292.2301, 132809.1562)  train/nll_loss: 6129.5645 (10316.0569, 7841.5986)  train/rec_loss: 0.0266 (0.0448, 0.0340)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0188)
2025-02-06 17:07:21,532 train INFO: [9260/46609/10000]  lr: 9.185708975168449e-05  eta: 0:01:33  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0204)  train/logits_fake: 0.0195 (0.0192, 0.0203)  train/total_loss: 6259.9917 (10309.0960, 6967.8545)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 144945.8125 (98401.7091, 144022.7344)  train/nll_loss: 6259.8750 (10308.9976, 6967.7104)  train/rec_loss: 0.0272 (0.0447, 0.0302)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0203)
2025-02-06 17:07:24,074 train INFO: [9280/46609/10000]  lr: 9.182287655232461e-05  eta: 0:01:31  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0206)  train/logits_fake: 0.0195 (0.0192, 0.0203)  train/total_loss: 6129.7344 (10299.8656, 6103.8467)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 145898.0000 (98505.7126, 150186.5000)  train/nll_loss: 6129.5645 (10299.7671, 6103.6963)  train/rec_loss: 0.0266 (0.0447, 0.0265)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0203)
2025-02-06 17:07:26,614 train INFO: [9300/46609/10000]  lr: 9.178859809850221e-05  eta: 0:01:28  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0170)  train/logits_fake: 0.0195 (0.0192, 0.0169)  train/total_loss: 6129.7344 (10292.6014, 9304.8896)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 145898.0000 (98619.9630, 163189.5312)  train/nll_loss: 6129.5645 (10292.5028, 9304.7266)  train/rec_loss: 0.0266 (0.0447, 0.0404)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0195 (-0.0192, -0.0169)
2025-02-06 17:07:29,154 train INFO: [9320/46609/10000]  lr: 9.175425444434769e-05  eta: 0:01:26  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0175)  train/logits_fake: 0.0192 (0.0192, 0.0174)  train/total_loss: 6152.1860 (10284.5858, 6666.7017)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 145898.0000 (98736.7865, 155904.6094)  train/nll_loss: 6152.0361 (10284.4870, 6666.5459)  train/rec_loss: 0.0267 (0.0446, 0.0289)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0174)
2025-02-06 17:07:32,033 train INFO: [9340/46609/10000]  lr: 9.171984564409432e-05  eta: 0:01:23  iter_time: 0.169  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0174)  train/logits_fake: 0.0190 (0.0192, 0.0178)  train/total_loss: 6332.8335 (10277.4550, 7958.0366)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 152242.5781 (98869.2545, 170527.7344)  train/nll_loss: 6332.7080 (10277.3562, 7957.8662)  train/rec_loss: 0.0275 (0.0446, 0.0345)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0192, -0.0178)
2025-02-06 17:07:34,580 train INFO: [9360/46609/10000]  lr: 9.168537175207834e-05  eta: 0:01:21  iter_time: 0.128  data: 0.001  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0189 (0.0191, 0.0204)  train/logits_fake: 0.0189 (0.0192, 0.0201)  train/total_loss: 6509.2739 (10269.9997, 4850.0532)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 151712.8438 (98967.4381, 118213.9531)  train/nll_loss: 6509.1621 (10269.9007, 4849.9351)  train/rec_loss: 0.0283 (0.0446, 0.0211)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0189 (-0.0192, -0.0201)
2025-02-06 17:07:37,127 train INFO: [9380/46609/10000]  lr: 9.165083282273869e-05  eta: 0:01:18  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0194)  train/logits_fake: 0.0190 (0.0192, 0.0193)  train/total_loss: 6560.8364 (10262.3294, 6476.8120)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 152218.1250 (99069.3658, 111727.8047)  train/nll_loss: 6560.6870 (10262.2303, 6476.7002)  train/rec_loss: 0.0285 (0.0445, 0.0281)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0193)
2025-02-06 17:07:39,665 train INFO: [9400/46609/10000]  lr: 9.161622891061709e-05  eta: 0:01:16  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0194)  train/logits_fake: 0.0191 (0.0192, 0.0196)  train/total_loss: 6436.2056 (10252.9079, 6846.6816)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 151209.9375 (99171.6595, 131170.9219)  train/nll_loss: 6436.0400 (10252.8088, 6846.5503)  train/rec_loss: 0.0279 (0.0445, 0.0297)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0196)
2025-02-06 17:07:42,204 train INFO: [9420/46609/10000]  lr: 9.158156007035782e-05  eta: 0:01:13  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0184)  train/logits_fake: 0.0192 (0.0192, 0.0188)  train/total_loss: 6322.5537 (10245.5644, 7150.3228)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 150477.7344 (99292.3645, 181286.8438)  train/nll_loss: 6322.4062 (10245.4651, 7150.1416)  train/rec_loss: 0.0274 (0.0445, 0.0310)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0188)
2025-02-06 17:07:44,739 train INFO: [9440/46609/10000]  lr: 9.154682635670772e-05  eta: 0:01:11  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0196)  train/logits_fake: 0.0192 (0.0192, 0.0201)  train/total_loss: 6284.3267 (10237.8308, 5091.0215)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 149027.7812 (99394.6797, 129761.7031)  train/nll_loss: 6284.1787 (10237.7314, 5090.8916)  train/rec_loss: 0.0273 (0.0444, 0.0221)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0201)
2025-02-06 17:07:47,276 train INFO: [9460/46609/10000]  lr: 9.151202782451605e-05  eta: 0:01:08  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0201)  train/logits_fake: 0.0192 (0.0192, 0.0202)  train/total_loss: 6215.0996 (10230.2321, 14487.1865)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 149301.4375 (99510.0605, 125997.8281)  train/nll_loss: 6214.9219 (10230.1326, 14487.0605)  train/rec_loss: 0.0270 (0.0444, 0.0629)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0202)
2025-02-06 17:07:49,825 train INFO: [9480/46609/10000]  lr: 9.147716452873446e-05  eta: 0:01:05  iter_time: 0.128  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0233)  train/logits_fake: 0.0190 (0.0192, 0.0232)  train/total_loss: 6088.0864 (10222.4167, 8037.9209)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 149301.4375 (99618.7636, 153938.7188)  train/nll_loss: 6087.9160 (10222.3171, 8037.7671)  train/rec_loss: 0.0264 (0.0444, 0.0349)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0232)
2025-02-06 17:07:52,358 train INFO: [9500/46609/10000]  lr: 9.144223652441683e-05  eta: 0:01:03  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0177)  train/logits_fake: 0.0190 (0.0192, 0.0171)  train/total_loss: 6232.2422 (10214.2762, 6596.4990)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 150107.7344 (99726.2874, 140422.7500)  train/nll_loss: 6232.0996 (10214.1765, 6596.3584)  train/rec_loss: 0.0270 (0.0443, 0.0286)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0171)
2025-02-06 17:07:54,897 train INFO: [9520/46609/10000]  lr: 9.140724386671929e-05  eta: 0:01:00  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0192)  train/logits_fake: 0.0190 (0.0192, 0.0192)  train/total_loss: 6242.1318 (10206.9399, 5891.8428)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 147046.7188 (99817.5844, 187656.2500)  train/nll_loss: 6241.9834 (10206.8401, 5891.6553)  train/rec_loss: 0.0271 (0.0443, 0.0256)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0192, -0.0192)
2025-02-06 17:07:57,431 train INFO: [9540/46609/10000]  lr: 9.137218661089997e-05  eta: 0:00:58  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0191)  train/logits_fake: 0.0192 (0.0192, 0.0190)  train/total_loss: 6111.5278 (10198.0060, 13224.4756)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 148129.4844 (99921.0375, 174096.6406)  train/nll_loss: 6111.3818 (10197.9061, 13224.3018)  train/rec_loss: 0.0265 (0.0443, 0.0574)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0190)
2025-02-06 17:07:59,953 train INFO: [9560/46609/10000]  lr: 9.13370648123191e-05  eta: 0:00:55  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0187)  train/logits_fake: 0.0192 (0.0192, 0.0192)  train/total_loss: 5984.4023 (10189.3216, 6894.1211)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 147046.7188 (100011.6594, 163077.3125)  train/nll_loss: 5984.2515 (10189.2216, 6893.9580)  train/rec_loss: 0.0260 (0.0442, 0.0299)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0192)
2025-02-06 17:08:02,488 train INFO: [9580/46609/10000]  lr: 9.130187852643877e-05  eta: 0:00:53  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0187)  train/logits_fake: 0.0192 (0.0192, 0.0186)  train/total_loss: 5984.4023 (10180.8849, 7159.6655)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 147094.6406 (100118.4081, 133847.6562)  train/nll_loss: 5984.2515 (10180.7848, 7159.5317)  train/rec_loss: 0.0260 (0.0442, 0.0311)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0186)
2025-02-06 17:08:05,031 train INFO: [9600/46609/10000]  lr: 9.126662780882294e-05  eta: 0:00:50  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0193)  train/logits_fake: 0.0192 (0.0192, 0.0193)  train/total_loss: 5891.8428 (10172.7315, 5253.2510)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 145782.3125 (100221.5722, 132091.7656)  train/nll_loss: 5891.6553 (10172.6313, 5253.1187)  train/rec_loss: 0.0256 (0.0442, 0.0228)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0193)
2025-02-06 17:08:07,574 train INFO: [9620/46609/10000]  lr: 9.123131271513731e-05  eta: 0:00:48  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0192)  train/logits_fake: 0.0192 (0.0192, 0.0198)  train/total_loss: 6026.6655 (10165.5407, 5087.1201)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 146065.1875 (100321.5341, 145542.5312)  train/nll_loss: 6026.5454 (10165.4403, 5086.9746)  train/rec_loss: 0.0262 (0.0441, 0.0221)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0198)
2025-02-06 17:08:10,118 train INFO: [9640/46609/10000]  lr: 9.119593330114921e-05  eta: 0:00:45  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0192)  train/logits_fake: 0.0191 (0.0192, 0.0191)  train/total_loss: 6192.9678 (10157.8397, 9065.1777)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 147675.9375 (100430.0981, 150827.4219)  train/nll_loss: 6192.8047 (10157.7393, 9065.0273)  train/rec_loss: 0.0269 (0.0441, 0.0393)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0191)
2025-02-06 17:08:12,651 train INFO: [9660/46609/10000]  lr: 9.11604896227276e-05  eta: 0:00:43  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0180)  train/logits_fake: 0.0190 (0.0192, 0.0187)  train/total_loss: 6241.8462 (10149.4247, 7000.9722)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 147675.9375 (100519.6719, 117828.0391)  train/nll_loss: 6241.7100 (10149.3242, 7000.8545)  train/rec_loss: 0.0271 (0.0441, 0.0304)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0187)
2025-02-06 17:08:15,184 train INFO: [9680/46609/10000]  lr: 9.112498173584287e-05  eta: 0:00:40  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0190 (0.0191, 0.0198)  train/logits_fake: 0.0190 (0.0192, 0.0194)  train/total_loss: 6479.9502 (10142.4530, 4921.7964)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 150747.9062 (100629.9955, 117253.7812)  train/nll_loss: 6479.7939 (10142.3524, 4921.6792)  train/rec_loss: 0.0281 (0.0440, 0.0214)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0194)
2025-02-06 17:08:17,711 train INFO: [9700/46609/10000]  lr: 9.108940969656679e-05  eta: 0:00:38  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0199)  train/logits_fake: 0.0190 (0.0192, 0.0202)  train/total_loss: 6259.5981 (10133.7764, 4710.4116)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 149935.8594 (100727.5081, 134042.4531)  train/nll_loss: 6259.4351 (10133.6757, 4710.2773)  train/rec_loss: 0.0272 (0.0440, 0.0204)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0202)
2025-02-06 17:08:20,237 train INFO: [9720/46609/10000]  lr: 9.105377356107251e-05  eta: 0:00:35  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0210)  train/logits_fake: 0.0191 (0.0192, 0.0208)  train/total_loss: 6241.7056 (10127.4664, 6098.4692)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 152197.2812 (100832.5436, 136655.1406)  train/nll_loss: 6241.5508 (10127.3656, 6098.3325)  train/rec_loss: 0.0271 (0.0440, 0.0265)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0208)
2025-02-06 17:08:22,771 train INFO: [9740/46609/10000]  lr: 9.101807338563434e-05  eta: 0:00:32  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0194 (0.0191, 0.0202)  train/logits_fake: 0.0192 (0.0192, 0.0203)  train/total_loss: 6160.3252 (10119.5255, 7739.2656)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 152197.2812 (100939.6373, 176251.1094)  train/nll_loss: 6160.1885 (10119.4245, 7739.0894)  train/rec_loss: 0.0267 (0.0439, 0.0336)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0203)
2025-02-06 17:08:25,309 train INFO: [9760/46609/10000]  lr: 9.098230922662772e-05  eta: 0:00:30  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0194 (0.0191, 0.0194)  train/logits_fake: 0.0192 (0.0192, 0.0197)  train/total_loss: 6090.8447 (10110.8560, 4982.1973)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 152052.2031 (101039.1788, 136277.2656)  train/nll_loss: 6090.6660 (10110.7549, 4982.0610)  train/rec_loss: 0.0264 (0.0439, 0.0216)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0197)
2025-02-06 17:08:27,840 train INFO: [9780/46609/10000]  lr: 9.094648114052913e-05  eta: 0:00:27  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0195 (0.0191, 0.0198)  train/logits_fake: 0.0194 (0.0192, 0.0193)  train/total_loss: 5996.6909 (10102.9820, 6274.5415)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 149764.6875 (101144.3359, 159707.3125)  train/nll_loss: 5996.5498 (10102.8809, 6274.3818)  train/rec_loss: 0.0260 (0.0438, 0.0272)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0193)
2025-02-06 17:08:30,379 train INFO: [9800/46609/10000]  lr: 9.091058918391603e-05  eta: 0:00:25  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0195 (0.0191, 0.0200)  train/logits_fake: 0.0194 (0.0192, 0.0198)  train/total_loss: 6090.8447 (10095.0499, 6425.8823)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 154565.0625 (101258.7763, 133695.7812)  train/nll_loss: 6090.6660 (10094.9487, 6425.7485)  train/rec_loss: 0.0264 (0.0438, 0.0279)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0198)
2025-02-06 17:08:32,926 train INFO: [9820/46609/10000]  lr: 9.087463341346672e-05  eta: 0:00:22  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0194 (0.0191, 0.0173)  train/logits_fake: 0.0193 (0.0192, 0.0175)  train/total_loss: 6013.0649 (10086.6501, 7264.2959)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 155070.2031 (101368.9802, 171970.8125)  train/nll_loss: 6012.9087 (10086.5487, 7264.1240)  train/rec_loss: 0.0261 (0.0438, 0.0315)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0175)
2025-02-06 17:08:35,463 train INFO: [9840/46609/10000]  lr: 9.083861388596024e-05  eta: 0:00:20  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0194 (0.0191, 0.0176)  train/logits_fake: 0.0193 (0.0192, 0.0178)  train/total_loss: 6013.0649 (10078.2897, 7317.2856)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 155465.3125 (101479.3187, 169385.6250)  train/nll_loss: 6012.9087 (10078.1882, 7317.1162)  train/rec_loss: 0.0261 (0.0437, 0.0318)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0194 (-0.0192, -0.0178)
2025-02-06 17:08:38,000 train INFO: [9860/46609/10000]  lr: 9.080253065827637e-05  eta: 0:00:17  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0202)  train/logits_fake: 0.0193 (0.0192, 0.0203)  train/total_loss: 5996.6909 (10070.5499, 5424.4131)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 157122.8438 (101617.4728, 157122.8438)  train/nll_loss: 5996.5498 (10070.4483, 5424.2559)  train/rec_loss: 0.0260 (0.0437, 0.0235)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0203)
2025-02-06 17:08:40,544 train INFO: [9880/46609/10000]  lr: 9.076638378739544e-05  eta: 0:00:15  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0193 (0.0191, 0.0194)  train/logits_fake: 0.0193 (0.0192, 0.0193)  train/total_loss: 6013.0649 (10064.0017, 6524.3208)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 157457.4062 (101723.5295, 192197.5625)  train/nll_loss: 6012.9087 (10063.9000, 6524.1284)  train/rec_loss: 0.0261 (0.0437, 0.0283)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0193 (-0.0192, -0.0193)
2025-02-06 17:08:43,081 train INFO: [9900/46609/10000]  lr: 9.073017333039831e-05  eta: 0:00:12  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0176)  train/logits_fake: 0.0192 (0.0192, 0.0180)  train/total_loss: 6251.9600 (10058.2304, 8484.8145)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 158438.6250 (101839.0250, 152837.0938)  train/nll_loss: 6251.7939 (10058.1285, 8484.6611)  train/rec_loss: 0.0271 (0.0437, 0.0368)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0180)
2025-02-06 17:08:45,614 train INFO: [9920/46609/10000]  lr: 9.069389934446619e-05  eta: 0:00:10  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0192 (0.0191, 0.0193)  train/logits_fake: 0.0192 (0.0192, 0.0190)  train/total_loss: 6380.2104 (10051.6380, 6075.5825)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 157186.3750 (101940.4868, 134412.8125)  train/nll_loss: 6380.0732 (10051.5360, 6075.4482)  train/rec_loss: 0.0277 (0.0436, 0.0264)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0192 (-0.0192, -0.0190)
2025-02-06 17:08:48,146 train INFO: [9940/46609/10000]  lr: 9.065756188688072e-05  eta: 0:00:07  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0186)  train/logits_fake: 0.0191 (0.0192, 0.0186)  train/total_loss: 6417.9287 (10044.4521, 4998.5366)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 158428.1250 (102056.7956, 174560.1250)  train/nll_loss: 6417.7529 (10044.3501, 4998.3623)  train/rec_loss: 0.0279 (0.0436, 0.0217)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0186)
2025-02-06 17:08:50,681 train INFO: [9960/46609/10000]  lr: 9.062116101502362e-05  eta: 0:00:05  iter_time: 0.126  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0180)  train/logits_fake: 0.0190 (0.0192, 0.0179)  train/total_loss: 6402.1484 (10035.8651, 5453.9868)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 155066.6719 (102167.2546, 193537.7812)  train/nll_loss: 6401.9824 (10035.7629, 5453.7935)  train/rec_loss: 0.0278 (0.0436, 0.0237)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0179)
2025-02-06 17:08:53,216 train INFO: [9980/46609/10000]  lr: 9.058469678637693e-05  eta: 0:00:02  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0217)  train/logits_fake: 0.0190 (0.0192, 0.0218)  train/total_loss: 6204.3301 (10027.9040, 5557.1445)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 153772.9062 (102267.9355, 146489.4375)  train/nll_loss: 6204.1606 (10027.8018, 5556.9980)  train/rec_loss: 0.0269 (0.0435, 0.0241)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0190 (-0.0192, -0.0218)
2025-02-06 17:08:55,751 train INFO: [10000/46609/10000]  lr: 9.054816925852258e-05  eta: 0:00:00  iter_time: 0.127  data: 0.000  memory: 7894  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: 0.0191 (0.0191, 0.0208)  train/logits_fake: 0.0191 (0.0192, 0.0201)  train/total_loss: 6075.5825 (10020.3811, 9023.7002)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 152554.6875 (102378.8435, 178818.5000)  train/nll_loss: 6075.4482 (10020.2788, 9023.5215)  train/rec_loss: 0.0264 (0.0435, 0.0392)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: -0.0191 (-0.0192, -0.0201)
2025-02-06 17:44:40,213 train INFO: Epoch [1.21](val stats)  val/disc_loss: 0.0000 (0.0000, 0.0000)  val/logits_real: 0.0182 (0.0191, 0.0227)  val/logits_fake: 0.0177 (0.0188, 0.0176)  val/total_loss: 9588.8877 (7326.4516, 21275.8633)  val/logvar: 0.0000 (0.0000, 0.0000)  val/kl_loss: 179883.8125 (160781.7944, 163407.0625)  val/nll_loss: 9588.6758 (7326.2908, 21275.6992)  val/rec_loss: 0.0416 (0.0318, 0.0923)  val/d_weight: 0.0000 (0.0000, 0.0000)  val/disc_factor: 0.0000 (0.0000, 0.0000)  val/g_loss: -0.0177 (-0.0188, -0.0176)  MSE: 0.0041 (0.0026, 0.0221)
Traceback (most recent call last):
  File "/home/exouser/YuZheng/train.py", line 179, in <module>
    main(args)
  File "/home/exouser/YuZheng/train.py", line 153, in main
    subprocess_fn(args)
  File "/home/exouser/YuZheng/train.py", line 78, in subprocess_fn
    model_without_ddp.trainer(train_dataloader, valid_dataloader, builder.get_max_epoch(), builder.get_max_step(), checkpoint_savedir=args.relative_checkpoint_dir if model_without_ddp.use_ceph else args.run_dir, resume=args.resume)
  File "/home/exouser/YuZheng/models/model.py", line 427, in trainer
    self._iter_trainer(train_data_loader, test_data_loader, max_steps) 
  File "/home/exouser/YuZheng/models/model.py", line 525, in _iter_trainer
    self.save_checkpoint(epoch=(step+1)/epoch_step, checkpoint_savedir=self.checkpoint_savedir, save_type='save_best', step=step+1)
  File "/home/exouser/YuZheng/models/model.py", line 398, in save_checkpoint
    'amp_scaler':       self.gscaler.state_dict(),
  File "/home/exouser/anaconda3/envs/yuzhengood/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1928, in __getattr__
    raise AttributeError(
AttributeError: 'autoencoder_kl_gan_model' object has no attribute 'gscaler'
